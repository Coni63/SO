{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REBER Grammar with RNN\n",
    "\n",
    "In this workbook, we are going to set-up multiple Recurrent Neural Network to test them using as test <a href=\"https://www.willamette.edu/~gorr/classes/cs449/reber.html\" target=\"_blank\">Reber's grammar</a> words.\n",
    "\n",
    "## What is a Reber Word ?\n",
    "\n",
    "A Reber word is a word following the Reber's grammar. The grammar is based on the following graph:\n",
    "\n",
    "<img src=\"reber.gif\"/>\n",
    "\n",
    "The word must start with B, then it can be either T or P and so on until it reaches E. To prepare data for this, we are going to use a OneHotEncoder to have 7 inputs, n timesteps (depending on the length of the word) and k batches. To generate it, I use the algorith from <a href=\"http://christianherta.de/lehre/dataScience/machineLearning/neuralNetworks/reberGrammar.php\" target=\"_target\">this site</a>\n",
    "\n",
    "It also exists an Embedded version of the Reber Grammar using the following graph :\n",
    "\n",
    "<img src=\"embreber.gif\"/>\n",
    "\n",
    "For now, we gonna focus on the simple version and based on the result, we may try the embedded version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "import create_dataset as reber\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of datas\n",
    "\n",
    "For the OneHotEncoder, the chain 'BTSXPVE' will be used. We can now try only 1 example to check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTXXTVPXVPS\n",
      "[ 1.  0.  0.  0.  0.  0.  0.] [ 0.  1.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "x, y = reber.get_one_example(minLength=10)\n",
    "print(reber.sequenceToWord(x))\n",
    "print(x[0], y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*y* is the possible outcome for a given input. That means B ([ 1.  0.  0.  0.  0.  0.  0.]) can be followed by T or P ([ 0.  1.  0.  0.  1.  0.  0.]).\n",
    "\n",
    "However, we won't use y as output but for every timestep, we are going to provide the next timestep as target. For this, we will use the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(x0):\n",
    "    end = np.array([0.,  0.,  0.,  0.,  0.,  0.,  1.])\n",
    "    y=x0[1:]\n",
    "    y.append(end)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we take as input \"BTSXS\", the output will be \"TSXSE\" (but the input in encoded).\n",
    "\n",
    "We can also generate few words to check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTSSSSSXXVPS\n",
      "BPTTTVPXVPXTTTVV\n",
      "BPTTTVPXVPXVPXTVV\n",
      "BPTTVPXTVPS\n",
      "BTXXTVPXVPXVPS\n",
      "BTSSXXTVPXVV\n",
      "BTSSSXXVPS\n",
      "BTXXTVPXVPXTTTTVPS\n",
      "BPVPXTTTVPXTTVPXVV\n",
      "BTSXXTTTVV\n"
     ]
    }
   ],
   "source": [
    "min_length = 10\n",
    "for i in range(10):\n",
    "    inp, out = reber.get_one_example(min_length)\n",
    "    print(reber.sequenceToWord(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have the first \"problem\" now, the length of the string is variable. So when we are going to generate our test/train datas, we will have to pad them to the same length (let's say 20). This is done by using <b>sequence.pad_sequences</b> for Keras Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 20, 7)\n",
      "(2048, 20, 7)\n",
      "(256, 20, 7)\n",
      "(256, 20, 7)\n",
      "(1, 20, 7)\n",
      "(1, 20, 7)\n",
      "(1, 20, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "X_val, y_val = [], []\n",
    "y_possible = []\n",
    "\n",
    "for i in range(2048):\n",
    "    x, y = reber.get_one_example(min_length)\n",
    "    X_train.append(x)\n",
    "    y_train.append(generate(x))\n",
    "\n",
    "for i in range(256):\n",
    "    x, y = reber.get_one_example(min_length)\n",
    "    X_test.append(x)\n",
    "    y_test.append(generate(x))  \n",
    "    \n",
    "for i in range(1):\n",
    "    x, y = reber.get_one_example(min_length)\n",
    "    X_val.append(x)\n",
    "    y_val.append(generate(x))\n",
    "    y_possible.append(y)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "y_possible = np.array(y_possible)\n",
    "\n",
    "maxlen = 20\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_train = sequence.pad_sequences(y_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_test = sequence.pad_sequences(y_test, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_val = sequence.pad_sequences(y_val, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_possible = sequence.pad_sequences(y_possible, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(y_possible.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1 0 0 1 0 0]\n",
      "  [0 0 1 1 0 0 0]\n",
      "  [0 0 1 1 0 0 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 0 0 0 1 1 0]\n",
      "  [0 0 1 1 0 0 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 0 0 0 1 1 0]\n",
      "  [0 0 1 1 0 0 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 0 0 0 1 1 0]\n",
      "  [0 0 1 1 0 0 0]\n",
      "  [0 1 0 0 0 1 0]\n",
      "  [0 0 0 0 1 1 0]\n",
      "  [0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(y_possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have 2048 strings for training, 256 for test and 1 just for visualisation later. We can now set-up our model.\n",
    "\n",
    "## Test of RNNs\n",
    "\n",
    "For this model, we are going to use a many-to-many RNN. That means for every input, the model will predict an output. The training will be done based on the input we prepared previously. Once trained. We will be able to \"transfer\" the learning to a one-to-many model in order to have a \"generator\".\n",
    "\n",
    "<img src=\"RNN_types.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the writing of this notebook, I tried some loss, metrics and optimizer. The following ones are the one fitting the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_unit = 7\n",
    "inp_shape = (maxlen, 7)\n",
    "loss_ = \"categorical_crossentropy\"\n",
    "metrics_ = \"categorical_crossentropy\"\n",
    "optimizer_ = \"Nadam\"\n",
    "nb_epoch = 250\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "The first model we will setup is an <b>LSTM</b> which means <b>L</b>ong <b>S</b>hort-<b>T</b>erm <b>M</b>emory. The principle is \n",
    "quite complex but very powerfull for long sequences inputs (because there is less issues with Vanishing Gradient Problem) or long term memory (You can refer to <a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\" target=\"_blank\">this link</a> for more informations)\n",
    "\n",
    "LSTM is widely for speech recognition, Natural Language processing, Sentiment Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=nb_unit, input_shape=inp_shape, return_sequences=True, activation='softmax'))  # single LSTM\n",
    "model.compile(loss=loss_,\n",
    "              optimizer=optimizer_,\n",
    "              metrics=[metrics_])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"lstm_simple.h5\",\n",
    "    monitor=loss_,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1)\n",
    "early = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: (None, 20, 7)\n",
      "Outputs: (None, 20, 7)\n",
      "Actual input: (2048, 20, 7)\n",
      "Actual output: (2048, 20, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs: {}\".format(model.input_shape))\n",
    "print(\"Outputs: {}\".format(model.output_shape))\n",
    "print(\"Actual input: {}\".format(X_train.shape))\n",
    "print(\"Actual output: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 256 samples\n",
      "Epoch 1/250\n",
      "Epoch 00001: categorical_crossentropy improved from inf to 1.22591, saving model to lstm_simple.h5\n",
      " - 3s - loss: 1.2259 - categorical_crossentropy: 1.2259 - val_loss: 1.2533 - val_categorical_crossentropy: 1.2533\n",
      "Epoch 2/250\n",
      "Epoch 00002: categorical_crossentropy improved from 1.22591 to 1.17858, saving model to lstm_simple.h5\n",
      " - 2s - loss: 1.1786 - categorical_crossentropy: 1.1786 - val_loss: 1.2060 - val_categorical_crossentropy: 1.2060\n",
      "Epoch 3/250\n",
      "Epoch 00003: categorical_crossentropy improved from 1.17858 to 1.13519, saving model to lstm_simple.h5\n",
      " - 2s - loss: 1.1352 - categorical_crossentropy: 1.1352 - val_loss: 1.1637 - val_categorical_crossentropy: 1.1637\n",
      "Epoch 4/250\n",
      "Epoch 00004: categorical_crossentropy improved from 1.13519 to 1.09620, saving model to lstm_simple.h5\n",
      " - 2s - loss: 1.0962 - categorical_crossentropy: 1.0962 - val_loss: 1.1260 - val_categorical_crossentropy: 1.1260\n",
      "Epoch 5/250\n",
      "Epoch 00005: categorical_crossentropy improved from 1.09620 to 1.06158, saving model to lstm_simple.h5\n",
      " - 2s - loss: 1.0616 - categorical_crossentropy: 1.0616 - val_loss: 1.0922 - val_categorical_crossentropy: 1.0922\n",
      "Epoch 6/250\n",
      "Epoch 00006: categorical_crossentropy improved from 1.06158 to 1.03051, saving model to lstm_simple.h5\n",
      " - 2s - loss: 1.0305 - categorical_crossentropy: 1.0305 - val_loss: 1.0614 - val_categorical_crossentropy: 1.0614\n",
      "Epoch 7/250\n",
      "Epoch 00007: categorical_crossentropy improved from 1.03051 to 1.00197, saving model to lstm_simple.h5\n",
      " - 2s - loss: 1.0020 - categorical_crossentropy: 1.0020 - val_loss: 1.0321 - val_categorical_crossentropy: 1.0321\n",
      "Epoch 8/250\n",
      "Epoch 00008: categorical_crossentropy improved from 1.00197 to 0.97481, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.9748 - categorical_crossentropy: 0.9748 - val_loss: 1.0039 - val_categorical_crossentropy: 1.0039\n",
      "Epoch 9/250\n",
      "Epoch 00009: categorical_crossentropy improved from 0.97481 to 0.94866, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.9487 - categorical_crossentropy: 0.9487 - val_loss: 0.9762 - val_categorical_crossentropy: 0.9762\n",
      "Epoch 10/250\n",
      "Epoch 00010: categorical_crossentropy improved from 0.94866 to 0.92286, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.9229 - categorical_crossentropy: 0.9229 - val_loss: 0.9488 - val_categorical_crossentropy: 0.9488\n",
      "Epoch 11/250\n",
      "Epoch 00011: categorical_crossentropy improved from 0.92286 to 0.89675, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.8968 - categorical_crossentropy: 0.8968 - val_loss: 0.9206 - val_categorical_crossentropy: 0.9206\n",
      "Epoch 12/250\n",
      "Epoch 00012: categorical_crossentropy improved from 0.89675 to 0.86962, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.8696 - categorical_crossentropy: 0.8696 - val_loss: 0.8922 - val_categorical_crossentropy: 0.8922\n",
      "Epoch 13/250\n",
      "Epoch 00013: categorical_crossentropy improved from 0.86962 to 0.84309, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.8431 - categorical_crossentropy: 0.8431 - val_loss: 0.8643 - val_categorical_crossentropy: 0.8643\n",
      "Epoch 14/250\n",
      "Epoch 00014: categorical_crossentropy improved from 0.84309 to 0.81656, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.8166 - categorical_crossentropy: 0.8166 - val_loss: 0.8361 - val_categorical_crossentropy: 0.8361\n",
      "Epoch 15/250\n",
      "Epoch 00015: categorical_crossentropy improved from 0.81656 to 0.78966, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.7897 - categorical_crossentropy: 0.7897 - val_loss: 0.8074 - val_categorical_crossentropy: 0.8074\n",
      "Epoch 16/250\n",
      "Epoch 00016: categorical_crossentropy improved from 0.78966 to 0.76231, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.7623 - categorical_crossentropy: 0.7623 - val_loss: 0.7778 - val_categorical_crossentropy: 0.7778\n",
      "Epoch 17/250\n",
      "Epoch 00017: categorical_crossentropy improved from 0.76231 to 0.73355, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.7336 - categorical_crossentropy: 0.7336 - val_loss: 0.7472 - val_categorical_crossentropy: 0.7472\n",
      "Epoch 18/250\n",
      "Epoch 00018: categorical_crossentropy improved from 0.73355 to 0.70680, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.7068 - categorical_crossentropy: 0.7068 - val_loss: 0.7205 - val_categorical_crossentropy: 0.7205\n",
      "Epoch 19/250\n",
      "Epoch 00019: categorical_crossentropy improved from 0.70680 to 0.68230, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.6823 - categorical_crossentropy: 0.6823 - val_loss: 0.6947 - val_categorical_crossentropy: 0.6947\n",
      "Epoch 20/250\n",
      "Epoch 00020: categorical_crossentropy improved from 0.68230 to 0.66105, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.6611 - categorical_crossentropy: 0.6611 - val_loss: 0.6731 - val_categorical_crossentropy: 0.6731\n",
      "Epoch 21/250\n",
      "Epoch 00021: categorical_crossentropy improved from 0.66105 to 0.64241, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.6424 - categorical_crossentropy: 0.6424 - val_loss: 0.6529 - val_categorical_crossentropy: 0.6529\n",
      "Epoch 22/250\n",
      "Epoch 00022: categorical_crossentropy improved from 0.64241 to 0.62419, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.6242 - categorical_crossentropy: 0.6242 - val_loss: 0.6343 - val_categorical_crossentropy: 0.6343\n",
      "Epoch 23/250\n",
      "Epoch 00023: categorical_crossentropy improved from 0.62419 to 0.60922, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.6092 - categorical_crossentropy: 0.6092 - val_loss: 0.6202 - val_categorical_crossentropy: 0.6202\n",
      "Epoch 24/250\n",
      "Epoch 00024: categorical_crossentropy improved from 0.60922 to 0.59704, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5970 - categorical_crossentropy: 0.5970 - val_loss: 0.6088 - val_categorical_crossentropy: 0.6088\n",
      "Epoch 25/250\n",
      "Epoch 00025: categorical_crossentropy improved from 0.59704 to 0.58627, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5863 - categorical_crossentropy: 0.5863 - val_loss: 0.5979 - val_categorical_crossentropy: 0.5979\n",
      "Epoch 26/250\n",
      "Epoch 00026: categorical_crossentropy improved from 0.58627 to 0.57665, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5766 - categorical_crossentropy: 0.5766 - val_loss: 0.5885 - val_categorical_crossentropy: 0.5885\n",
      "Epoch 27/250\n",
      "Epoch 00027: categorical_crossentropy improved from 0.57665 to 0.56766, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5677 - categorical_crossentropy: 0.5677 - val_loss: 0.5793 - val_categorical_crossentropy: 0.5793\n",
      "Epoch 28/250\n",
      "Epoch 00028: categorical_crossentropy improved from 0.56766 to 0.55876, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5588 - categorical_crossentropy: 0.5588 - val_loss: 0.5703 - val_categorical_crossentropy: 0.5703\n",
      "Epoch 29/250\n",
      "Epoch 00029: categorical_crossentropy improved from 0.55876 to 0.55103, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5510 - categorical_crossentropy: 0.5510 - val_loss: 0.5626 - val_categorical_crossentropy: 0.5626\n",
      "Epoch 30/250\n",
      "Epoch 00030: categorical_crossentropy improved from 0.55103 to 0.54428, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5443 - categorical_crossentropy: 0.5443 - val_loss: 0.5559 - val_categorical_crossentropy: 0.5559\n",
      "Epoch 31/250\n",
      "Epoch 00031: categorical_crossentropy improved from 0.54428 to 0.53812, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5381 - categorical_crossentropy: 0.5381 - val_loss: 0.5501 - val_categorical_crossentropy: 0.5501\n",
      "Epoch 32/250\n",
      "Epoch 00032: categorical_crossentropy improved from 0.53812 to 0.53235, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5324 - categorical_crossentropy: 0.5324 - val_loss: 0.5438 - val_categorical_crossentropy: 0.5438\n",
      "Epoch 33/250\n",
      "Epoch 00033: categorical_crossentropy improved from 0.53235 to 0.52680, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5268 - categorical_crossentropy: 0.5268 - val_loss: 0.5382 - val_categorical_crossentropy: 0.5382\n",
      "Epoch 34/250\n",
      "Epoch 00034: categorical_crossentropy improved from 0.52680 to 0.52087, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5209 - categorical_crossentropy: 0.5209 - val_loss: 0.5323 - val_categorical_crossentropy: 0.5323\n",
      "Epoch 35/250\n",
      "Epoch 00035: categorical_crossentropy improved from 0.52087 to 0.51442, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5144 - categorical_crossentropy: 0.5144 - val_loss: 0.5268 - val_categorical_crossentropy: 0.5268\n",
      "Epoch 36/250\n",
      "Epoch 00036: categorical_crossentropy improved from 0.51442 to 0.50916, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5092 - categorical_crossentropy: 0.5092 - val_loss: 0.5222 - val_categorical_crossentropy: 0.5222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "Epoch 00037: categorical_crossentropy improved from 0.50916 to 0.50457, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5046 - categorical_crossentropy: 0.5046 - val_loss: 0.5181 - val_categorical_crossentropy: 0.5181\n",
      "Epoch 38/250\n",
      "Epoch 00038: categorical_crossentropy improved from 0.50457 to 0.50038, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.5004 - categorical_crossentropy: 0.5004 - val_loss: 0.5144 - val_categorical_crossentropy: 0.5144\n",
      "Epoch 39/250\n",
      "Epoch 00039: categorical_crossentropy improved from 0.50038 to 0.49642, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4964 - categorical_crossentropy: 0.4964 - val_loss: 0.5105 - val_categorical_crossentropy: 0.5105\n",
      "Epoch 40/250\n",
      "Epoch 00040: categorical_crossentropy improved from 0.49642 to 0.49262, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4926 - categorical_crossentropy: 0.4926 - val_loss: 0.5068 - val_categorical_crossentropy: 0.5068\n",
      "Epoch 41/250\n",
      "Epoch 00041: categorical_crossentropy improved from 0.49262 to 0.48870, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4887 - categorical_crossentropy: 0.4887 - val_loss: 0.5035 - val_categorical_crossentropy: 0.5035\n",
      "Epoch 42/250\n",
      "Epoch 00042: categorical_crossentropy improved from 0.48870 to 0.48495, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4850 - categorical_crossentropy: 0.4850 - val_loss: 0.4996 - val_categorical_crossentropy: 0.4996\n",
      "Epoch 43/250\n",
      "Epoch 00043: categorical_crossentropy improved from 0.48495 to 0.48122, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4812 - categorical_crossentropy: 0.4812 - val_loss: 0.4958 - val_categorical_crossentropy: 0.4958\n",
      "Epoch 44/250\n",
      "Epoch 00044: categorical_crossentropy improved from 0.48122 to 0.47732, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4773 - categorical_crossentropy: 0.4773 - val_loss: 0.4914 - val_categorical_crossentropy: 0.4914\n",
      "Epoch 45/250\n",
      "Epoch 00045: categorical_crossentropy improved from 0.47732 to 0.47280, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4728 - categorical_crossentropy: 0.4728 - val_loss: 0.4859 - val_categorical_crossentropy: 0.4859\n",
      "Epoch 46/250\n",
      "Epoch 00046: categorical_crossentropy improved from 0.47280 to 0.46699, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4670 - categorical_crossentropy: 0.4670 - val_loss: 0.4782 - val_categorical_crossentropy: 0.4782\n",
      "Epoch 47/250\n",
      "Epoch 00047: categorical_crossentropy improved from 0.46699 to 0.45941, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4594 - categorical_crossentropy: 0.4594 - val_loss: 0.4680 - val_categorical_crossentropy: 0.4680\n",
      "Epoch 48/250\n",
      "Epoch 00048: categorical_crossentropy improved from 0.45941 to 0.44849, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4485 - categorical_crossentropy: 0.4485 - val_loss: 0.4565 - val_categorical_crossentropy: 0.4565\n",
      "Epoch 49/250\n",
      "Epoch 00049: categorical_crossentropy improved from 0.44849 to 0.44256, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4426 - categorical_crossentropy: 0.4426 - val_loss: 0.4537 - val_categorical_crossentropy: 0.4537\n",
      "Epoch 50/250\n",
      "Epoch 00050: categorical_crossentropy improved from 0.44256 to 0.43945, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4395 - categorical_crossentropy: 0.4395 - val_loss: 0.4502 - val_categorical_crossentropy: 0.4502\n",
      "Epoch 51/250\n",
      "Epoch 00051: categorical_crossentropy improved from 0.43945 to 0.43676, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4368 - categorical_crossentropy: 0.4368 - val_loss: 0.4480 - val_categorical_crossentropy: 0.4480\n",
      "Epoch 52/250\n",
      "Epoch 00052: categorical_crossentropy improved from 0.43676 to 0.43429, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4343 - categorical_crossentropy: 0.4343 - val_loss: 0.4452 - val_categorical_crossentropy: 0.4452\n",
      "Epoch 53/250\n",
      "Epoch 00053: categorical_crossentropy improved from 0.43429 to 0.43243, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4324 - categorical_crossentropy: 0.4324 - val_loss: 0.4449 - val_categorical_crossentropy: 0.4449\n",
      "Epoch 54/250\n",
      "Epoch 00054: categorical_crossentropy improved from 0.43243 to 0.43078, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4308 - categorical_crossentropy: 0.4308 - val_loss: 0.4426 - val_categorical_crossentropy: 0.4426\n",
      "Epoch 55/250\n",
      "Epoch 00055: categorical_crossentropy improved from 0.43078 to 0.42938, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4294 - categorical_crossentropy: 0.4294 - val_loss: 0.4434 - val_categorical_crossentropy: 0.4434\n",
      "Epoch 56/250\n",
      "Epoch 00056: categorical_crossentropy improved from 0.42938 to 0.42816, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4282 - categorical_crossentropy: 0.4282 - val_loss: 0.4406 - val_categorical_crossentropy: 0.4406\n",
      "Epoch 57/250\n",
      "Epoch 00057: categorical_crossentropy improved from 0.42816 to 0.42683, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4268 - categorical_crossentropy: 0.4268 - val_loss: 0.4395 - val_categorical_crossentropy: 0.4395\n",
      "Epoch 58/250\n",
      "Epoch 00058: categorical_crossentropy improved from 0.42683 to 0.42579, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4258 - categorical_crossentropy: 0.4258 - val_loss: 0.4384 - val_categorical_crossentropy: 0.4384\n",
      "Epoch 59/250\n",
      "Epoch 00059: categorical_crossentropy improved from 0.42579 to 0.42469, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4247 - categorical_crossentropy: 0.4247 - val_loss: 0.4377 - val_categorical_crossentropy: 0.4377\n",
      "Epoch 60/250\n",
      "Epoch 00060: categorical_crossentropy improved from 0.42469 to 0.42371, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4237 - categorical_crossentropy: 0.4237 - val_loss: 0.4379 - val_categorical_crossentropy: 0.4379\n",
      "Epoch 61/250\n",
      "Epoch 00061: categorical_crossentropy improved from 0.42371 to 0.42252, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4225 - categorical_crossentropy: 0.4225 - val_loss: 0.4367 - val_categorical_crossentropy: 0.4367\n",
      "Epoch 62/250\n",
      "Epoch 00062: categorical_crossentropy improved from 0.42252 to 0.42200, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4220 - categorical_crossentropy: 0.4220 - val_loss: 0.4376 - val_categorical_crossentropy: 0.4376\n",
      "Epoch 63/250\n",
      "Epoch 00063: categorical_crossentropy improved from 0.42200 to 0.42089, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4209 - categorical_crossentropy: 0.4209 - val_loss: 0.4354 - val_categorical_crossentropy: 0.4354\n",
      "Epoch 64/250\n",
      "Epoch 00064: categorical_crossentropy improved from 0.42089 to 0.41978, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4198 - categorical_crossentropy: 0.4198 - val_loss: 0.4344 - val_categorical_crossentropy: 0.4344\n",
      "Epoch 65/250\n",
      "Epoch 00065: categorical_crossentropy improved from 0.41978 to 0.41929, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4193 - categorical_crossentropy: 0.4193 - val_loss: 0.4334 - val_categorical_crossentropy: 0.4334\n",
      "Epoch 66/250\n",
      "Epoch 00066: categorical_crossentropy improved from 0.41929 to 0.41828, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4183 - categorical_crossentropy: 0.4183 - val_loss: 0.4333 - val_categorical_crossentropy: 0.4333\n",
      "Epoch 67/250\n",
      "Epoch 00067: categorical_crossentropy improved from 0.41828 to 0.41719, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4172 - categorical_crossentropy: 0.4172 - val_loss: 0.4324 - val_categorical_crossentropy: 0.4324\n",
      "Epoch 68/250\n",
      "Epoch 00068: categorical_crossentropy improved from 0.41719 to 0.41656, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4166 - categorical_crossentropy: 0.4166 - val_loss: 0.4313 - val_categorical_crossentropy: 0.4313\n",
      "Epoch 69/250\n",
      "Epoch 00069: categorical_crossentropy improved from 0.41656 to 0.41529, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4153 - categorical_crossentropy: 0.4153 - val_loss: 0.4308 - val_categorical_crossentropy: 0.4308\n",
      "Epoch 70/250\n",
      "Epoch 00070: categorical_crossentropy improved from 0.41529 to 0.41438, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4144 - categorical_crossentropy: 0.4144 - val_loss: 0.4306 - val_categorical_crossentropy: 0.4306\n",
      "Epoch 71/250\n",
      "Epoch 00071: categorical_crossentropy improved from 0.41438 to 0.41332, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4133 - categorical_crossentropy: 0.4133 - val_loss: 0.4307 - val_categorical_crossentropy: 0.4307\n",
      "Epoch 72/250\n",
      "Epoch 00072: categorical_crossentropy improved from 0.41332 to 0.41231, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4123 - categorical_crossentropy: 0.4123 - val_loss: 0.4282 - val_categorical_crossentropy: 0.4282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/250\n",
      "Epoch 00073: categorical_crossentropy improved from 0.41231 to 0.41079, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4108 - categorical_crossentropy: 0.4108 - val_loss: 0.4264 - val_categorical_crossentropy: 0.4264\n",
      "Epoch 74/250\n",
      "Epoch 00074: categorical_crossentropy improved from 0.41079 to 0.41000, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4100 - categorical_crossentropy: 0.4100 - val_loss: 0.4257 - val_categorical_crossentropy: 0.4257\n",
      "Epoch 75/250\n",
      "Epoch 00075: categorical_crossentropy improved from 0.41000 to 0.40842, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4084 - categorical_crossentropy: 0.4084 - val_loss: 0.4240 - val_categorical_crossentropy: 0.4240\n",
      "Epoch 76/250\n",
      "Epoch 00076: categorical_crossentropy improved from 0.40842 to 0.40708, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4071 - categorical_crossentropy: 0.4071 - val_loss: 0.4222 - val_categorical_crossentropy: 0.4222\n",
      "Epoch 77/250\n",
      "Epoch 00077: categorical_crossentropy improved from 0.40708 to 0.40603, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4060 - categorical_crossentropy: 0.4060 - val_loss: 0.4222 - val_categorical_crossentropy: 0.4222\n",
      "Epoch 78/250\n",
      "Epoch 00078: categorical_crossentropy improved from 0.40603 to 0.40473, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4047 - categorical_crossentropy: 0.4047 - val_loss: 0.4201 - val_categorical_crossentropy: 0.4201\n",
      "Epoch 79/250\n",
      "Epoch 00079: categorical_crossentropy improved from 0.40473 to 0.40316, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4032 - categorical_crossentropy: 0.4032 - val_loss: 0.4213 - val_categorical_crossentropy: 0.4213\n",
      "Epoch 80/250\n",
      "Epoch 00080: categorical_crossentropy improved from 0.40316 to 0.40217, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4022 - categorical_crossentropy: 0.4022 - val_loss: 0.4324 - val_categorical_crossentropy: 0.4324\n",
      "Epoch 81/250\n",
      "Epoch 00081: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.4035 - categorical_crossentropy: 0.4035 - val_loss: 0.4199 - val_categorical_crossentropy: 0.4199\n",
      "Epoch 82/250\n",
      "Epoch 00082: categorical_crossentropy improved from 0.40217 to 0.40045, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.4004 - categorical_crossentropy: 0.4004 - val_loss: 0.4171 - val_categorical_crossentropy: 0.4171\n",
      "Epoch 83/250\n",
      "Epoch 00083: categorical_crossentropy improved from 0.40045 to 0.39911, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3991 - categorical_crossentropy: 0.3991 - val_loss: 0.4159 - val_categorical_crossentropy: 0.4159\n",
      "Epoch 84/250\n",
      "Epoch 00084: categorical_crossentropy improved from 0.39911 to 0.39772, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3977 - categorical_crossentropy: 0.3977 - val_loss: 0.4134 - val_categorical_crossentropy: 0.4134\n",
      "Epoch 85/250\n",
      "Epoch 00085: categorical_crossentropy improved from 0.39772 to 0.39631, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3963 - categorical_crossentropy: 0.3963 - val_loss: 0.4128 - val_categorical_crossentropy: 0.4128\n",
      "Epoch 86/250\n",
      "Epoch 00086: categorical_crossentropy improved from 0.39631 to 0.39511, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3951 - categorical_crossentropy: 0.3951 - val_loss: 0.4109 - val_categorical_crossentropy: 0.4109\n",
      "Epoch 87/250\n",
      "Epoch 00087: categorical_crossentropy improved from 0.39511 to 0.39381, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3938 - categorical_crossentropy: 0.3938 - val_loss: 0.4108 - val_categorical_crossentropy: 0.4108\n",
      "Epoch 88/250\n",
      "Epoch 00088: categorical_crossentropy improved from 0.39381 to 0.39228, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3923 - categorical_crossentropy: 0.3923 - val_loss: 0.4079 - val_categorical_crossentropy: 0.4079\n",
      "Epoch 89/250\n",
      "Epoch 00089: categorical_crossentropy improved from 0.39228 to 0.39086, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3909 - categorical_crossentropy: 0.3909 - val_loss: 0.4067 - val_categorical_crossentropy: 0.4067\n",
      "Epoch 90/250\n",
      "Epoch 00090: categorical_crossentropy improved from 0.39086 to 0.38977, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3898 - categorical_crossentropy: 0.3898 - val_loss: 0.4062 - val_categorical_crossentropy: 0.4062\n",
      "Epoch 91/250\n",
      "Epoch 00091: categorical_crossentropy improved from 0.38977 to 0.38861, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3886 - categorical_crossentropy: 0.3886 - val_loss: 0.4051 - val_categorical_crossentropy: 0.4051\n",
      "Epoch 92/250\n",
      "Epoch 00092: categorical_crossentropy improved from 0.38861 to 0.38609, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3861 - categorical_crossentropy: 0.3861 - val_loss: 0.4032 - val_categorical_crossentropy: 0.4032\n",
      "Epoch 93/250\n",
      "Epoch 00093: categorical_crossentropy improved from 0.38609 to 0.38444, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3844 - categorical_crossentropy: 0.3844 - val_loss: 0.4016 - val_categorical_crossentropy: 0.4016\n",
      "Epoch 94/250\n",
      "Epoch 00094: categorical_crossentropy improved from 0.38444 to 0.38312, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3831 - categorical_crossentropy: 0.3831 - val_loss: 0.3998 - val_categorical_crossentropy: 0.3998\n",
      "Epoch 95/250\n",
      "Epoch 00095: categorical_crossentropy improved from 0.38312 to 0.38182, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3818 - categorical_crossentropy: 0.3818 - val_loss: 0.3992 - val_categorical_crossentropy: 0.3992\n",
      "Epoch 96/250\n",
      "Epoch 00096: categorical_crossentropy improved from 0.38182 to 0.38095, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3809 - categorical_crossentropy: 0.3809 - val_loss: 0.3979 - val_categorical_crossentropy: 0.3979\n",
      "Epoch 97/250\n",
      "Epoch 00097: categorical_crossentropy improved from 0.38095 to 0.38056, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3806 - categorical_crossentropy: 0.3806 - val_loss: 0.3984 - val_categorical_crossentropy: 0.3984\n",
      "Epoch 98/250\n",
      "Epoch 00098: categorical_crossentropy improved from 0.38056 to 0.38019, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3802 - categorical_crossentropy: 0.3802 - val_loss: 0.3979 - val_categorical_crossentropy: 0.3979\n",
      "Epoch 99/250\n",
      "Epoch 00099: categorical_crossentropy improved from 0.38019 to 0.37992, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3799 - categorical_crossentropy: 0.3799 - val_loss: 0.3972 - val_categorical_crossentropy: 0.3972\n",
      "Epoch 100/250\n",
      "Epoch 00100: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.3800 - categorical_crossentropy: 0.3800 - val_loss: 0.3980 - val_categorical_crossentropy: 0.3980\n",
      "Epoch 101/250\n",
      "Epoch 00101: categorical_crossentropy improved from 0.37992 to 0.37953, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3795 - categorical_crossentropy: 0.3795 - val_loss: 0.3971 - val_categorical_crossentropy: 0.3971\n",
      "Epoch 102/250\n",
      "Epoch 00102: categorical_crossentropy improved from 0.37953 to 0.37913, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3791 - categorical_crossentropy: 0.3791 - val_loss: 0.3973 - val_categorical_crossentropy: 0.3973\n",
      "Epoch 103/250\n",
      "Epoch 00103: categorical_crossentropy improved from 0.37913 to 0.37901, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3790 - categorical_crossentropy: 0.3790 - val_loss: 0.3963 - val_categorical_crossentropy: 0.3963\n",
      "Epoch 104/250\n",
      "Epoch 00104: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.3795 - categorical_crossentropy: 0.3795 - val_loss: 0.3985 - val_categorical_crossentropy: 0.3985\n",
      "Epoch 105/250\n",
      "Epoch 00105: categorical_crossentropy improved from 0.37901 to 0.37883, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3788 - categorical_crossentropy: 0.3788 - val_loss: 0.3965 - val_categorical_crossentropy: 0.3965\n",
      "Epoch 106/250\n",
      "Epoch 00106: categorical_crossentropy improved from 0.37883 to 0.37838, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3784 - categorical_crossentropy: 0.3784 - val_loss: 0.3964 - val_categorical_crossentropy: 0.3964\n",
      "Epoch 107/250\n",
      "Epoch 00107: categorical_crossentropy improved from 0.37838 to 0.37815, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3782 - categorical_crossentropy: 0.3782 - val_loss: 0.3971 - val_categorical_crossentropy: 0.3971\n",
      "Epoch 108/250\n",
      "Epoch 00108: categorical_crossentropy improved from 0.37815 to 0.37804, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3780 - categorical_crossentropy: 0.3780 - val_loss: 0.3955 - val_categorical_crossentropy: 0.3955\n",
      "Epoch 109/250\n",
      "Epoch 00109: categorical_crossentropy improved from 0.37804 to 0.37769, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3777 - categorical_crossentropy: 0.3777 - val_loss: 0.3951 - val_categorical_crossentropy: 0.3951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/250\n",
      "Epoch 00110: categorical_crossentropy improved from 0.37769 to 0.37746, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3775 - categorical_crossentropy: 0.3775 - val_loss: 0.3987 - val_categorical_crossentropy: 0.3987\n",
      "Epoch 111/250\n",
      "Epoch 00111: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.3783 - categorical_crossentropy: 0.3783 - val_loss: 0.3969 - val_categorical_crossentropy: 0.3969\n",
      "Epoch 112/250\n",
      "Epoch 00112: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.3775 - categorical_crossentropy: 0.3775 - val_loss: 0.3943 - val_categorical_crossentropy: 0.3943\n",
      "Epoch 113/250\n",
      "Epoch 00113: categorical_crossentropy improved from 0.37746 to 0.37701, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3770 - categorical_crossentropy: 0.3770 - val_loss: 0.3946 - val_categorical_crossentropy: 0.3946\n",
      "Epoch 114/250\n",
      "Epoch 00114: categorical_crossentropy improved from 0.37701 to 0.37673, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.3767 - categorical_crossentropy: 0.3767 - val_loss: 0.3940 - val_categorical_crossentropy: 0.3940\n",
      "Epoch 115/250\n",
      "Epoch 00115: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.3769 - categorical_crossentropy: 0.3769 - val_loss: 0.3958 - val_categorical_crossentropy: 0.3958\n",
      "Epoch 116/250\n",
      "Epoch 00116: categorical_crossentropy did not improve\n",
      " - 2s - loss: 0.3774 - categorical_crossentropy: 0.3774 - val_loss: 0.3945 - val_categorical_crossentropy: 0.3945\n",
      "Epoch 117/250\n",
      "Epoch 00117: categorical_crossentropy improved from 0.37673 to 0.08198, saving model to lstm_simple.h5\n",
      " - 2s - loss: 0.0820 - categorical_crossentropy: 0.0820 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 118/250\n",
      "Epoch 00118: categorical_crossentropy improved from 0.08198 to 0.00000, saving model to lstm_simple.h5\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 119/250\n",
      "Epoch 00119: categorical_crossentropy improved from 0.00000 to 0.00000, saving model to lstm_simple.h5\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 120/250\n",
      "Epoch 00120: categorical_crossentropy improved from 0.00000 to 0.00000, saving model to lstm_simple.h5\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 121/250\n",
      "Epoch 00121: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 122/250\n",
      "Epoch 00122: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 123/250\n",
      "Epoch 00123: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 124/250\n",
      "Epoch 00124: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 125/250\n",
      "Epoch 00125: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 126/250\n",
      "Epoch 00126: categorical_crossentropy improved from 0.00000 to 0.00000, saving model to lstm_simple.h5\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 127/250\n",
      "Epoch 00127: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 128/250\n",
      "Epoch 00128: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 129/250\n",
      "Epoch 00129: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 130/250\n",
      "Epoch 00130: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 131/250\n",
      "Epoch 00131: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 132/250\n",
      "Epoch 00132: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 133/250\n",
      "Epoch 00133: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 134/250\n",
      "Epoch 00134: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 135/250\n",
      "Epoch 00135: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 136/250\n",
      "Epoch 00136: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 137/250\n",
      "Epoch 00137: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 138/250\n",
      "Epoch 00138: categorical_crossentropy did not improve\n",
      " - 2s - loss: 7.5460e-08 - categorical_crossentropy: 7.5460e-08 - val_loss: 7.8743e-08 - val_categorical_crossentropy: 7.8743e-08\n",
      "Epoch 00138: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 20, 7)             420       \n",
      "=================================================================\n",
      "Total params: 420\n",
      "Trainable params: 420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training time : 222.43411540985107s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    callbacks = [checkpoint, early])\n",
    "stop = time.time()\n",
    "t1 = stop-start\n",
    "print(model.summary())\n",
    "print(\"Training time : {}s\".format(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_steps = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN\n",
    "\n",
    "Using the same code, we can train the standard RNN. The principle is that every output of every hidden layers, are also feed as entry for the next step\n",
    "\n",
    "<img src=\"SimpleRNN.png\"/>\n",
    "\n",
    "This allows a \"short term memory\". It creates a kind of hysteresis used as memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(SimpleRNN(units=nb_unit, input_shape=inp_shape, return_sequences=True, activation='softmax'))\n",
    "model2.compile(loss=loss_,\n",
    "              optimizer=optimizer_,\n",
    "              metrics=[metrics_])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"srnn_simple.h5\",\n",
    "    monitor=loss_,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1)\n",
    "early = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 256 samples\n",
      "Epoch 1/250\n",
      "Epoch 00001: categorical_crossentropy improved from inf to 1.21966, saving model to srnn_simple.h5\n",
      " - 1s - loss: 1.2197 - categorical_crossentropy: 1.2197 - val_loss: 1.2300 - val_categorical_crossentropy: 1.2300\n",
      "Epoch 2/250\n",
      "Epoch 00002: categorical_crossentropy improved from 1.21966 to 1.14588, saving model to srnn_simple.h5\n",
      " - 1s - loss: 1.1459 - categorical_crossentropy: 1.1459 - val_loss: 1.1620 - val_categorical_crossentropy: 1.1620\n",
      "Epoch 3/250\n",
      "Epoch 00003: categorical_crossentropy improved from 1.14588 to 1.08776, saving model to srnn_simple.h5\n",
      " - 1s - loss: 1.0878 - categorical_crossentropy: 1.0878 - val_loss: 1.1087 - val_categorical_crossentropy: 1.1087\n",
      "Epoch 4/250\n",
      "Epoch 00004: categorical_crossentropy improved from 1.08776 to 1.04124, saving model to srnn_simple.h5\n",
      " - 1s - loss: 1.0412 - categorical_crossentropy: 1.0412 - val_loss: 1.0644 - val_categorical_crossentropy: 1.0644\n",
      "Epoch 5/250\n",
      "Epoch 00005: categorical_crossentropy improved from 1.04124 to 1.00190, saving model to srnn_simple.h5\n",
      " - 1s - loss: 1.0019 - categorical_crossentropy: 1.0019 - val_loss: 1.0257 - val_categorical_crossentropy: 1.0257\n",
      "Epoch 6/250\n",
      "Epoch 00006: categorical_crossentropy improved from 1.00190 to 0.96723, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.9672 - categorical_crossentropy: 0.9672 - val_loss: 0.9909 - val_categorical_crossentropy: 0.9909\n",
      "Epoch 7/250\n",
      "Epoch 00007: categorical_crossentropy improved from 0.96723 to 0.93580, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.9358 - categorical_crossentropy: 0.9358 - val_loss: 0.9588 - val_categorical_crossentropy: 0.9588\n",
      "Epoch 8/250\n",
      "Epoch 00008: categorical_crossentropy improved from 0.93580 to 0.90673, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.9067 - categorical_crossentropy: 0.9067 - val_loss: 0.9288 - val_categorical_crossentropy: 0.9288\n",
      "Epoch 9/250\n",
      "Epoch 00009: categorical_crossentropy improved from 0.90673 to 0.87950, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.8795 - categorical_crossentropy: 0.8795 - val_loss: 0.9005 - val_categorical_crossentropy: 0.9005\n",
      "Epoch 10/250\n",
      "Epoch 00010: categorical_crossentropy improved from 0.87950 to 0.85371, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.8537 - categorical_crossentropy: 0.8537 - val_loss: 0.8735 - val_categorical_crossentropy: 0.8735\n",
      "Epoch 11/250\n",
      "Epoch 00011: categorical_crossentropy improved from 0.85371 to 0.82920, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.8292 - categorical_crossentropy: 0.8292 - val_loss: 0.8479 - val_categorical_crossentropy: 0.8479\n",
      "Epoch 12/250\n",
      "Epoch 00012: categorical_crossentropy improved from 0.82920 to 0.80588, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.8059 - categorical_crossentropy: 0.8059 - val_loss: 0.8235 - val_categorical_crossentropy: 0.8235\n",
      "Epoch 13/250\n",
      "Epoch 00013: categorical_crossentropy improved from 0.80588 to 0.78370, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.7837 - categorical_crossentropy: 0.7837 - val_loss: 0.8003 - val_categorical_crossentropy: 0.8003\n",
      "Epoch 14/250\n",
      "Epoch 00014: categorical_crossentropy improved from 0.78370 to 0.76267, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.7627 - categorical_crossentropy: 0.7627 - val_loss: 0.7785 - val_categorical_crossentropy: 0.7785\n",
      "Epoch 15/250\n",
      "Epoch 00015: categorical_crossentropy improved from 0.76267 to 0.74275, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.7427 - categorical_crossentropy: 0.7427 - val_loss: 0.7579 - val_categorical_crossentropy: 0.7579\n",
      "Epoch 16/250\n",
      "Epoch 00016: categorical_crossentropy improved from 0.74275 to 0.72399, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.7240 - categorical_crossentropy: 0.7240 - val_loss: 0.7386 - val_categorical_crossentropy: 0.7386\n",
      "Epoch 17/250\n",
      "Epoch 00017: categorical_crossentropy improved from 0.72399 to 0.70631, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.7063 - categorical_crossentropy: 0.7063 - val_loss: 0.7204 - val_categorical_crossentropy: 0.7204\n",
      "Epoch 18/250\n",
      "Epoch 00018: categorical_crossentropy improved from 0.70631 to 0.68969, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.6897 - categorical_crossentropy: 0.6897 - val_loss: 0.7034 - val_categorical_crossentropy: 0.7034\n",
      "Epoch 19/250\n",
      "Epoch 00019: categorical_crossentropy improved from 0.68969 to 0.67408, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.6741 - categorical_crossentropy: 0.6741 - val_loss: 0.6876 - val_categorical_crossentropy: 0.6876\n",
      "Epoch 20/250\n",
      "Epoch 00020: categorical_crossentropy improved from 0.67408 to 0.65940, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.6594 - categorical_crossentropy: 0.6594 - val_loss: 0.6727 - val_categorical_crossentropy: 0.6727\n",
      "Epoch 21/250\n",
      "Epoch 00021: categorical_crossentropy improved from 0.65940 to 0.64560, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.6456 - categorical_crossentropy: 0.6456 - val_loss: 0.6587 - val_categorical_crossentropy: 0.6587\n",
      "Epoch 22/250\n",
      "Epoch 00022: categorical_crossentropy improved from 0.64560 to 0.63256, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.6326 - categorical_crossentropy: 0.6326 - val_loss: 0.6456 - val_categorical_crossentropy: 0.6456\n",
      "Epoch 23/250\n",
      "Epoch 00023: categorical_crossentropy improved from 0.63256 to 0.62024, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.6202 - categorical_crossentropy: 0.6202 - val_loss: 0.6331 - val_categorical_crossentropy: 0.6331\n",
      "Epoch 24/250\n",
      "Epoch 00024: categorical_crossentropy improved from 0.62024 to 0.60851, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.6085 - categorical_crossentropy: 0.6085 - val_loss: 0.6214 - val_categorical_crossentropy: 0.6214\n",
      "Epoch 25/250\n",
      "Epoch 00025: categorical_crossentropy improved from 0.60851 to 0.59737, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5974 - categorical_crossentropy: 0.5974 - val_loss: 0.6102 - val_categorical_crossentropy: 0.6102\n",
      "Epoch 26/250\n",
      "Epoch 00026: categorical_crossentropy improved from 0.59737 to 0.58678, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5868 - categorical_crossentropy: 0.5868 - val_loss: 0.5995 - val_categorical_crossentropy: 0.5995\n",
      "Epoch 27/250\n",
      "Epoch 00027: categorical_crossentropy improved from 0.58678 to 0.57665, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5766 - categorical_crossentropy: 0.5766 - val_loss: 0.5894 - val_categorical_crossentropy: 0.5894\n",
      "Epoch 28/250\n",
      "Epoch 00028: categorical_crossentropy improved from 0.57665 to 0.56701, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5670 - categorical_crossentropy: 0.5670 - val_loss: 0.5797 - val_categorical_crossentropy: 0.5797\n",
      "Epoch 29/250\n",
      "Epoch 00029: categorical_crossentropy improved from 0.56701 to 0.55783, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5578 - categorical_crossentropy: 0.5578 - val_loss: 0.5705 - val_categorical_crossentropy: 0.5705\n",
      "Epoch 30/250\n",
      "Epoch 00030: categorical_crossentropy improved from 0.55783 to 0.54910, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5491 - categorical_crossentropy: 0.5491 - val_loss: 0.5618 - val_categorical_crossentropy: 0.5618\n",
      "Epoch 31/250\n",
      "Epoch 00031: categorical_crossentropy improved from 0.54910 to 0.54083, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5408 - categorical_crossentropy: 0.5408 - val_loss: 0.5536 - val_categorical_crossentropy: 0.5536\n",
      "Epoch 32/250\n",
      "Epoch 00032: categorical_crossentropy improved from 0.54083 to 0.53302, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5330 - categorical_crossentropy: 0.5330 - val_loss: 0.5458 - val_categorical_crossentropy: 0.5458\n",
      "Epoch 33/250\n",
      "Epoch 00033: categorical_crossentropy improved from 0.53302 to 0.52566, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5257 - categorical_crossentropy: 0.5257 - val_loss: 0.5385 - val_categorical_crossentropy: 0.5385\n",
      "Epoch 34/250\n",
      "Epoch 00034: categorical_crossentropy improved from 0.52566 to 0.51872, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5187 - categorical_crossentropy: 0.5187 - val_loss: 0.5316 - val_categorical_crossentropy: 0.5316\n",
      "Epoch 35/250\n",
      "Epoch 00035: categorical_crossentropy improved from 0.51872 to 0.51221, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5122 - categorical_crossentropy: 0.5122 - val_loss: 0.5252 - val_categorical_crossentropy: 0.5252\n",
      "Epoch 36/250\n",
      "Epoch 00036: categorical_crossentropy improved from 0.51221 to 0.50613, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5061 - categorical_crossentropy: 0.5061 - val_loss: 0.5191 - val_categorical_crossentropy: 0.5191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "Epoch 00037: categorical_crossentropy improved from 0.50613 to 0.50040, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.5004 - categorical_crossentropy: 0.5004 - val_loss: 0.5134 - val_categorical_crossentropy: 0.5134\n",
      "Epoch 38/250\n",
      "Epoch 00038: categorical_crossentropy improved from 0.50040 to 0.49502, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4950 - categorical_crossentropy: 0.4950 - val_loss: 0.5081 - val_categorical_crossentropy: 0.5081\n",
      "Epoch 39/250\n",
      "Epoch 00039: categorical_crossentropy improved from 0.49502 to 0.48997, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4900 - categorical_crossentropy: 0.4900 - val_loss: 0.5031 - val_categorical_crossentropy: 0.5031\n",
      "Epoch 40/250\n",
      "Epoch 00040: categorical_crossentropy improved from 0.48997 to 0.48525, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4853 - categorical_crossentropy: 0.4853 - val_loss: 0.4984 - val_categorical_crossentropy: 0.4984\n",
      "Epoch 41/250\n",
      "Epoch 00041: categorical_crossentropy improved from 0.48525 to 0.48080, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4808 - categorical_crossentropy: 0.4808 - val_loss: 0.4939 - val_categorical_crossentropy: 0.4939\n",
      "Epoch 42/250\n",
      "Epoch 00042: categorical_crossentropy improved from 0.48080 to 0.47658, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4766 - categorical_crossentropy: 0.4766 - val_loss: 0.4897 - val_categorical_crossentropy: 0.4897\n",
      "Epoch 43/250\n",
      "Epoch 00043: categorical_crossentropy improved from 0.47658 to 0.47263, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4726 - categorical_crossentropy: 0.4726 - val_loss: 0.4858 - val_categorical_crossentropy: 0.4858\n",
      "Epoch 44/250\n",
      "Epoch 00044: categorical_crossentropy improved from 0.47263 to 0.46888, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4689 - categorical_crossentropy: 0.4689 - val_loss: 0.4820 - val_categorical_crossentropy: 0.4820\n",
      "Epoch 45/250\n",
      "Epoch 00045: categorical_crossentropy improved from 0.46888 to 0.46536, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4654 - categorical_crossentropy: 0.4654 - val_loss: 0.4785 - val_categorical_crossentropy: 0.4785\n",
      "Epoch 46/250\n",
      "Epoch 00046: categorical_crossentropy improved from 0.46536 to 0.46199, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4620 - categorical_crossentropy: 0.4620 - val_loss: 0.4751 - val_categorical_crossentropy: 0.4751\n",
      "Epoch 47/250\n",
      "Epoch 00047: categorical_crossentropy improved from 0.46199 to 0.45883, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4588 - categorical_crossentropy: 0.4588 - val_loss: 0.4720 - val_categorical_crossentropy: 0.4720\n",
      "Epoch 48/250\n",
      "Epoch 00048: categorical_crossentropy improved from 0.45883 to 0.45583, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4558 - categorical_crossentropy: 0.4558 - val_loss: 0.4690 - val_categorical_crossentropy: 0.4690\n",
      "Epoch 49/250\n",
      "Epoch 00049: categorical_crossentropy improved from 0.45583 to 0.45296, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4530 - categorical_crossentropy: 0.4530 - val_loss: 0.4661 - val_categorical_crossentropy: 0.4661\n",
      "Epoch 50/250\n",
      "Epoch 00050: categorical_crossentropy improved from 0.45296 to 0.45023, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4502 - categorical_crossentropy: 0.4502 - val_loss: 0.4634 - val_categorical_crossentropy: 0.4634\n",
      "Epoch 51/250\n",
      "Epoch 00051: categorical_crossentropy improved from 0.45023 to 0.44766, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4477 - categorical_crossentropy: 0.4477 - val_loss: 0.4608 - val_categorical_crossentropy: 0.4608\n",
      "Epoch 52/250\n",
      "Epoch 00052: categorical_crossentropy improved from 0.44766 to 0.44519, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4452 - categorical_crossentropy: 0.4452 - val_loss: 0.4583 - val_categorical_crossentropy: 0.4583\n",
      "Epoch 53/250\n",
      "Epoch 00053: categorical_crossentropy improved from 0.44519 to 0.44283, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4428 - categorical_crossentropy: 0.4428 - val_loss: 0.4560 - val_categorical_crossentropy: 0.4560\n",
      "Epoch 54/250\n",
      "Epoch 00054: categorical_crossentropy improved from 0.44283 to 0.44057, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4406 - categorical_crossentropy: 0.4406 - val_loss: 0.4537 - val_categorical_crossentropy: 0.4537\n",
      "Epoch 55/250\n",
      "Epoch 00055: categorical_crossentropy improved from 0.44057 to 0.43843, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4384 - categorical_crossentropy: 0.4384 - val_loss: 0.4516 - val_categorical_crossentropy: 0.4516\n",
      "Epoch 56/250\n",
      "Epoch 00056: categorical_crossentropy improved from 0.43843 to 0.43638, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4364 - categorical_crossentropy: 0.4364 - val_loss: 0.4496 - val_categorical_crossentropy: 0.4496\n",
      "Epoch 57/250\n",
      "Epoch 00057: categorical_crossentropy improved from 0.43638 to 0.43441, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4344 - categorical_crossentropy: 0.4344 - val_loss: 0.4476 - val_categorical_crossentropy: 0.4476\n",
      "Epoch 58/250\n",
      "Epoch 00058: categorical_crossentropy improved from 0.43441 to 0.43253, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4325 - categorical_crossentropy: 0.4325 - val_loss: 0.4457 - val_categorical_crossentropy: 0.4457\n",
      "Epoch 59/250\n",
      "Epoch 00059: categorical_crossentropy improved from 0.43253 to 0.43071, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4307 - categorical_crossentropy: 0.4307 - val_loss: 0.4439 - val_categorical_crossentropy: 0.4439\n",
      "Epoch 60/250\n",
      "Epoch 00060: categorical_crossentropy improved from 0.43071 to 0.42897, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4290 - categorical_crossentropy: 0.4290 - val_loss: 0.4422 - val_categorical_crossentropy: 0.4422\n",
      "Epoch 61/250\n",
      "Epoch 00061: categorical_crossentropy improved from 0.42897 to 0.42731, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4273 - categorical_crossentropy: 0.4273 - val_loss: 0.4405 - val_categorical_crossentropy: 0.4405\n",
      "Epoch 62/250\n",
      "Epoch 00062: categorical_crossentropy improved from 0.42731 to 0.42571, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4257 - categorical_crossentropy: 0.4257 - val_loss: 0.4389 - val_categorical_crossentropy: 0.4389\n",
      "Epoch 63/250\n",
      "Epoch 00063: categorical_crossentropy improved from 0.42571 to 0.42417, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4242 - categorical_crossentropy: 0.4242 - val_loss: 0.4375 - val_categorical_crossentropy: 0.4375\n",
      "Epoch 64/250\n",
      "Epoch 00064: categorical_crossentropy improved from 0.42417 to 0.42269, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4227 - categorical_crossentropy: 0.4227 - val_loss: 0.4359 - val_categorical_crossentropy: 0.4359\n",
      "Epoch 65/250\n",
      "Epoch 00065: categorical_crossentropy improved from 0.42269 to 0.42128, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4213 - categorical_crossentropy: 0.4213 - val_loss: 0.4345 - val_categorical_crossentropy: 0.4345\n",
      "Epoch 66/250\n",
      "Epoch 00066: categorical_crossentropy improved from 0.42128 to 0.41989, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4199 - categorical_crossentropy: 0.4199 - val_loss: 0.4331 - val_categorical_crossentropy: 0.4331\n",
      "Epoch 67/250\n",
      "Epoch 00067: categorical_crossentropy improved from 0.41989 to 0.41857, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4186 - categorical_crossentropy: 0.4186 - val_loss: 0.4319 - val_categorical_crossentropy: 0.4319\n",
      "Epoch 68/250\n",
      "Epoch 00068: categorical_crossentropy improved from 0.41857 to 0.41728, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4173 - categorical_crossentropy: 0.4173 - val_loss: 0.4305 - val_categorical_crossentropy: 0.4305\n",
      "Epoch 69/250\n",
      "Epoch 00069: categorical_crossentropy improved from 0.41728 to 0.41605, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4160 - categorical_crossentropy: 0.4160 - val_loss: 0.4294 - val_categorical_crossentropy: 0.4294\n",
      "Epoch 70/250\n",
      "Epoch 00070: categorical_crossentropy improved from 0.41605 to 0.41487, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4149 - categorical_crossentropy: 0.4149 - val_loss: 0.4282 - val_categorical_crossentropy: 0.4282\n",
      "Epoch 71/250\n",
      "Epoch 00071: categorical_crossentropy improved from 0.41487 to 0.41369, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4137 - categorical_crossentropy: 0.4137 - val_loss: 0.4270 - val_categorical_crossentropy: 0.4270\n",
      "Epoch 72/250\n",
      "Epoch 00072: categorical_crossentropy improved from 0.41369 to 0.41259, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4126 - categorical_crossentropy: 0.4126 - val_loss: 0.4259 - val_categorical_crossentropy: 0.4259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/250\n",
      "Epoch 00073: categorical_crossentropy improved from 0.41259 to 0.41151, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4115 - categorical_crossentropy: 0.4115 - val_loss: 0.4248 - val_categorical_crossentropy: 0.4248\n",
      "Epoch 74/250\n",
      "Epoch 00074: categorical_crossentropy improved from 0.41151 to 0.41047, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4105 - categorical_crossentropy: 0.4105 - val_loss: 0.4238 - val_categorical_crossentropy: 0.4238\n",
      "Epoch 75/250\n",
      "Epoch 00075: categorical_crossentropy improved from 0.41047 to 0.40947, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4095 - categorical_crossentropy: 0.4095 - val_loss: 0.4228 - val_categorical_crossentropy: 0.4228\n",
      "Epoch 76/250\n",
      "Epoch 00076: categorical_crossentropy improved from 0.40947 to 0.40848, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4085 - categorical_crossentropy: 0.4085 - val_loss: 0.4218 - val_categorical_crossentropy: 0.4218\n",
      "Epoch 77/250\n",
      "Epoch 00077: categorical_crossentropy improved from 0.40848 to 0.40753, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4075 - categorical_crossentropy: 0.4075 - val_loss: 0.4208 - val_categorical_crossentropy: 0.4208\n",
      "Epoch 78/250\n",
      "Epoch 00078: categorical_crossentropy improved from 0.40753 to 0.40661, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4066 - categorical_crossentropy: 0.4066 - val_loss: 0.4199 - val_categorical_crossentropy: 0.4199\n",
      "Epoch 79/250\n",
      "Epoch 00079: categorical_crossentropy improved from 0.40661 to 0.40574, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4057 - categorical_crossentropy: 0.4057 - val_loss: 0.4191 - val_categorical_crossentropy: 0.4191\n",
      "Epoch 80/250\n",
      "Epoch 00080: categorical_crossentropy improved from 0.40574 to 0.40487, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4049 - categorical_crossentropy: 0.4049 - val_loss: 0.4183 - val_categorical_crossentropy: 0.4183\n",
      "Epoch 81/250\n",
      "Epoch 00081: categorical_crossentropy improved from 0.40487 to 0.40404, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4040 - categorical_crossentropy: 0.4040 - val_loss: 0.4174 - val_categorical_crossentropy: 0.4174\n",
      "Epoch 82/250\n",
      "Epoch 00082: categorical_crossentropy improved from 0.40404 to 0.40321, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4032 - categorical_crossentropy: 0.4032 - val_loss: 0.4166 - val_categorical_crossentropy: 0.4166\n",
      "Epoch 83/250\n",
      "Epoch 00083: categorical_crossentropy improved from 0.40321 to 0.40244, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4024 - categorical_crossentropy: 0.4024 - val_loss: 0.4159 - val_categorical_crossentropy: 0.4159\n",
      "Epoch 84/250\n",
      "Epoch 00084: categorical_crossentropy improved from 0.40244 to 0.40166, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4017 - categorical_crossentropy: 0.4017 - val_loss: 0.4151 - val_categorical_crossentropy: 0.4151\n",
      "Epoch 85/250\n",
      "Epoch 00085: categorical_crossentropy improved from 0.40166 to 0.40091, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4009 - categorical_crossentropy: 0.4009 - val_loss: 0.4143 - val_categorical_crossentropy: 0.4143\n",
      "Epoch 86/250\n",
      "Epoch 00086: categorical_crossentropy improved from 0.40091 to 0.40020, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.4002 - categorical_crossentropy: 0.4002 - val_loss: 0.4136 - val_categorical_crossentropy: 0.4136\n",
      "Epoch 87/250\n",
      "Epoch 00087: categorical_crossentropy improved from 0.40020 to 0.39948, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3995 - categorical_crossentropy: 0.3995 - val_loss: 0.4130 - val_categorical_crossentropy: 0.4130\n",
      "Epoch 88/250\n",
      "Epoch 00088: categorical_crossentropy improved from 0.39948 to 0.39879, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3988 - categorical_crossentropy: 0.3988 - val_loss: 0.4124 - val_categorical_crossentropy: 0.4124\n",
      "Epoch 89/250\n",
      "Epoch 00089: categorical_crossentropy improved from 0.39879 to 0.39811, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3981 - categorical_crossentropy: 0.3981 - val_loss: 0.4116 - val_categorical_crossentropy: 0.4116\n",
      "Epoch 90/250\n",
      "Epoch 00090: categorical_crossentropy improved from 0.39811 to 0.39748, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3975 - categorical_crossentropy: 0.3975 - val_loss: 0.4110 - val_categorical_crossentropy: 0.4110\n",
      "Epoch 91/250\n",
      "Epoch 00091: categorical_crossentropy improved from 0.39748 to 0.39685, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3968 - categorical_crossentropy: 0.3968 - val_loss: 0.4104 - val_categorical_crossentropy: 0.4104\n",
      "Epoch 92/250\n",
      "Epoch 00092: categorical_crossentropy improved from 0.39685 to 0.39624, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3962 - categorical_crossentropy: 0.3962 - val_loss: 0.4098 - val_categorical_crossentropy: 0.4098\n",
      "Epoch 93/250\n",
      "Epoch 00093: categorical_crossentropy improved from 0.39624 to 0.39564, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3956 - categorical_crossentropy: 0.3956 - val_loss: 0.4093 - val_categorical_crossentropy: 0.4093\n",
      "Epoch 94/250\n",
      "Epoch 00094: categorical_crossentropy improved from 0.39564 to 0.39504, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3950 - categorical_crossentropy: 0.3950 - val_loss: 0.4087 - val_categorical_crossentropy: 0.4087\n",
      "Epoch 95/250\n",
      "Epoch 00095: categorical_crossentropy improved from 0.39504 to 0.39447, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3945 - categorical_crossentropy: 0.3945 - val_loss: 0.4080 - val_categorical_crossentropy: 0.4080\n",
      "Epoch 96/250\n",
      "Epoch 00096: categorical_crossentropy improved from 0.39447 to 0.39391, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3939 - categorical_crossentropy: 0.3939 - val_loss: 0.4075 - val_categorical_crossentropy: 0.4075\n",
      "Epoch 97/250\n",
      "Epoch 00097: categorical_crossentropy improved from 0.39391 to 0.39335, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3934 - categorical_crossentropy: 0.3934 - val_loss: 0.4070 - val_categorical_crossentropy: 0.4070\n",
      "Epoch 98/250\n",
      "Epoch 00098: categorical_crossentropy improved from 0.39335 to 0.39283, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3928 - categorical_crossentropy: 0.3928 - val_loss: 0.4065 - val_categorical_crossentropy: 0.4065\n",
      "Epoch 99/250\n",
      "Epoch 00099: categorical_crossentropy improved from 0.39283 to 0.39231, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3923 - categorical_crossentropy: 0.3923 - val_loss: 0.4060 - val_categorical_crossentropy: 0.4060\n",
      "Epoch 100/250\n",
      "Epoch 00100: categorical_crossentropy improved from 0.39231 to 0.39183, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3918 - categorical_crossentropy: 0.3918 - val_loss: 0.4055 - val_categorical_crossentropy: 0.4055\n",
      "Epoch 101/250\n",
      "Epoch 00101: categorical_crossentropy improved from 0.39183 to 0.39130, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3913 - categorical_crossentropy: 0.3913 - val_loss: 0.4049 - val_categorical_crossentropy: 0.4049\n",
      "Epoch 102/250\n",
      "Epoch 00102: categorical_crossentropy improved from 0.39130 to 0.39082, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3908 - categorical_crossentropy: 0.3908 - val_loss: 0.4045 - val_categorical_crossentropy: 0.4045\n",
      "Epoch 103/250\n",
      "Epoch 00103: categorical_crossentropy improved from 0.39082 to 0.39036, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3904 - categorical_crossentropy: 0.3904 - val_loss: 0.4041 - val_categorical_crossentropy: 0.4041\n",
      "Epoch 104/250\n",
      "Epoch 00104: categorical_crossentropy improved from 0.39036 to 0.38990, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3899 - categorical_crossentropy: 0.3899 - val_loss: 0.4036 - val_categorical_crossentropy: 0.4036\n",
      "Epoch 105/250\n",
      "Epoch 00105: categorical_crossentropy improved from 0.38990 to 0.38945, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3894 - categorical_crossentropy: 0.3894 - val_loss: 0.4031 - val_categorical_crossentropy: 0.4031\n",
      "Epoch 106/250\n",
      "Epoch 00106: categorical_crossentropy improved from 0.38945 to 0.38901, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3890 - categorical_crossentropy: 0.3890 - val_loss: 0.4028 - val_categorical_crossentropy: 0.4028\n",
      "Epoch 107/250\n",
      "Epoch 00107: categorical_crossentropy improved from 0.38901 to 0.38857, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3886 - categorical_crossentropy: 0.3886 - val_loss: 0.4023 - val_categorical_crossentropy: 0.4023\n",
      "Epoch 108/250\n",
      "Epoch 00108: categorical_crossentropy improved from 0.38857 to 0.38815, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3881 - categorical_crossentropy: 0.3881 - val_loss: 0.4019 - val_categorical_crossentropy: 0.4019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/250\n",
      "Epoch 00109: categorical_crossentropy improved from 0.38815 to 0.38774, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3877 - categorical_crossentropy: 0.3877 - val_loss: 0.4016 - val_categorical_crossentropy: 0.4016\n",
      "Epoch 110/250\n",
      "Epoch 00110: categorical_crossentropy improved from 0.38774 to 0.38733, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3873 - categorical_crossentropy: 0.3873 - val_loss: 0.4011 - val_categorical_crossentropy: 0.4011\n",
      "Epoch 111/250\n",
      "Epoch 00111: categorical_crossentropy improved from 0.38733 to 0.38693, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3869 - categorical_crossentropy: 0.3869 - val_loss: 0.4007 - val_categorical_crossentropy: 0.4007\n",
      "Epoch 112/250\n",
      "Epoch 00112: categorical_crossentropy improved from 0.38693 to 0.38654, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3865 - categorical_crossentropy: 0.3865 - val_loss: 0.4004 - val_categorical_crossentropy: 0.4004\n",
      "Epoch 113/250\n",
      "Epoch 00113: categorical_crossentropy improved from 0.38654 to 0.38617, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3862 - categorical_crossentropy: 0.3862 - val_loss: 0.3999 - val_categorical_crossentropy: 0.3999\n",
      "Epoch 114/250\n",
      "Epoch 00114: categorical_crossentropy improved from 0.38617 to 0.38582, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3858 - categorical_crossentropy: 0.3858 - val_loss: 0.3997 - val_categorical_crossentropy: 0.3997\n",
      "Epoch 115/250\n",
      "Epoch 00115: categorical_crossentropy improved from 0.38582 to 0.38542, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3854 - categorical_crossentropy: 0.3854 - val_loss: 0.3993 - val_categorical_crossentropy: 0.3993\n",
      "Epoch 116/250\n",
      "Epoch 00116: categorical_crossentropy improved from 0.38542 to 0.38508, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3851 - categorical_crossentropy: 0.3851 - val_loss: 0.3989 - val_categorical_crossentropy: 0.3989\n",
      "Epoch 117/250\n",
      "Epoch 00117: categorical_crossentropy improved from 0.38508 to 0.38473, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3847 - categorical_crossentropy: 0.3847 - val_loss: 0.3988 - val_categorical_crossentropy: 0.3988\n",
      "Epoch 118/250\n",
      "Epoch 00118: categorical_crossentropy improved from 0.38473 to 0.38439, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3844 - categorical_crossentropy: 0.3844 - val_loss: 0.3983 - val_categorical_crossentropy: 0.3983\n",
      "Epoch 119/250\n",
      "Epoch 00119: categorical_crossentropy improved from 0.38439 to 0.38404, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3840 - categorical_crossentropy: 0.3840 - val_loss: 0.3979 - val_categorical_crossentropy: 0.3979\n",
      "Epoch 120/250\n",
      "Epoch 00120: categorical_crossentropy improved from 0.38404 to 0.38372, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3837 - categorical_crossentropy: 0.3837 - val_loss: 0.3977 - val_categorical_crossentropy: 0.3977\n",
      "Epoch 121/250\n",
      "Epoch 00121: categorical_crossentropy improved from 0.38372 to 0.38342, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3834 - categorical_crossentropy: 0.3834 - val_loss: 0.3973 - val_categorical_crossentropy: 0.3973\n",
      "Epoch 122/250\n",
      "Epoch 00122: categorical_crossentropy improved from 0.38342 to 0.38308, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3831 - categorical_crossentropy: 0.3831 - val_loss: 0.3970 - val_categorical_crossentropy: 0.3970\n",
      "Epoch 123/250\n",
      "Epoch 00123: categorical_crossentropy improved from 0.38308 to 0.38276, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3828 - categorical_crossentropy: 0.3828 - val_loss: 0.3967 - val_categorical_crossentropy: 0.3967\n",
      "Epoch 124/250\n",
      "Epoch 00124: categorical_crossentropy improved from 0.38276 to 0.38245, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3825 - categorical_crossentropy: 0.3825 - val_loss: 0.3964 - val_categorical_crossentropy: 0.3964\n",
      "Epoch 125/250\n",
      "Epoch 00125: categorical_crossentropy improved from 0.38245 to 0.38215, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3822 - categorical_crossentropy: 0.3822 - val_loss: 0.3961 - val_categorical_crossentropy: 0.3961\n",
      "Epoch 126/250\n",
      "Epoch 00126: categorical_crossentropy improved from 0.38215 to 0.38186, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3819 - categorical_crossentropy: 0.3819 - val_loss: 0.3960 - val_categorical_crossentropy: 0.3960\n",
      "Epoch 127/250\n",
      "Epoch 00127: categorical_crossentropy improved from 0.38186 to 0.38158, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3816 - categorical_crossentropy: 0.3816 - val_loss: 0.3956 - val_categorical_crossentropy: 0.3956\n",
      "Epoch 128/250\n",
      "Epoch 00128: categorical_crossentropy improved from 0.38158 to 0.38126, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3813 - categorical_crossentropy: 0.3813 - val_loss: 0.3954 - val_categorical_crossentropy: 0.3954\n",
      "Epoch 129/250\n",
      "Epoch 00129: categorical_crossentropy improved from 0.38126 to 0.38101, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3810 - categorical_crossentropy: 0.3810 - val_loss: 0.3950 - val_categorical_crossentropy: 0.3950\n",
      "Epoch 130/250\n",
      "Epoch 00130: categorical_crossentropy improved from 0.38101 to 0.38071, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3807 - categorical_crossentropy: 0.3807 - val_loss: 0.3948 - val_categorical_crossentropy: 0.3948\n",
      "Epoch 131/250\n",
      "Epoch 00131: categorical_crossentropy improved from 0.38071 to 0.38045, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3805 - categorical_crossentropy: 0.3805 - val_loss: 0.3945 - val_categorical_crossentropy: 0.3945\n",
      "Epoch 132/250\n",
      "Epoch 00132: categorical_crossentropy improved from 0.38045 to 0.38018, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3802 - categorical_crossentropy: 0.3802 - val_loss: 0.3943 - val_categorical_crossentropy: 0.3943\n",
      "Epoch 133/250\n",
      "Epoch 00133: categorical_crossentropy improved from 0.38018 to 0.37993, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3799 - categorical_crossentropy: 0.3799 - val_loss: 0.3940 - val_categorical_crossentropy: 0.3940\n",
      "Epoch 134/250\n",
      "Epoch 00134: categorical_crossentropy improved from 0.37993 to 0.37964, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3796 - categorical_crossentropy: 0.3796 - val_loss: 0.3937 - val_categorical_crossentropy: 0.3937\n",
      "Epoch 135/250\n",
      "Epoch 00135: categorical_crossentropy improved from 0.37964 to 0.37942, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3794 - categorical_crossentropy: 0.3794 - val_loss: 0.3935 - val_categorical_crossentropy: 0.3935\n",
      "Epoch 136/250\n",
      "Epoch 00136: categorical_crossentropy improved from 0.37942 to 0.37915, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3791 - categorical_crossentropy: 0.3791 - val_loss: 0.3932 - val_categorical_crossentropy: 0.3932\n",
      "Epoch 137/250\n",
      "Epoch 00137: categorical_crossentropy improved from 0.37915 to 0.37890, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3789 - categorical_crossentropy: 0.3789 - val_loss: 0.3930 - val_categorical_crossentropy: 0.3930\n",
      "Epoch 138/250\n",
      "Epoch 00138: categorical_crossentropy improved from 0.37890 to 0.37865, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3787 - categorical_crossentropy: 0.3787 - val_loss: 0.3928 - val_categorical_crossentropy: 0.3928\n",
      "Epoch 139/250\n",
      "Epoch 00139: categorical_crossentropy improved from 0.37865 to 0.37843, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3784 - categorical_crossentropy: 0.3784 - val_loss: 0.3925 - val_categorical_crossentropy: 0.3925\n",
      "Epoch 140/250\n",
      "Epoch 00140: categorical_crossentropy improved from 0.37843 to 0.37819, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3782 - categorical_crossentropy: 0.3782 - val_loss: 0.3924 - val_categorical_crossentropy: 0.3924\n",
      "Epoch 141/250\n",
      "Epoch 00141: categorical_crossentropy improved from 0.37819 to 0.37791, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3779 - categorical_crossentropy: 0.3779 - val_loss: 0.3921 - val_categorical_crossentropy: 0.3921\n",
      "Epoch 142/250\n",
      "Epoch 00142: categorical_crossentropy improved from 0.37791 to 0.37769, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3777 - categorical_crossentropy: 0.3777 - val_loss: 0.3920 - val_categorical_crossentropy: 0.3920\n",
      "Epoch 143/250\n",
      "Epoch 00143: categorical_crossentropy improved from 0.37769 to 0.37744, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3774 - categorical_crossentropy: 0.3774 - val_loss: 0.3915 - val_categorical_crossentropy: 0.3915\n",
      "Epoch 144/250\n",
      "Epoch 00144: categorical_crossentropy improved from 0.37744 to 0.37723, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3772 - categorical_crossentropy: 0.3772 - val_loss: 0.3915 - val_categorical_crossentropy: 0.3915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/250\n",
      "Epoch 00145: categorical_crossentropy improved from 0.37723 to 0.37698, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3770 - categorical_crossentropy: 0.3770 - val_loss: 0.3911 - val_categorical_crossentropy: 0.3911\n",
      "Epoch 146/250\n",
      "Epoch 00146: categorical_crossentropy improved from 0.37698 to 0.37682, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3768 - categorical_crossentropy: 0.3768 - val_loss: 0.3909 - val_categorical_crossentropy: 0.3909\n",
      "Epoch 147/250\n",
      "Epoch 00147: categorical_crossentropy improved from 0.37682 to 0.37656, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3766 - categorical_crossentropy: 0.3766 - val_loss: 0.3909 - val_categorical_crossentropy: 0.3909\n",
      "Epoch 148/250\n",
      "Epoch 00148: categorical_crossentropy improved from 0.37656 to 0.37633, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3763 - categorical_crossentropy: 0.3763 - val_loss: 0.3905 - val_categorical_crossentropy: 0.3905\n",
      "Epoch 149/250\n",
      "Epoch 00149: categorical_crossentropy improved from 0.37633 to 0.37608, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3761 - categorical_crossentropy: 0.3761 - val_loss: 0.3904 - val_categorical_crossentropy: 0.3904\n",
      "Epoch 150/250\n",
      "Epoch 00150: categorical_crossentropy improved from 0.37608 to 0.37586, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3759 - categorical_crossentropy: 0.3759 - val_loss: 0.3901 - val_categorical_crossentropy: 0.3901\n",
      "Epoch 151/250\n",
      "Epoch 00151: categorical_crossentropy improved from 0.37586 to 0.37567, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3757 - categorical_crossentropy: 0.3757 - val_loss: 0.3901 - val_categorical_crossentropy: 0.3901\n",
      "Epoch 152/250\n",
      "Epoch 00152: categorical_crossentropy improved from 0.37567 to 0.37544, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3754 - categorical_crossentropy: 0.3754 - val_loss: 0.3897 - val_categorical_crossentropy: 0.3897\n",
      "Epoch 153/250\n",
      "Epoch 00153: categorical_crossentropy improved from 0.37544 to 0.37519, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3752 - categorical_crossentropy: 0.3752 - val_loss: 0.3894 - val_categorical_crossentropy: 0.3894\n",
      "Epoch 154/250\n",
      "Epoch 00154: categorical_crossentropy improved from 0.37519 to 0.37500, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3750 - categorical_crossentropy: 0.3750 - val_loss: 0.3893 - val_categorical_crossentropy: 0.3893\n",
      "Epoch 155/250\n",
      "Epoch 00155: categorical_crossentropy improved from 0.37500 to 0.37477, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3748 - categorical_crossentropy: 0.3748 - val_loss: 0.3890 - val_categorical_crossentropy: 0.3890\n",
      "Epoch 156/250\n",
      "Epoch 00156: categorical_crossentropy improved from 0.37477 to 0.37455, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3745 - categorical_crossentropy: 0.3745 - val_loss: 0.3888 - val_categorical_crossentropy: 0.3888\n",
      "Epoch 157/250\n",
      "Epoch 00157: categorical_crossentropy improved from 0.37455 to 0.37432, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3743 - categorical_crossentropy: 0.3743 - val_loss: 0.3886 - val_categorical_crossentropy: 0.3886\n",
      "Epoch 158/250\n",
      "Epoch 00158: categorical_crossentropy improved from 0.37432 to 0.37411, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3741 - categorical_crossentropy: 0.3741 - val_loss: 0.3883 - val_categorical_crossentropy: 0.3883\n",
      "Epoch 159/250\n",
      "Epoch 00159: categorical_crossentropy improved from 0.37411 to 0.37383, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3738 - categorical_crossentropy: 0.3738 - val_loss: 0.3880 - val_categorical_crossentropy: 0.3880\n",
      "Epoch 160/250\n",
      "Epoch 00160: categorical_crossentropy improved from 0.37383 to 0.37364, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3736 - categorical_crossentropy: 0.3736 - val_loss: 0.3880 - val_categorical_crossentropy: 0.3880\n",
      "Epoch 161/250\n",
      "Epoch 00161: categorical_crossentropy improved from 0.37364 to 0.37339, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3734 - categorical_crossentropy: 0.3734 - val_loss: 0.3878 - val_categorical_crossentropy: 0.3878\n",
      "Epoch 162/250\n",
      "Epoch 00162: categorical_crossentropy improved from 0.37339 to 0.37316, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3732 - categorical_crossentropy: 0.3732 - val_loss: 0.3874 - val_categorical_crossentropy: 0.3874\n",
      "Epoch 163/250\n",
      "Epoch 00163: categorical_crossentropy improved from 0.37316 to 0.37292, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3729 - categorical_crossentropy: 0.3729 - val_loss: 0.3871 - val_categorical_crossentropy: 0.3871\n",
      "Epoch 164/250\n",
      "Epoch 00164: categorical_crossentropy improved from 0.37292 to 0.37265, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3727 - categorical_crossentropy: 0.3727 - val_loss: 0.3868 - val_categorical_crossentropy: 0.3868\n",
      "Epoch 165/250\n",
      "Epoch 00165: categorical_crossentropy improved from 0.37265 to 0.37244, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3724 - categorical_crossentropy: 0.3724 - val_loss: 0.3866 - val_categorical_crossentropy: 0.3866\n",
      "Epoch 166/250\n",
      "Epoch 00166: categorical_crossentropy improved from 0.37244 to 0.37216, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3722 - categorical_crossentropy: 0.3722 - val_loss: 0.3863 - val_categorical_crossentropy: 0.3863\n",
      "Epoch 167/250\n",
      "Epoch 00167: categorical_crossentropy improved from 0.37216 to 0.37191, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3719 - categorical_crossentropy: 0.3719 - val_loss: 0.3862 - val_categorical_crossentropy: 0.3862\n",
      "Epoch 168/250\n",
      "Epoch 00168: categorical_crossentropy improved from 0.37191 to 0.37167, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3717 - categorical_crossentropy: 0.3717 - val_loss: 0.3858 - val_categorical_crossentropy: 0.3858\n",
      "Epoch 169/250\n",
      "Epoch 00169: categorical_crossentropy improved from 0.37167 to 0.37141, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3714 - categorical_crossentropy: 0.3714 - val_loss: 0.3855 - val_categorical_crossentropy: 0.3855\n",
      "Epoch 170/250\n",
      "Epoch 00170: categorical_crossentropy improved from 0.37141 to 0.37109, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3711 - categorical_crossentropy: 0.3711 - val_loss: 0.3852 - val_categorical_crossentropy: 0.3852\n",
      "Epoch 171/250\n",
      "Epoch 00171: categorical_crossentropy improved from 0.37109 to 0.37085, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3708 - categorical_crossentropy: 0.3708 - val_loss: 0.3850 - val_categorical_crossentropy: 0.3850\n",
      "Epoch 172/250\n",
      "Epoch 00172: categorical_crossentropy improved from 0.37085 to 0.37053, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3705 - categorical_crossentropy: 0.3705 - val_loss: 0.3847 - val_categorical_crossentropy: 0.3847\n",
      "Epoch 173/250\n",
      "Epoch 00173: categorical_crossentropy improved from 0.37053 to 0.37027, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3703 - categorical_crossentropy: 0.3703 - val_loss: 0.3845 - val_categorical_crossentropy: 0.3845\n",
      "Epoch 174/250\n",
      "Epoch 00174: categorical_crossentropy improved from 0.37027 to 0.36999, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3700 - categorical_crossentropy: 0.3700 - val_loss: 0.3841 - val_categorical_crossentropy: 0.3841\n",
      "Epoch 175/250\n",
      "Epoch 00175: categorical_crossentropy improved from 0.36999 to 0.36966, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3697 - categorical_crossentropy: 0.3697 - val_loss: 0.3838 - val_categorical_crossentropy: 0.3838\n",
      "Epoch 176/250\n",
      "Epoch 00176: categorical_crossentropy improved from 0.36966 to 0.36948, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3695 - categorical_crossentropy: 0.3695 - val_loss: 0.3835 - val_categorical_crossentropy: 0.3835\n",
      "Epoch 177/250\n",
      "Epoch 00177: categorical_crossentropy improved from 0.36948 to 0.36913, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3691 - categorical_crossentropy: 0.3691 - val_loss: 0.3834 - val_categorical_crossentropy: 0.3834\n",
      "Epoch 178/250\n",
      "Epoch 00178: categorical_crossentropy improved from 0.36913 to 0.36886, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3689 - categorical_crossentropy: 0.3689 - val_loss: 0.3830 - val_categorical_crossentropy: 0.3830\n",
      "Epoch 179/250\n",
      "Epoch 00179: categorical_crossentropy improved from 0.36886 to 0.36849, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3685 - categorical_crossentropy: 0.3685 - val_loss: 0.3827 - val_categorical_crossentropy: 0.3827\n",
      "Epoch 180/250\n",
      "Epoch 00180: categorical_crossentropy improved from 0.36849 to 0.36828, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3683 - categorical_crossentropy: 0.3683 - val_loss: 0.3823 - val_categorical_crossentropy: 0.3823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/250\n",
      "Epoch 00181: categorical_crossentropy improved from 0.36828 to 0.36803, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3680 - categorical_crossentropy: 0.3680 - val_loss: 0.3821 - val_categorical_crossentropy: 0.3821\n",
      "Epoch 182/250\n",
      "Epoch 00182: categorical_crossentropy improved from 0.36803 to 0.36770, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3677 - categorical_crossentropy: 0.3677 - val_loss: 0.3819 - val_categorical_crossentropy: 0.3819\n",
      "Epoch 183/250\n",
      "Epoch 00183: categorical_crossentropy improved from 0.36770 to 0.36742, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3674 - categorical_crossentropy: 0.3674 - val_loss: 0.3822 - val_categorical_crossentropy: 0.3822\n",
      "Epoch 184/250\n",
      "Epoch 00184: categorical_crossentropy improved from 0.36742 to 0.36720, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3672 - categorical_crossentropy: 0.3672 - val_loss: 0.3813 - val_categorical_crossentropy: 0.3813\n",
      "Epoch 185/250\n",
      "Epoch 00185: categorical_crossentropy improved from 0.36720 to 0.36696, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3670 - categorical_crossentropy: 0.3670 - val_loss: 0.3815 - val_categorical_crossentropy: 0.3815\n",
      "Epoch 186/250\n",
      "Epoch 00186: categorical_crossentropy improved from 0.36696 to 0.36673, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3667 - categorical_crossentropy: 0.3667 - val_loss: 0.3809 - val_categorical_crossentropy: 0.3809\n",
      "Epoch 187/250\n",
      "Epoch 00187: categorical_crossentropy improved from 0.36673 to 0.36641, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3664 - categorical_crossentropy: 0.3664 - val_loss: 0.3807 - val_categorical_crossentropy: 0.3807\n",
      "Epoch 188/250\n",
      "Epoch 00188: categorical_crossentropy improved from 0.36641 to 0.36627, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3663 - categorical_crossentropy: 0.3663 - val_loss: 0.3804 - val_categorical_crossentropy: 0.3804\n",
      "Epoch 189/250\n",
      "Epoch 00189: categorical_crossentropy improved from 0.36627 to 0.36597, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3660 - categorical_crossentropy: 0.3660 - val_loss: 0.3804 - val_categorical_crossentropy: 0.3804\n",
      "Epoch 190/250\n",
      "Epoch 00190: categorical_crossentropy improved from 0.36597 to 0.36581, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3658 - categorical_crossentropy: 0.3658 - val_loss: 0.3798 - val_categorical_crossentropy: 0.3798\n",
      "Epoch 191/250\n",
      "Epoch 00191: categorical_crossentropy improved from 0.36581 to 0.36550, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3655 - categorical_crossentropy: 0.3655 - val_loss: 0.3801 - val_categorical_crossentropy: 0.3801\n",
      "Epoch 192/250\n",
      "Epoch 00192: categorical_crossentropy improved from 0.36550 to 0.36540, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3654 - categorical_crossentropy: 0.3654 - val_loss: 0.3797 - val_categorical_crossentropy: 0.3797\n",
      "Epoch 193/250\n",
      "Epoch 00193: categorical_crossentropy improved from 0.36540 to 0.36513, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3651 - categorical_crossentropy: 0.3651 - val_loss: 0.3795 - val_categorical_crossentropy: 0.3795\n",
      "Epoch 194/250\n",
      "Epoch 00194: categorical_crossentropy improved from 0.36513 to 0.36493, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3649 - categorical_crossentropy: 0.3649 - val_loss: 0.3790 - val_categorical_crossentropy: 0.3790\n",
      "Epoch 195/250\n",
      "Epoch 00195: categorical_crossentropy improved from 0.36493 to 0.36477, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3648 - categorical_crossentropy: 0.3648 - val_loss: 0.3789 - val_categorical_crossentropy: 0.3789\n",
      "Epoch 196/250\n",
      "Epoch 00196: categorical_crossentropy improved from 0.36477 to 0.36458, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3646 - categorical_crossentropy: 0.3646 - val_loss: 0.3786 - val_categorical_crossentropy: 0.3786\n",
      "Epoch 197/250\n",
      "Epoch 00197: categorical_crossentropy improved from 0.36458 to 0.36435, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3644 - categorical_crossentropy: 0.3644 - val_loss: 0.3790 - val_categorical_crossentropy: 0.3790\n",
      "Epoch 198/250\n",
      "Epoch 00198: categorical_crossentropy improved from 0.36435 to 0.36427, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3643 - categorical_crossentropy: 0.3643 - val_loss: 0.3783 - val_categorical_crossentropy: 0.3783\n",
      "Epoch 199/250\n",
      "Epoch 00199: categorical_crossentropy improved from 0.36427 to 0.36410, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3641 - categorical_crossentropy: 0.3641 - val_loss: 0.3796 - val_categorical_crossentropy: 0.3796\n",
      "Epoch 200/250\n",
      "Epoch 00200: categorical_crossentropy improved from 0.36410 to 0.36387, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3639 - categorical_crossentropy: 0.3639 - val_loss: 0.3779 - val_categorical_crossentropy: 0.3779\n",
      "Epoch 201/250\n",
      "Epoch 00201: categorical_crossentropy improved from 0.36387 to 0.36381, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3638 - categorical_crossentropy: 0.3638 - val_loss: 0.3784 - val_categorical_crossentropy: 0.3784\n",
      "Epoch 202/250\n",
      "Epoch 00202: categorical_crossentropy improved from 0.36381 to 0.36352, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3635 - categorical_crossentropy: 0.3635 - val_loss: 0.3787 - val_categorical_crossentropy: 0.3787\n",
      "Epoch 203/250\n",
      "Epoch 00203: categorical_crossentropy improved from 0.36352 to 0.36349, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3635 - categorical_crossentropy: 0.3635 - val_loss: 0.3780 - val_categorical_crossentropy: 0.3780\n",
      "Epoch 204/250\n",
      "Epoch 00204: categorical_crossentropy improved from 0.36349 to 0.36331, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3633 - categorical_crossentropy: 0.3633 - val_loss: 0.3775 - val_categorical_crossentropy: 0.3775\n",
      "Epoch 205/250\n",
      "Epoch 00205: categorical_crossentropy improved from 0.36331 to 0.36318, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3632 - categorical_crossentropy: 0.3632 - val_loss: 0.3774 - val_categorical_crossentropy: 0.3774\n",
      "Epoch 206/250\n",
      "Epoch 00206: categorical_crossentropy improved from 0.36318 to 0.36307, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3631 - categorical_crossentropy: 0.3631 - val_loss: 0.3771 - val_categorical_crossentropy: 0.3771\n",
      "Epoch 207/250\n",
      "Epoch 00207: categorical_crossentropy improved from 0.36307 to 0.36295, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3629 - categorical_crossentropy: 0.3629 - val_loss: 0.3769 - val_categorical_crossentropy: 0.3769\n",
      "Epoch 208/250\n",
      "Epoch 00208: categorical_crossentropy improved from 0.36295 to 0.36280, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3628 - categorical_crossentropy: 0.3628 - val_loss: 0.3769 - val_categorical_crossentropy: 0.3769\n",
      "Epoch 209/250\n",
      "Epoch 00209: categorical_crossentropy improved from 0.36280 to 0.36260, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3626 - categorical_crossentropy: 0.3626 - val_loss: 0.3771 - val_categorical_crossentropy: 0.3771\n",
      "Epoch 210/250\n",
      "Epoch 00210: categorical_crossentropy improved from 0.36260 to 0.36253, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3625 - categorical_crossentropy: 0.3625 - val_loss: 0.3765 - val_categorical_crossentropy: 0.3765\n",
      "Epoch 211/250\n",
      "Epoch 00211: categorical_crossentropy improved from 0.36253 to 0.36248, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3625 - categorical_crossentropy: 0.3625 - val_loss: 0.3764 - val_categorical_crossentropy: 0.3764\n",
      "Epoch 212/250\n",
      "Epoch 00212: categorical_crossentropy improved from 0.36248 to 0.36230, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3623 - categorical_crossentropy: 0.3623 - val_loss: 0.3764 - val_categorical_crossentropy: 0.3764\n",
      "Epoch 213/250\n",
      "Epoch 00213: categorical_crossentropy improved from 0.36230 to 0.36224, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3622 - categorical_crossentropy: 0.3622 - val_loss: 0.3762 - val_categorical_crossentropy: 0.3762\n",
      "Epoch 214/250\n",
      "Epoch 00214: categorical_crossentropy improved from 0.36224 to 0.36212, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3621 - categorical_crossentropy: 0.3621 - val_loss: 0.3761 - val_categorical_crossentropy: 0.3761\n",
      "Epoch 215/250\n",
      "Epoch 00215: categorical_crossentropy improved from 0.36212 to 0.36194, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3619 - categorical_crossentropy: 0.3619 - val_loss: 0.3760 - val_categorical_crossentropy: 0.3760\n",
      "Epoch 216/250\n",
      "Epoch 00216: categorical_crossentropy improved from 0.36194 to 0.36182, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3618 - categorical_crossentropy: 0.3618 - val_loss: 0.3758 - val_categorical_crossentropy: 0.3758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/250\n",
      "Epoch 00217: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.3618 - categorical_crossentropy: 0.3618 - val_loss: 0.3762 - val_categorical_crossentropy: 0.3762\n",
      "Epoch 218/250\n",
      "Epoch 00218: categorical_crossentropy improved from 0.36182 to 0.36171, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3617 - categorical_crossentropy: 0.3617 - val_loss: 0.3756 - val_categorical_crossentropy: 0.3756\n",
      "Epoch 219/250\n",
      "Epoch 00219: categorical_crossentropy improved from 0.36171 to 0.36154, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3615 - categorical_crossentropy: 0.3615 - val_loss: 0.3756 - val_categorical_crossentropy: 0.3756\n",
      "Epoch 220/250\n",
      "Epoch 00220: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.3616 - categorical_crossentropy: 0.3616 - val_loss: 0.3762 - val_categorical_crossentropy: 0.3762\n",
      "Epoch 221/250\n",
      "Epoch 00221: categorical_crossentropy improved from 0.36154 to 0.36140, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3614 - categorical_crossentropy: 0.3614 - val_loss: 0.3756 - val_categorical_crossentropy: 0.3756\n",
      "Epoch 222/250\n",
      "Epoch 00222: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.3614 - categorical_crossentropy: 0.3614 - val_loss: 0.3752 - val_categorical_crossentropy: 0.3752\n",
      "Epoch 223/250\n",
      "Epoch 00223: categorical_crossentropy improved from 0.36140 to 0.36120, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3612 - categorical_crossentropy: 0.3612 - val_loss: 0.3751 - val_categorical_crossentropy: 0.3751\n",
      "Epoch 224/250\n",
      "Epoch 00224: categorical_crossentropy improved from 0.36120 to 0.36115, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3612 - categorical_crossentropy: 0.3612 - val_loss: 0.3752 - val_categorical_crossentropy: 0.3752\n",
      "Epoch 225/250\n",
      "Epoch 00225: categorical_crossentropy improved from 0.36115 to 0.36104, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3610 - categorical_crossentropy: 0.3610 - val_loss: 0.3752 - val_categorical_crossentropy: 0.3752\n",
      "Epoch 226/250\n",
      "Epoch 00226: categorical_crossentropy improved from 0.36104 to 0.36089, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3609 - categorical_crossentropy: 0.3609 - val_loss: 0.3751 - val_categorical_crossentropy: 0.3751\n",
      "Epoch 227/250\n",
      "Epoch 00227: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.3611 - categorical_crossentropy: 0.3611 - val_loss: 0.3748 - val_categorical_crossentropy: 0.3748\n",
      "Epoch 228/250\n",
      "Epoch 00228: categorical_crossentropy improved from 0.36089 to 0.36089, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3609 - categorical_crossentropy: 0.3609 - val_loss: 0.3755 - val_categorical_crossentropy: 0.3755\n",
      "Epoch 229/250\n",
      "Epoch 00229: categorical_crossentropy improved from 0.36089 to 0.36065, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3607 - categorical_crossentropy: 0.3607 - val_loss: 0.3748 - val_categorical_crossentropy: 0.3748\n",
      "Epoch 230/250\n",
      "Epoch 00230: categorical_crossentropy improved from 0.36065 to 0.36062, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3606 - categorical_crossentropy: 0.3606 - val_loss: 0.3746 - val_categorical_crossentropy: 0.3746\n",
      "Epoch 231/250\n",
      "Epoch 00231: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.3606 - categorical_crossentropy: 0.3606 - val_loss: 0.3745 - val_categorical_crossentropy: 0.3745\n",
      "Epoch 232/250\n",
      "Epoch 00232: categorical_crossentropy improved from 0.36062 to 0.36043, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3604 - categorical_crossentropy: 0.3604 - val_loss: 0.3745 - val_categorical_crossentropy: 0.3745\n",
      "Epoch 233/250\n",
      "Epoch 00233: categorical_crossentropy improved from 0.36043 to 0.36039, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3604 - categorical_crossentropy: 0.3604 - val_loss: 0.3743 - val_categorical_crossentropy: 0.3743\n",
      "Epoch 234/250\n",
      "Epoch 00234: categorical_crossentropy improved from 0.36039 to 0.36032, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3603 - categorical_crossentropy: 0.3603 - val_loss: 0.3748 - val_categorical_crossentropy: 0.3748\n",
      "Epoch 235/250\n",
      "Epoch 00235: categorical_crossentropy improved from 0.36032 to 0.36024, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3602 - categorical_crossentropy: 0.3602 - val_loss: 0.3745 - val_categorical_crossentropy: 0.3745\n",
      "Epoch 236/250\n",
      "Epoch 00236: categorical_crossentropy improved from 0.36024 to 0.36017, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3602 - categorical_crossentropy: 0.3602 - val_loss: 0.3744 - val_categorical_crossentropy: 0.3744\n",
      "Epoch 237/250\n",
      "Epoch 00237: categorical_crossentropy improved from 0.36017 to 0.36015, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3602 - categorical_crossentropy: 0.3602 - val_loss: 0.3744 - val_categorical_crossentropy: 0.3744\n",
      "Epoch 238/250\n",
      "Epoch 00238: categorical_crossentropy improved from 0.36015 to 0.36001, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3600 - categorical_crossentropy: 0.3600 - val_loss: 0.3742 - val_categorical_crossentropy: 0.3742\n",
      "Epoch 239/250\n",
      "Epoch 00239: categorical_crossentropy improved from 0.36001 to 0.35999, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3600 - categorical_crossentropy: 0.3600 - val_loss: 0.3739 - val_categorical_crossentropy: 0.3739\n",
      "Epoch 240/250\n",
      "Epoch 00240: categorical_crossentropy improved from 0.35999 to 0.35986, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3599 - categorical_crossentropy: 0.3599 - val_loss: 0.3739 - val_categorical_crossentropy: 0.3739\n",
      "Epoch 241/250\n",
      "Epoch 00241: categorical_crossentropy improved from 0.35986 to 0.35979, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3598 - categorical_crossentropy: 0.3598 - val_loss: 0.3738 - val_categorical_crossentropy: 0.3738\n",
      "Epoch 242/250\n",
      "Epoch 00242: categorical_crossentropy improved from 0.35979 to 0.35976, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3598 - categorical_crossentropy: 0.3598 - val_loss: 0.3742 - val_categorical_crossentropy: 0.3742\n",
      "Epoch 243/250\n",
      "Epoch 00243: categorical_crossentropy improved from 0.35976 to 0.35963, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3596 - categorical_crossentropy: 0.3596 - val_loss: 0.3745 - val_categorical_crossentropy: 0.3745\n",
      "Epoch 244/250\n",
      "Epoch 00244: categorical_crossentropy improved from 0.35963 to 0.35963, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3596 - categorical_crossentropy: 0.3596 - val_loss: 0.3736 - val_categorical_crossentropy: 0.3736\n",
      "Epoch 245/250\n",
      "Epoch 00245: categorical_crossentropy improved from 0.35963 to 0.35960, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3596 - categorical_crossentropy: 0.3596 - val_loss: 0.3738 - val_categorical_crossentropy: 0.3738\n",
      "Epoch 246/250\n",
      "Epoch 00246: categorical_crossentropy improved from 0.35960 to 0.35949, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3595 - categorical_crossentropy: 0.3595 - val_loss: 0.3737 - val_categorical_crossentropy: 0.3737\n",
      "Epoch 247/250\n",
      "Epoch 00247: categorical_crossentropy improved from 0.35949 to 0.35934, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3593 - categorical_crossentropy: 0.3593 - val_loss: 0.3742 - val_categorical_crossentropy: 0.3742\n",
      "Epoch 248/250\n",
      "Epoch 00248: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.3594 - categorical_crossentropy: 0.3594 - val_loss: 0.3735 - val_categorical_crossentropy: 0.3735\n",
      "Epoch 249/250\n",
      "Epoch 00249: categorical_crossentropy improved from 0.35934 to 0.35930, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3593 - categorical_crossentropy: 0.3593 - val_loss: 0.3740 - val_categorical_crossentropy: 0.3740\n",
      "Epoch 250/250\n",
      "Epoch 00250: categorical_crossentropy improved from 0.35930 to 0.35923, saving model to srnn_simple.h5\n",
      " - 1s - loss: 0.3592 - categorical_crossentropy: 0.3592 - val_loss: 0.3733 - val_categorical_crossentropy: 0.3733\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 20, 7)             105       \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None Training time : 181.81644415855408s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history2 = model2.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    callbacks = [checkpoint, early])\n",
    "stop = time.time()\n",
    "t2 = stop-start\n",
    "print(model2.summary(), end=\" \")\n",
    "print(\"Training time : {}s\".format(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SRNN_steps = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "Finally, we can train a <b>GRU</b> (<b>G</b>ated <b>R</b>ecurrent <b>U</b>nits). It's a simplification of LSTMs. They also have a memory mechanism but with less parameters. As a result they are faster to train. You can find differences on <a href=\"https://datascience.stackexchange.com/questions/14581/what-is-difference-between-gru-and-lstm\" target=\"_blank\">this topic</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(GRU(units=nb_unit, input_shape=inp_shape, return_sequences=True, activation='softmax'))\n",
    "model3.compile(loss=loss_,\n",
    "              optimizer=optimizer_,\n",
    "              metrics=[metrics_])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"gru_simple.h5\",\n",
    "    monitor=loss_,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1)\n",
    "early = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 256 samples\n",
      "Epoch 1/250\n",
      "Epoch 00001: categorical_crossentropy improved from inf to 1.22655, saving model to gru_simple.h5\n",
      " - 2s - loss: 1.2266 - categorical_crossentropy: 1.2266 - val_loss: 1.2455 - val_categorical_crossentropy: 1.2455\n",
      "Epoch 2/250\n",
      "Epoch 00002: categorical_crossentropy improved from 1.22655 to 1.16774, saving model to gru_simple.h5\n",
      " - 1s - loss: 1.1677 - categorical_crossentropy: 1.1677 - val_loss: 1.1880 - val_categorical_crossentropy: 1.1880\n",
      "Epoch 3/250\n",
      "Epoch 00003: categorical_crossentropy improved from 1.16774 to 1.11684, saving model to gru_simple.h5\n",
      " - 1s - loss: 1.1168 - categorical_crossentropy: 1.1168 - val_loss: 1.1385 - val_categorical_crossentropy: 1.1385\n",
      "Epoch 4/250\n",
      "Epoch 00004: categorical_crossentropy improved from 1.11684 to 1.07207, saving model to gru_simple.h5\n",
      " - 1s - loss: 1.0721 - categorical_crossentropy: 1.0721 - val_loss: 1.0937 - val_categorical_crossentropy: 1.0937\n",
      "Epoch 5/250\n",
      "Epoch 00005: categorical_crossentropy improved from 1.07207 to 1.03074, saving model to gru_simple.h5\n",
      " - 1s - loss: 1.0307 - categorical_crossentropy: 1.0307 - val_loss: 1.0513 - val_categorical_crossentropy: 1.0513\n",
      "Epoch 6/250\n",
      "Epoch 00006: categorical_crossentropy improved from 1.03074 to 0.99096, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.9910 - categorical_crossentropy: 0.9910 - val_loss: 1.0094 - val_categorical_crossentropy: 1.0094\n",
      "Epoch 7/250\n",
      "Epoch 00007: categorical_crossentropy improved from 0.99096 to 0.95107, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.9511 - categorical_crossentropy: 0.9511 - val_loss: 0.9666 - val_categorical_crossentropy: 0.9666\n",
      "Epoch 8/250\n",
      "Epoch 00008: categorical_crossentropy improved from 0.95107 to 0.90970, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.9097 - categorical_crossentropy: 0.9097 - val_loss: 0.9210 - val_categorical_crossentropy: 0.9210\n",
      "Epoch 9/250\n",
      "Epoch 00009: categorical_crossentropy improved from 0.90970 to 0.86645, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.8665 - categorical_crossentropy: 0.8665 - val_loss: 0.8748 - val_categorical_crossentropy: 0.8748\n",
      "Epoch 10/250\n",
      "Epoch 00010: categorical_crossentropy improved from 0.86645 to 0.82285, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.8228 - categorical_crossentropy: 0.8228 - val_loss: 0.8269 - val_categorical_crossentropy: 0.8269\n",
      "Epoch 11/250\n",
      "Epoch 00011: categorical_crossentropy improved from 0.82285 to 0.77770, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.7777 - categorical_crossentropy: 0.7777 - val_loss: 0.7799 - val_categorical_crossentropy: 0.7799\n",
      "Epoch 12/250\n",
      "Epoch 00012: categorical_crossentropy improved from 0.77770 to 0.73744, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.7374 - categorical_crossentropy: 0.7374 - val_loss: 0.7407 - val_categorical_crossentropy: 0.7407\n",
      "Epoch 13/250\n",
      "Epoch 00013: categorical_crossentropy improved from 0.73744 to 0.70341, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.7034 - categorical_crossentropy: 0.7034 - val_loss: 0.7088 - val_categorical_crossentropy: 0.7088\n",
      "Epoch 14/250\n",
      "Epoch 00014: categorical_crossentropy improved from 0.70341 to 0.67465, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.6747 - categorical_crossentropy: 0.6747 - val_loss: 0.6810 - val_categorical_crossentropy: 0.6810\n",
      "Epoch 15/250\n",
      "Epoch 00015: categorical_crossentropy improved from 0.67465 to 0.64984, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.6498 - categorical_crossentropy: 0.6498 - val_loss: 0.6576 - val_categorical_crossentropy: 0.6576\n",
      "Epoch 16/250\n",
      "Epoch 00016: categorical_crossentropy improved from 0.64984 to 0.62824, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.6282 - categorical_crossentropy: 0.6282 - val_loss: 0.6363 - val_categorical_crossentropy: 0.6363\n",
      "Epoch 17/250\n",
      "Epoch 00017: categorical_crossentropy improved from 0.62824 to 0.60820, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.6082 - categorical_crossentropy: 0.6082 - val_loss: 0.6166 - val_categorical_crossentropy: 0.6166\n",
      "Epoch 18/250\n",
      "Epoch 00018: categorical_crossentropy improved from 0.60820 to 0.58970, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.5897 - categorical_crossentropy: 0.5897 - val_loss: 0.5986 - val_categorical_crossentropy: 0.5986\n",
      "Epoch 19/250\n",
      "Epoch 00019: categorical_crossentropy improved from 0.58970 to 0.57262, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.5726 - categorical_crossentropy: 0.5726 - val_loss: 0.5822 - val_categorical_crossentropy: 0.5822\n",
      "Epoch 20/250\n",
      "Epoch 00020: categorical_crossentropy improved from 0.57262 to 0.55703, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.5570 - categorical_crossentropy: 0.5570 - val_loss: 0.5673 - val_categorical_crossentropy: 0.5673\n",
      "Epoch 21/250\n",
      "Epoch 00021: categorical_crossentropy improved from 0.55703 to 0.54277, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.5428 - categorical_crossentropy: 0.5428 - val_loss: 0.5535 - val_categorical_crossentropy: 0.5535\n",
      "Epoch 22/250\n",
      "Epoch 00022: categorical_crossentropy improved from 0.54277 to 0.52923, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.5292 - categorical_crossentropy: 0.5292 - val_loss: 0.5404 - val_categorical_crossentropy: 0.5404\n",
      "Epoch 23/250\n",
      "Epoch 00023: categorical_crossentropy improved from 0.52923 to 0.51673, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.5167 - categorical_crossentropy: 0.5167 - val_loss: 0.5282 - val_categorical_crossentropy: 0.5282\n",
      "Epoch 24/250\n",
      "Epoch 00024: categorical_crossentropy improved from 0.51673 to 0.50522, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.5052 - categorical_crossentropy: 0.5052 - val_loss: 0.5169 - val_categorical_crossentropy: 0.5169\n",
      "Epoch 25/250\n",
      "Epoch 00025: categorical_crossentropy improved from 0.50522 to 0.49438, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4944 - categorical_crossentropy: 0.4944 - val_loss: 0.5062 - val_categorical_crossentropy: 0.5062\n",
      "Epoch 26/250\n",
      "Epoch 00026: categorical_crossentropy improved from 0.49438 to 0.48422, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4842 - categorical_crossentropy: 0.4842 - val_loss: 0.4963 - val_categorical_crossentropy: 0.4963\n",
      "Epoch 27/250\n",
      "Epoch 00027: categorical_crossentropy improved from 0.48422 to 0.47485, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4749 - categorical_crossentropy: 0.4749 - val_loss: 0.4872 - val_categorical_crossentropy: 0.4872\n",
      "Epoch 28/250\n",
      "Epoch 00028: categorical_crossentropy improved from 0.47485 to 0.46625, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4663 - categorical_crossentropy: 0.4663 - val_loss: 0.4788 - val_categorical_crossentropy: 0.4788\n",
      "Epoch 29/250\n",
      "Epoch 00029: categorical_crossentropy improved from 0.46625 to 0.45836, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4584 - categorical_crossentropy: 0.4584 - val_loss: 0.4711 - val_categorical_crossentropy: 0.4711\n",
      "Epoch 30/250\n",
      "Epoch 00030: categorical_crossentropy improved from 0.45836 to 0.45117, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4512 - categorical_crossentropy: 0.4512 - val_loss: 0.4642 - val_categorical_crossentropy: 0.4642\n",
      "Epoch 31/250\n",
      "Epoch 00031: categorical_crossentropy improved from 0.45117 to 0.44467, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4447 - categorical_crossentropy: 0.4447 - val_loss: 0.4579 - val_categorical_crossentropy: 0.4579\n",
      "Epoch 32/250\n",
      "Epoch 00032: categorical_crossentropy improved from 0.44467 to 0.43883, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4388 - categorical_crossentropy: 0.4388 - val_loss: 0.4522 - val_categorical_crossentropy: 0.4522\n",
      "Epoch 33/250\n",
      "Epoch 00033: categorical_crossentropy improved from 0.43883 to 0.43366, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4337 - categorical_crossentropy: 0.4337 - val_loss: 0.4474 - val_categorical_crossentropy: 0.4474\n",
      "Epoch 34/250\n",
      "Epoch 00034: categorical_crossentropy improved from 0.43366 to 0.42926, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4293 - categorical_crossentropy: 0.4293 - val_loss: 0.4432 - val_categorical_crossentropy: 0.4432\n",
      "Epoch 35/250\n",
      "Epoch 00035: categorical_crossentropy improved from 0.42926 to 0.42535, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4253 - categorical_crossentropy: 0.4253 - val_loss: 0.4395 - val_categorical_crossentropy: 0.4395\n",
      "Epoch 36/250\n",
      "Epoch 00036: categorical_crossentropy improved from 0.42535 to 0.42185, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4218 - categorical_crossentropy: 0.4218 - val_loss: 0.4362 - val_categorical_crossentropy: 0.4362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "Epoch 00037: categorical_crossentropy improved from 0.42185 to 0.41864, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4186 - categorical_crossentropy: 0.4186 - val_loss: 0.4331 - val_categorical_crossentropy: 0.4331\n",
      "Epoch 38/250\n",
      "Epoch 00038: categorical_crossentropy improved from 0.41864 to 0.41571, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4157 - categorical_crossentropy: 0.4157 - val_loss: 0.4304 - val_categorical_crossentropy: 0.4304\n",
      "Epoch 39/250\n",
      "Epoch 00039: categorical_crossentropy improved from 0.41571 to 0.41299, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4130 - categorical_crossentropy: 0.4130 - val_loss: 0.4278 - val_categorical_crossentropy: 0.4278\n",
      "Epoch 40/250\n",
      "Epoch 00040: categorical_crossentropy improved from 0.41299 to 0.41050, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4105 - categorical_crossentropy: 0.4105 - val_loss: 0.4254 - val_categorical_crossentropy: 0.4254\n",
      "Epoch 41/250\n",
      "Epoch 00041: categorical_crossentropy improved from 0.41050 to 0.40823, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4082 - categorical_crossentropy: 0.4082 - val_loss: 0.4232 - val_categorical_crossentropy: 0.4232\n",
      "Epoch 42/250\n",
      "Epoch 00042: categorical_crossentropy improved from 0.40823 to 0.40612, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4061 - categorical_crossentropy: 0.4061 - val_loss: 0.4212 - val_categorical_crossentropy: 0.4212\n",
      "Epoch 43/250\n",
      "Epoch 00043: categorical_crossentropy improved from 0.40612 to 0.40413, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4041 - categorical_crossentropy: 0.4041 - val_loss: 0.4192 - val_categorical_crossentropy: 0.4192\n",
      "Epoch 44/250\n",
      "Epoch 00044: categorical_crossentropy improved from 0.40413 to 0.40227, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4023 - categorical_crossentropy: 0.4023 - val_loss: 0.4174 - val_categorical_crossentropy: 0.4174\n",
      "Epoch 45/250\n",
      "Epoch 00045: categorical_crossentropy improved from 0.40227 to 0.40051, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.4005 - categorical_crossentropy: 0.4005 - val_loss: 0.4157 - val_categorical_crossentropy: 0.4157\n",
      "Epoch 46/250\n",
      "Epoch 00046: categorical_crossentropy improved from 0.40051 to 0.39886, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3989 - categorical_crossentropy: 0.3989 - val_loss: 0.4141 - val_categorical_crossentropy: 0.4141\n",
      "Epoch 47/250\n",
      "Epoch 00047: categorical_crossentropy improved from 0.39886 to 0.39730, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3973 - categorical_crossentropy: 0.3973 - val_loss: 0.4126 - val_categorical_crossentropy: 0.4126\n",
      "Epoch 48/250\n",
      "Epoch 00048: categorical_crossentropy improved from 0.39730 to 0.39582, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3958 - categorical_crossentropy: 0.3958 - val_loss: 0.4112 - val_categorical_crossentropy: 0.4112\n",
      "Epoch 49/250\n",
      "Epoch 00049: categorical_crossentropy improved from 0.39582 to 0.39442, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3944 - categorical_crossentropy: 0.3944 - val_loss: 0.4098 - val_categorical_crossentropy: 0.4098\n",
      "Epoch 50/250\n",
      "Epoch 00050: categorical_crossentropy improved from 0.39442 to 0.39310, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3931 - categorical_crossentropy: 0.3931 - val_loss: 0.4085 - val_categorical_crossentropy: 0.4085\n",
      "Epoch 51/250\n",
      "Epoch 00051: categorical_crossentropy improved from 0.39310 to 0.39185, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3919 - categorical_crossentropy: 0.3919 - val_loss: 0.4073 - val_categorical_crossentropy: 0.4073\n",
      "Epoch 52/250\n",
      "Epoch 00052: categorical_crossentropy improved from 0.39185 to 0.39066, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3907 - categorical_crossentropy: 0.3907 - val_loss: 0.4062 - val_categorical_crossentropy: 0.4062\n",
      "Epoch 53/250\n",
      "Epoch 00053: categorical_crossentropy improved from 0.39066 to 0.38954, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3895 - categorical_crossentropy: 0.3895 - val_loss: 0.4051 - val_categorical_crossentropy: 0.4051\n",
      "Epoch 54/250\n",
      "Epoch 00054: categorical_crossentropy improved from 0.38954 to 0.38849, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3885 - categorical_crossentropy: 0.3885 - val_loss: 0.4040 - val_categorical_crossentropy: 0.4040\n",
      "Epoch 55/250\n",
      "Epoch 00055: categorical_crossentropy improved from 0.38849 to 0.38748, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3875 - categorical_crossentropy: 0.3875 - val_loss: 0.4030 - val_categorical_crossentropy: 0.4030\n",
      "Epoch 56/250\n",
      "Epoch 00056: categorical_crossentropy improved from 0.38748 to 0.38653, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3865 - categorical_crossentropy: 0.3865 - val_loss: 0.4021 - val_categorical_crossentropy: 0.4021\n",
      "Epoch 57/250\n",
      "Epoch 00057: categorical_crossentropy improved from 0.38653 to 0.38564, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3856 - categorical_crossentropy: 0.3856 - val_loss: 0.4011 - val_categorical_crossentropy: 0.4011\n",
      "Epoch 58/250\n",
      "Epoch 00058: categorical_crossentropy improved from 0.38564 to 0.38477, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3848 - categorical_crossentropy: 0.3848 - val_loss: 0.4003 - val_categorical_crossentropy: 0.4003\n",
      "Epoch 59/250\n",
      "Epoch 00059: categorical_crossentropy improved from 0.38477 to 0.38394, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3839 - categorical_crossentropy: 0.3839 - val_loss: 0.3994 - val_categorical_crossentropy: 0.3994\n",
      "Epoch 60/250\n",
      "Epoch 00060: categorical_crossentropy improved from 0.38394 to 0.38314, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3831 - categorical_crossentropy: 0.3831 - val_loss: 0.3986 - val_categorical_crossentropy: 0.3986\n",
      "Epoch 61/250\n",
      "Epoch 00061: categorical_crossentropy improved from 0.38314 to 0.38239, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3824 - categorical_crossentropy: 0.3824 - val_loss: 0.3978 - val_categorical_crossentropy: 0.3978\n",
      "Epoch 62/250\n",
      "Epoch 00062: categorical_crossentropy improved from 0.38239 to 0.38165, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3817 - categorical_crossentropy: 0.3817 - val_loss: 0.3971 - val_categorical_crossentropy: 0.3971\n",
      "Epoch 63/250\n",
      "Epoch 00063: categorical_crossentropy improved from 0.38165 to 0.38094, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3809 - categorical_crossentropy: 0.3809 - val_loss: 0.3964 - val_categorical_crossentropy: 0.3964\n",
      "Epoch 64/250\n",
      "Epoch 00064: categorical_crossentropy improved from 0.38094 to 0.38027, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3803 - categorical_crossentropy: 0.3803 - val_loss: 0.3957 - val_categorical_crossentropy: 0.3957\n",
      "Epoch 65/250\n",
      "Epoch 00065: categorical_crossentropy improved from 0.38027 to 0.37962, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3796 - categorical_crossentropy: 0.3796 - val_loss: 0.3950 - val_categorical_crossentropy: 0.3950\n",
      "Epoch 66/250\n",
      "Epoch 00066: categorical_crossentropy improved from 0.37962 to 0.37897, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3790 - categorical_crossentropy: 0.3790 - val_loss: 0.3944 - val_categorical_crossentropy: 0.3944\n",
      "Epoch 67/250\n",
      "Epoch 00067: categorical_crossentropy improved from 0.37897 to 0.37837, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3784 - categorical_crossentropy: 0.3784 - val_loss: 0.3938 - val_categorical_crossentropy: 0.3938\n",
      "Epoch 68/250\n",
      "Epoch 00068: categorical_crossentropy improved from 0.37837 to 0.37778, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3778 - categorical_crossentropy: 0.3778 - val_loss: 0.3931 - val_categorical_crossentropy: 0.3931\n",
      "Epoch 69/250\n",
      "Epoch 00069: categorical_crossentropy improved from 0.37778 to 0.37721, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3772 - categorical_crossentropy: 0.3772 - val_loss: 0.3926 - val_categorical_crossentropy: 0.3926\n",
      "Epoch 70/250\n",
      "Epoch 00070: categorical_crossentropy improved from 0.37721 to 0.37668, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3767 - categorical_crossentropy: 0.3767 - val_loss: 0.3920 - val_categorical_crossentropy: 0.3920\n",
      "Epoch 71/250\n",
      "Epoch 00071: categorical_crossentropy improved from 0.37668 to 0.37613, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3761 - categorical_crossentropy: 0.3761 - val_loss: 0.3914 - val_categorical_crossentropy: 0.3914\n",
      "Epoch 72/250\n",
      "Epoch 00072: categorical_crossentropy improved from 0.37613 to 0.37562, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3756 - categorical_crossentropy: 0.3756 - val_loss: 0.3909 - val_categorical_crossentropy: 0.3909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/250\n",
      "Epoch 00073: categorical_crossentropy improved from 0.37562 to 0.37512, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3751 - categorical_crossentropy: 0.3751 - val_loss: 0.3904 - val_categorical_crossentropy: 0.3904\n",
      "Epoch 74/250\n",
      "Epoch 00074: categorical_crossentropy improved from 0.37512 to 0.37465, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3746 - categorical_crossentropy: 0.3746 - val_loss: 0.3899 - val_categorical_crossentropy: 0.3899\n",
      "Epoch 75/250\n",
      "Epoch 00075: categorical_crossentropy improved from 0.37465 to 0.37419, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3742 - categorical_crossentropy: 0.3742 - val_loss: 0.3894 - val_categorical_crossentropy: 0.3894\n",
      "Epoch 76/250\n",
      "Epoch 00076: categorical_crossentropy improved from 0.37419 to 0.37375, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3737 - categorical_crossentropy: 0.3737 - val_loss: 0.3890 - val_categorical_crossentropy: 0.3890\n",
      "Epoch 77/250\n",
      "Epoch 00077: categorical_crossentropy improved from 0.37375 to 0.37330, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3733 - categorical_crossentropy: 0.3733 - val_loss: 0.3885 - val_categorical_crossentropy: 0.3885\n",
      "Epoch 78/250\n",
      "Epoch 00078: categorical_crossentropy improved from 0.37330 to 0.37289, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3729 - categorical_crossentropy: 0.3729 - val_loss: 0.3881 - val_categorical_crossentropy: 0.3881\n",
      "Epoch 79/250\n",
      "Epoch 00079: categorical_crossentropy improved from 0.37289 to 0.37248, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3725 - categorical_crossentropy: 0.3725 - val_loss: 0.3877 - val_categorical_crossentropy: 0.3877\n",
      "Epoch 80/250\n",
      "Epoch 00080: categorical_crossentropy improved from 0.37248 to 0.37208, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3721 - categorical_crossentropy: 0.3721 - val_loss: 0.3872 - val_categorical_crossentropy: 0.3872\n",
      "Epoch 81/250\n",
      "Epoch 00081: categorical_crossentropy improved from 0.37208 to 0.37170, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3717 - categorical_crossentropy: 0.3717 - val_loss: 0.3868 - val_categorical_crossentropy: 0.3868\n",
      "Epoch 82/250\n",
      "Epoch 00082: categorical_crossentropy improved from 0.37170 to 0.37132, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3713 - categorical_crossentropy: 0.3713 - val_loss: 0.3865 - val_categorical_crossentropy: 0.3865\n",
      "Epoch 83/250\n",
      "Epoch 00083: categorical_crossentropy improved from 0.37132 to 0.37098, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3710 - categorical_crossentropy: 0.3710 - val_loss: 0.3861 - val_categorical_crossentropy: 0.3861\n",
      "Epoch 84/250\n",
      "Epoch 00084: categorical_crossentropy improved from 0.37098 to 0.37063, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3706 - categorical_crossentropy: 0.3706 - val_loss: 0.3858 - val_categorical_crossentropy: 0.3858\n",
      "Epoch 85/250\n",
      "Epoch 00085: categorical_crossentropy improved from 0.37063 to 0.37030, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3703 - categorical_crossentropy: 0.3703 - val_loss: 0.3854 - val_categorical_crossentropy: 0.3854\n",
      "Epoch 86/250\n",
      "Epoch 00086: categorical_crossentropy improved from 0.37030 to 0.36998, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3700 - categorical_crossentropy: 0.3700 - val_loss: 0.3851 - val_categorical_crossentropy: 0.3851\n",
      "Epoch 87/250\n",
      "Epoch 00087: categorical_crossentropy improved from 0.36998 to 0.36966, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3697 - categorical_crossentropy: 0.3697 - val_loss: 0.3847 - val_categorical_crossentropy: 0.3847\n",
      "Epoch 88/250\n",
      "Epoch 00088: categorical_crossentropy improved from 0.36966 to 0.36937, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3694 - categorical_crossentropy: 0.3694 - val_loss: 0.3844 - val_categorical_crossentropy: 0.3844\n",
      "Epoch 89/250\n",
      "Epoch 00089: categorical_crossentropy improved from 0.36937 to 0.36908, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3691 - categorical_crossentropy: 0.3691 - val_loss: 0.3841 - val_categorical_crossentropy: 0.3841\n",
      "Epoch 90/250\n",
      "Epoch 00090: categorical_crossentropy improved from 0.36908 to 0.36878, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3688 - categorical_crossentropy: 0.3688 - val_loss: 0.3838 - val_categorical_crossentropy: 0.3838\n",
      "Epoch 91/250\n",
      "Epoch 00091: categorical_crossentropy improved from 0.36878 to 0.36850, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3685 - categorical_crossentropy: 0.3685 - val_loss: 0.3836 - val_categorical_crossentropy: 0.3836\n",
      "Epoch 92/250\n",
      "Epoch 00092: categorical_crossentropy improved from 0.36850 to 0.36822, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3682 - categorical_crossentropy: 0.3682 - val_loss: 0.3833 - val_categorical_crossentropy: 0.3833\n",
      "Epoch 93/250\n",
      "Epoch 00093: categorical_crossentropy improved from 0.36822 to 0.36798, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3680 - categorical_crossentropy: 0.3680 - val_loss: 0.3830 - val_categorical_crossentropy: 0.3830\n",
      "Epoch 94/250\n",
      "Epoch 00094: categorical_crossentropy improved from 0.36798 to 0.36771, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3677 - categorical_crossentropy: 0.3677 - val_loss: 0.3827 - val_categorical_crossentropy: 0.3827\n",
      "Epoch 95/250\n",
      "Epoch 00095: categorical_crossentropy improved from 0.36771 to 0.36746, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3675 - categorical_crossentropy: 0.3675 - val_loss: 0.3825 - val_categorical_crossentropy: 0.3825\n",
      "Epoch 96/250\n",
      "Epoch 00096: categorical_crossentropy improved from 0.36746 to 0.36722, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3672 - categorical_crossentropy: 0.3672 - val_loss: 0.3823 - val_categorical_crossentropy: 0.3823\n",
      "Epoch 97/250\n",
      "Epoch 00097: categorical_crossentropy improved from 0.36722 to 0.36699, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3670 - categorical_crossentropy: 0.3670 - val_loss: 0.3820 - val_categorical_crossentropy: 0.3820\n",
      "Epoch 98/250\n",
      "Epoch 00098: categorical_crossentropy improved from 0.36699 to 0.36675, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3667 - categorical_crossentropy: 0.3667 - val_loss: 0.3818 - val_categorical_crossentropy: 0.3818\n",
      "Epoch 99/250\n",
      "Epoch 00099: categorical_crossentropy improved from 0.36675 to 0.36653, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3665 - categorical_crossentropy: 0.3665 - val_loss: 0.3816 - val_categorical_crossentropy: 0.3816\n",
      "Epoch 100/250\n",
      "Epoch 00100: categorical_crossentropy improved from 0.36653 to 0.36631, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3663 - categorical_crossentropy: 0.3663 - val_loss: 0.3813 - val_categorical_crossentropy: 0.3813\n",
      "Epoch 101/250\n",
      "Epoch 00101: categorical_crossentropy improved from 0.36631 to 0.36609, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3661 - categorical_crossentropy: 0.3661 - val_loss: 0.3811 - val_categorical_crossentropy: 0.3811\n",
      "Epoch 102/250\n",
      "Epoch 00102: categorical_crossentropy improved from 0.36609 to 0.36587, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3659 - categorical_crossentropy: 0.3659 - val_loss: 0.3809 - val_categorical_crossentropy: 0.3809\n",
      "Epoch 103/250\n",
      "Epoch 00103: categorical_crossentropy improved from 0.36587 to 0.36568, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3657 - categorical_crossentropy: 0.3657 - val_loss: 0.3807 - val_categorical_crossentropy: 0.3807\n",
      "Epoch 104/250\n",
      "Epoch 00104: categorical_crossentropy improved from 0.36568 to 0.36548, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3655 - categorical_crossentropy: 0.3655 - val_loss: 0.3805 - val_categorical_crossentropy: 0.3805\n",
      "Epoch 105/250\n",
      "Epoch 00105: categorical_crossentropy improved from 0.36548 to 0.36528, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3653 - categorical_crossentropy: 0.3653 - val_loss: 0.3803 - val_categorical_crossentropy: 0.3803\n",
      "Epoch 106/250\n",
      "Epoch 00106: categorical_crossentropy improved from 0.36528 to 0.36510, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3651 - categorical_crossentropy: 0.3651 - val_loss: 0.3802 - val_categorical_crossentropy: 0.3802\n",
      "Epoch 107/250\n",
      "Epoch 00107: categorical_crossentropy improved from 0.36510 to 0.36492, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3649 - categorical_crossentropy: 0.3649 - val_loss: 0.3799 - val_categorical_crossentropy: 0.3799\n",
      "Epoch 108/250\n",
      "Epoch 00108: categorical_crossentropy improved from 0.36492 to 0.36475, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3648 - categorical_crossentropy: 0.3648 - val_loss: 0.3798 - val_categorical_crossentropy: 0.3798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/250\n",
      "Epoch 00109: categorical_crossentropy improved from 0.36475 to 0.36457, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3646 - categorical_crossentropy: 0.3646 - val_loss: 0.3797 - val_categorical_crossentropy: 0.3797\n",
      "Epoch 110/250\n",
      "Epoch 00110: categorical_crossentropy improved from 0.36457 to 0.36440, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3644 - categorical_crossentropy: 0.3644 - val_loss: 0.3795 - val_categorical_crossentropy: 0.3795\n",
      "Epoch 111/250\n",
      "Epoch 00111: categorical_crossentropy improved from 0.36440 to 0.36423, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3642 - categorical_crossentropy: 0.3642 - val_loss: 0.3793 - val_categorical_crossentropy: 0.3793\n",
      "Epoch 112/250\n",
      "Epoch 00112: categorical_crossentropy improved from 0.36423 to 0.36408, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3641 - categorical_crossentropy: 0.3641 - val_loss: 0.3792 - val_categorical_crossentropy: 0.3792\n",
      "Epoch 113/250\n",
      "Epoch 00113: categorical_crossentropy improved from 0.36408 to 0.36393, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3639 - categorical_crossentropy: 0.3639 - val_loss: 0.3791 - val_categorical_crossentropy: 0.3791\n",
      "Epoch 114/250\n",
      "Epoch 00114: categorical_crossentropy improved from 0.36393 to 0.36376, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3638 - categorical_crossentropy: 0.3638 - val_loss: 0.3789 - val_categorical_crossentropy: 0.3789\n",
      "Epoch 115/250\n",
      "Epoch 00115: categorical_crossentropy improved from 0.36376 to 0.36360, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3636 - categorical_crossentropy: 0.3636 - val_loss: 0.3788 - val_categorical_crossentropy: 0.3788\n",
      "Epoch 116/250\n",
      "Epoch 00116: categorical_crossentropy improved from 0.36360 to 0.36347, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3635 - categorical_crossentropy: 0.3635 - val_loss: 0.3786 - val_categorical_crossentropy: 0.3786\n",
      "Epoch 117/250\n",
      "Epoch 00117: categorical_crossentropy improved from 0.36347 to 0.36332, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3633 - categorical_crossentropy: 0.3633 - val_loss: 0.3785 - val_categorical_crossentropy: 0.3785\n",
      "Epoch 118/250\n",
      "Epoch 00118: categorical_crossentropy improved from 0.36332 to 0.36318, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3632 - categorical_crossentropy: 0.3632 - val_loss: 0.3784 - val_categorical_crossentropy: 0.3784\n",
      "Epoch 119/250\n",
      "Epoch 00119: categorical_crossentropy improved from 0.36318 to 0.36304, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3630 - categorical_crossentropy: 0.3630 - val_loss: 0.3783 - val_categorical_crossentropy: 0.3783\n",
      "Epoch 120/250\n",
      "Epoch 00120: categorical_crossentropy improved from 0.36304 to 0.36290, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3629 - categorical_crossentropy: 0.3629 - val_loss: 0.3780 - val_categorical_crossentropy: 0.3780\n",
      "Epoch 121/250\n",
      "Epoch 00121: categorical_crossentropy improved from 0.36290 to 0.36278, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3628 - categorical_crossentropy: 0.3628 - val_loss: 0.3780 - val_categorical_crossentropy: 0.3780\n",
      "Epoch 122/250\n",
      "Epoch 00122: categorical_crossentropy improved from 0.36278 to 0.36264, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3626 - categorical_crossentropy: 0.3626 - val_loss: 0.3779 - val_categorical_crossentropy: 0.3779\n",
      "Epoch 123/250\n",
      "Epoch 00123: categorical_crossentropy improved from 0.36264 to 0.36250, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3625 - categorical_crossentropy: 0.3625 - val_loss: 0.3777 - val_categorical_crossentropy: 0.3777\n",
      "Epoch 124/250\n",
      "Epoch 00124: categorical_crossentropy improved from 0.36250 to 0.36239, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3624 - categorical_crossentropy: 0.3624 - val_loss: 0.3776 - val_categorical_crossentropy: 0.3776\n",
      "Epoch 125/250\n",
      "Epoch 00125: categorical_crossentropy improved from 0.36239 to 0.36225, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3622 - categorical_crossentropy: 0.3622 - val_loss: 0.3776 - val_categorical_crossentropy: 0.3776\n",
      "Epoch 126/250\n",
      "Epoch 00126: categorical_crossentropy improved from 0.36225 to 0.36215, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3621 - categorical_crossentropy: 0.3621 - val_loss: 0.3775 - val_categorical_crossentropy: 0.3775\n",
      "Epoch 127/250\n",
      "Epoch 00127: categorical_crossentropy improved from 0.36215 to 0.36202, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3620 - categorical_crossentropy: 0.3620 - val_loss: 0.3773 - val_categorical_crossentropy: 0.3773\n",
      "Epoch 128/250\n",
      "Epoch 00128: categorical_crossentropy improved from 0.36202 to 0.36188, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3619 - categorical_crossentropy: 0.3619 - val_loss: 0.3772 - val_categorical_crossentropy: 0.3772\n",
      "Epoch 129/250\n",
      "Epoch 00129: categorical_crossentropy improved from 0.36188 to 0.36179, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3618 - categorical_crossentropy: 0.3618 - val_loss: 0.3770 - val_categorical_crossentropy: 0.3770\n",
      "Epoch 130/250\n",
      "Epoch 00130: categorical_crossentropy improved from 0.36179 to 0.36167, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3617 - categorical_crossentropy: 0.3617 - val_loss: 0.3769 - val_categorical_crossentropy: 0.3769\n",
      "Epoch 131/250\n",
      "Epoch 00131: categorical_crossentropy improved from 0.36167 to 0.36153, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3615 - categorical_crossentropy: 0.3615 - val_loss: 0.3768 - val_categorical_crossentropy: 0.3768\n",
      "Epoch 132/250\n",
      "Epoch 00132: categorical_crossentropy improved from 0.36153 to 0.36143, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3614 - categorical_crossentropy: 0.3614 - val_loss: 0.3767 - val_categorical_crossentropy: 0.3767\n",
      "Epoch 133/250\n",
      "Epoch 00133: categorical_crossentropy improved from 0.36143 to 0.36131, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3613 - categorical_crossentropy: 0.3613 - val_loss: 0.3767 - val_categorical_crossentropy: 0.3767\n",
      "Epoch 134/250\n",
      "Epoch 00134: categorical_crossentropy improved from 0.36131 to 0.36120, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3612 - categorical_crossentropy: 0.3612 - val_loss: 0.3765 - val_categorical_crossentropy: 0.3765\n",
      "Epoch 135/250\n",
      "Epoch 00135: categorical_crossentropy improved from 0.36120 to 0.36110, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3611 - categorical_crossentropy: 0.3611 - val_loss: 0.3765 - val_categorical_crossentropy: 0.3765\n",
      "Epoch 136/250\n",
      "Epoch 00136: categorical_crossentropy improved from 0.36110 to 0.36100, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3610 - categorical_crossentropy: 0.3610 - val_loss: 0.3764 - val_categorical_crossentropy: 0.3764\n",
      "Epoch 137/250\n",
      "Epoch 00137: categorical_crossentropy improved from 0.36100 to 0.36087, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3609 - categorical_crossentropy: 0.3609 - val_loss: 0.3763 - val_categorical_crossentropy: 0.3763\n",
      "Epoch 138/250\n",
      "Epoch 00138: categorical_crossentropy improved from 0.36087 to 0.36077, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3608 - categorical_crossentropy: 0.3608 - val_loss: 0.3761 - val_categorical_crossentropy: 0.3761\n",
      "Epoch 139/250\n",
      "Epoch 00139: categorical_crossentropy improved from 0.36077 to 0.36066, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3607 - categorical_crossentropy: 0.3607 - val_loss: 0.3761 - val_categorical_crossentropy: 0.3761\n",
      "Epoch 140/250\n",
      "Epoch 00140: categorical_crossentropy improved from 0.36066 to 0.36057, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3606 - categorical_crossentropy: 0.3606 - val_loss: 0.3760 - val_categorical_crossentropy: 0.3760\n",
      "Epoch 141/250\n",
      "Epoch 00141: categorical_crossentropy improved from 0.36057 to 0.36047, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3605 - categorical_crossentropy: 0.3605 - val_loss: 0.3759 - val_categorical_crossentropy: 0.3759\n",
      "Epoch 142/250\n",
      "Epoch 00142: categorical_crossentropy improved from 0.36047 to 0.36036, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3604 - categorical_crossentropy: 0.3604 - val_loss: 0.3758 - val_categorical_crossentropy: 0.3758\n",
      "Epoch 143/250\n",
      "Epoch 00143: categorical_crossentropy improved from 0.36036 to 0.36027, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3603 - categorical_crossentropy: 0.3603 - val_loss: 0.3757 - val_categorical_crossentropy: 0.3757\n",
      "Epoch 144/250\n",
      "Epoch 00144: categorical_crossentropy improved from 0.36027 to 0.36016, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3602 - categorical_crossentropy: 0.3602 - val_loss: 0.3756 - val_categorical_crossentropy: 0.3756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/250\n",
      "Epoch 00145: categorical_crossentropy improved from 0.36016 to 0.36006, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3601 - categorical_crossentropy: 0.3601 - val_loss: 0.3756 - val_categorical_crossentropy: 0.3756\n",
      "Epoch 146/250\n",
      "Epoch 00146: categorical_crossentropy improved from 0.36006 to 0.35999, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3600 - categorical_crossentropy: 0.3600 - val_loss: 0.3754 - val_categorical_crossentropy: 0.3754\n",
      "Epoch 147/250\n",
      "Epoch 00147: categorical_crossentropy improved from 0.35999 to 0.35988, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3599 - categorical_crossentropy: 0.3599 - val_loss: 0.3754 - val_categorical_crossentropy: 0.3754\n",
      "Epoch 148/250\n",
      "Epoch 00148: categorical_crossentropy improved from 0.35988 to 0.35978, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3598 - categorical_crossentropy: 0.3598 - val_loss: 0.3754 - val_categorical_crossentropy: 0.3754\n",
      "Epoch 149/250\n",
      "Epoch 00149: categorical_crossentropy improved from 0.35978 to 0.35969, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3597 - categorical_crossentropy: 0.3597 - val_loss: 0.3752 - val_categorical_crossentropy: 0.3752\n",
      "Epoch 150/250\n",
      "Epoch 00150: categorical_crossentropy improved from 0.35969 to 0.35959, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3596 - categorical_crossentropy: 0.3596 - val_loss: 0.3752 - val_categorical_crossentropy: 0.3752\n",
      "Epoch 151/250\n",
      "Epoch 00151: categorical_crossentropy improved from 0.35959 to 0.35950, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3595 - categorical_crossentropy: 0.3595 - val_loss: 0.3751 - val_categorical_crossentropy: 0.3751\n",
      "Epoch 152/250\n",
      "Epoch 00152: categorical_crossentropy improved from 0.35950 to 0.35941, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3594 - categorical_crossentropy: 0.3594 - val_loss: 0.3749 - val_categorical_crossentropy: 0.3749\n",
      "Epoch 153/250\n",
      "Epoch 00153: categorical_crossentropy improved from 0.35941 to 0.35933, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3593 - categorical_crossentropy: 0.3593 - val_loss: 0.3750 - val_categorical_crossentropy: 0.3750\n",
      "Epoch 154/250\n",
      "Epoch 00154: categorical_crossentropy improved from 0.35933 to 0.35922, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3592 - categorical_crossentropy: 0.3592 - val_loss: 0.3747 - val_categorical_crossentropy: 0.3747\n",
      "Epoch 155/250\n",
      "Epoch 00155: categorical_crossentropy improved from 0.35922 to 0.35915, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3591 - categorical_crossentropy: 0.3591 - val_loss: 0.3748 - val_categorical_crossentropy: 0.3748\n",
      "Epoch 156/250\n",
      "Epoch 00156: categorical_crossentropy improved from 0.35915 to 0.35905, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3590 - categorical_crossentropy: 0.3590 - val_loss: 0.3746 - val_categorical_crossentropy: 0.3746\n",
      "Epoch 157/250\n",
      "Epoch 00157: categorical_crossentropy improved from 0.35905 to 0.35895, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3589 - categorical_crossentropy: 0.3589 - val_loss: 0.3745 - val_categorical_crossentropy: 0.3745\n",
      "Epoch 158/250\n",
      "Epoch 00158: categorical_crossentropy improved from 0.35895 to 0.35887, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3589 - categorical_crossentropy: 0.3589 - val_loss: 0.3745 - val_categorical_crossentropy: 0.3745\n",
      "Epoch 159/250\n",
      "Epoch 00159: categorical_crossentropy improved from 0.35887 to 0.35878, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3588 - categorical_crossentropy: 0.3588 - val_loss: 0.3744 - val_categorical_crossentropy: 0.3744\n",
      "Epoch 160/250\n",
      "Epoch 00160: categorical_crossentropy improved from 0.35878 to 0.35868, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3587 - categorical_crossentropy: 0.3587 - val_loss: 0.3745 - val_categorical_crossentropy: 0.3745\n",
      "Epoch 161/250\n",
      "Epoch 00161: categorical_crossentropy improved from 0.35868 to 0.35861, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3586 - categorical_crossentropy: 0.3586 - val_loss: 0.3743 - val_categorical_crossentropy: 0.3743\n",
      "Epoch 162/250\n",
      "Epoch 00162: categorical_crossentropy improved from 0.35861 to 0.35851, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3585 - categorical_crossentropy: 0.3585 - val_loss: 0.3743 - val_categorical_crossentropy: 0.3743\n",
      "Epoch 163/250\n",
      "Epoch 00163: categorical_crossentropy improved from 0.35851 to 0.35843, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3584 - categorical_crossentropy: 0.3584 - val_loss: 0.3741 - val_categorical_crossentropy: 0.3741\n",
      "Epoch 164/250\n",
      "Epoch 00164: categorical_crossentropy improved from 0.35843 to 0.35833, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3583 - categorical_crossentropy: 0.3583 - val_loss: 0.3741 - val_categorical_crossentropy: 0.3741\n",
      "Epoch 165/250\n",
      "Epoch 00165: categorical_crossentropy improved from 0.35833 to 0.35826, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3583 - categorical_crossentropy: 0.3583 - val_loss: 0.3741 - val_categorical_crossentropy: 0.3741\n",
      "Epoch 166/250\n",
      "Epoch 00166: categorical_crossentropy improved from 0.35826 to 0.35817, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3582 - categorical_crossentropy: 0.3582 - val_loss: 0.3740 - val_categorical_crossentropy: 0.3740\n",
      "Epoch 167/250\n",
      "Epoch 00167: categorical_crossentropy improved from 0.35817 to 0.35809, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3581 - categorical_crossentropy: 0.3581 - val_loss: 0.3739 - val_categorical_crossentropy: 0.3739\n",
      "Epoch 168/250\n",
      "Epoch 00168: categorical_crossentropy improved from 0.35809 to 0.35799, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3580 - categorical_crossentropy: 0.3580 - val_loss: 0.3738 - val_categorical_crossentropy: 0.3738\n",
      "Epoch 169/250\n",
      "Epoch 00169: categorical_crossentropy improved from 0.35799 to 0.35790, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3579 - categorical_crossentropy: 0.3579 - val_loss: 0.3736 - val_categorical_crossentropy: 0.3736\n",
      "Epoch 170/250\n",
      "Epoch 00170: categorical_crossentropy improved from 0.35790 to 0.35781, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3578 - categorical_crossentropy: 0.3578 - val_loss: 0.3737 - val_categorical_crossentropy: 0.3737\n",
      "Epoch 171/250\n",
      "Epoch 00171: categorical_crossentropy improved from 0.35781 to 0.35773, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3577 - categorical_crossentropy: 0.3577 - val_loss: 0.3735 - val_categorical_crossentropy: 0.3735\n",
      "Epoch 172/250\n",
      "Epoch 00172: categorical_crossentropy improved from 0.35773 to 0.35765, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3576 - categorical_crossentropy: 0.3576 - val_loss: 0.3734 - val_categorical_crossentropy: 0.3734\n",
      "Epoch 173/250\n",
      "Epoch 00173: categorical_crossentropy improved from 0.35765 to 0.35757, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3576 - categorical_crossentropy: 0.3576 - val_loss: 0.3733 - val_categorical_crossentropy: 0.3733\n",
      "Epoch 174/250\n",
      "Epoch 00174: categorical_crossentropy improved from 0.35757 to 0.35747, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3575 - categorical_crossentropy: 0.3575 - val_loss: 0.3734 - val_categorical_crossentropy: 0.3734\n",
      "Epoch 175/250\n",
      "Epoch 00175: categorical_crossentropy improved from 0.35747 to 0.35737, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3574 - categorical_crossentropy: 0.3574 - val_loss: 0.3734 - val_categorical_crossentropy: 0.3734\n",
      "Epoch 176/250\n",
      "Epoch 00176: categorical_crossentropy improved from 0.35737 to 0.35731, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3573 - categorical_crossentropy: 0.3573 - val_loss: 0.3731 - val_categorical_crossentropy: 0.3731\n",
      "Epoch 177/250\n",
      "Epoch 00177: categorical_crossentropy improved from 0.35731 to 0.35720, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3572 - categorical_crossentropy: 0.3572 - val_loss: 0.3730 - val_categorical_crossentropy: 0.3730\n",
      "Epoch 178/250\n",
      "Epoch 00178: categorical_crossentropy improved from 0.35720 to 0.35711, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3571 - categorical_crossentropy: 0.3571 - val_loss: 0.3731 - val_categorical_crossentropy: 0.3731\n",
      "Epoch 179/250\n",
      "Epoch 00179: categorical_crossentropy improved from 0.35711 to 0.35702, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3570 - categorical_crossentropy: 0.3570 - val_loss: 0.3729 - val_categorical_crossentropy: 0.3729\n",
      "Epoch 180/250\n",
      "Epoch 00180: categorical_crossentropy improved from 0.35702 to 0.35693, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3569 - categorical_crossentropy: 0.3569 - val_loss: 0.3729 - val_categorical_crossentropy: 0.3729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/250\n",
      "Epoch 00181: categorical_crossentropy improved from 0.35693 to 0.35684, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3568 - categorical_crossentropy: 0.3568 - val_loss: 0.3727 - val_categorical_crossentropy: 0.3727\n",
      "Epoch 182/250\n",
      "Epoch 00182: categorical_crossentropy improved from 0.35684 to 0.35675, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3567 - categorical_crossentropy: 0.3567 - val_loss: 0.3729 - val_categorical_crossentropy: 0.3729\n",
      "Epoch 183/250\n",
      "Epoch 00183: categorical_crossentropy improved from 0.35675 to 0.35665, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3567 - categorical_crossentropy: 0.3567 - val_loss: 0.3727 - val_categorical_crossentropy: 0.3727\n",
      "Epoch 184/250\n",
      "Epoch 00184: categorical_crossentropy improved from 0.35665 to 0.35659, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3566 - categorical_crossentropy: 0.3566 - val_loss: 0.3727 - val_categorical_crossentropy: 0.3727\n",
      "Epoch 185/250\n",
      "Epoch 00185: categorical_crossentropy improved from 0.35659 to 0.35648, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3565 - categorical_crossentropy: 0.3565 - val_loss: 0.3724 - val_categorical_crossentropy: 0.3724\n",
      "Epoch 186/250\n",
      "Epoch 00186: categorical_crossentropy improved from 0.35648 to 0.35639, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3564 - categorical_crossentropy: 0.3564 - val_loss: 0.3725 - val_categorical_crossentropy: 0.3725\n",
      "Epoch 187/250\n",
      "Epoch 00187: categorical_crossentropy improved from 0.35639 to 0.35629, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3563 - categorical_crossentropy: 0.3563 - val_loss: 0.3723 - val_categorical_crossentropy: 0.3723\n",
      "Epoch 188/250\n",
      "Epoch 00188: categorical_crossentropy improved from 0.35629 to 0.35622, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3562 - categorical_crossentropy: 0.3562 - val_loss: 0.3723 - val_categorical_crossentropy: 0.3723\n",
      "Epoch 189/250\n",
      "Epoch 00189: categorical_crossentropy improved from 0.35622 to 0.35611, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3561 - categorical_crossentropy: 0.3561 - val_loss: 0.3722 - val_categorical_crossentropy: 0.3722\n",
      "Epoch 190/250\n",
      "Epoch 00190: categorical_crossentropy improved from 0.35611 to 0.35601, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3560 - categorical_crossentropy: 0.3560 - val_loss: 0.3723 - val_categorical_crossentropy: 0.3723\n",
      "Epoch 191/250\n",
      "Epoch 00191: categorical_crossentropy improved from 0.35601 to 0.35591, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3559 - categorical_crossentropy: 0.3559 - val_loss: 0.3721 - val_categorical_crossentropy: 0.3721\n",
      "Epoch 192/250\n",
      "Epoch 00192: categorical_crossentropy improved from 0.35591 to 0.35585, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3558 - categorical_crossentropy: 0.3558 - val_loss: 0.3721 - val_categorical_crossentropy: 0.3721\n",
      "Epoch 193/250\n",
      "Epoch 00193: categorical_crossentropy improved from 0.35585 to 0.35572, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3557 - categorical_crossentropy: 0.3557 - val_loss: 0.3723 - val_categorical_crossentropy: 0.3723\n",
      "Epoch 194/250\n",
      "Epoch 00194: categorical_crossentropy improved from 0.35572 to 0.35564, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3556 - categorical_crossentropy: 0.3556 - val_loss: 0.3720 - val_categorical_crossentropy: 0.3720\n",
      "Epoch 195/250\n",
      "Epoch 00195: categorical_crossentropy improved from 0.35564 to 0.35554, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3555 - categorical_crossentropy: 0.3555 - val_loss: 0.3720 - val_categorical_crossentropy: 0.3720\n",
      "Epoch 196/250\n",
      "Epoch 00196: categorical_crossentropy improved from 0.35554 to 0.35546, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3555 - categorical_crossentropy: 0.3555 - val_loss: 0.3719 - val_categorical_crossentropy: 0.3719\n",
      "Epoch 197/250\n",
      "Epoch 00197: categorical_crossentropy improved from 0.35546 to 0.35538, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3554 - categorical_crossentropy: 0.3554 - val_loss: 0.3718 - val_categorical_crossentropy: 0.3718\n",
      "Epoch 198/250\n",
      "Epoch 00198: categorical_crossentropy improved from 0.35538 to 0.35531, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3553 - categorical_crossentropy: 0.3553 - val_loss: 0.3718 - val_categorical_crossentropy: 0.3718\n",
      "Epoch 199/250\n",
      "Epoch 00199: categorical_crossentropy improved from 0.35531 to 0.35522, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3552 - categorical_crossentropy: 0.3552 - val_loss: 0.3717 - val_categorical_crossentropy: 0.3717\n",
      "Epoch 200/250\n",
      "Epoch 00200: categorical_crossentropy improved from 0.35522 to 0.35515, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3551 - categorical_crossentropy: 0.3551 - val_loss: 0.3718 - val_categorical_crossentropy: 0.3718\n",
      "Epoch 201/250\n",
      "Epoch 00201: categorical_crossentropy improved from 0.35515 to 0.35509, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3551 - categorical_crossentropy: 0.3551 - val_loss: 0.3719 - val_categorical_crossentropy: 0.3719\n",
      "Epoch 202/250\n",
      "Epoch 00202: categorical_crossentropy improved from 0.35509 to 0.35500, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3550 - categorical_crossentropy: 0.3550 - val_loss: 0.3717 - val_categorical_crossentropy: 0.3717\n",
      "Epoch 203/250\n",
      "Epoch 00203: categorical_crossentropy improved from 0.35500 to 0.35493, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3549 - categorical_crossentropy: 0.3549 - val_loss: 0.3718 - val_categorical_crossentropy: 0.3718\n",
      "Epoch 204/250\n",
      "Epoch 00204: categorical_crossentropy improved from 0.35493 to 0.35486, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3549 - categorical_crossentropy: 0.3549 - val_loss: 0.3716 - val_categorical_crossentropy: 0.3716\n",
      "Epoch 205/250\n",
      "Epoch 00205: categorical_crossentropy improved from 0.35486 to 0.35483, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3548 - categorical_crossentropy: 0.3548 - val_loss: 0.3717 - val_categorical_crossentropy: 0.3717\n",
      "Epoch 206/250\n",
      "Epoch 00206: categorical_crossentropy improved from 0.35483 to 0.35473, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3547 - categorical_crossentropy: 0.3547 - val_loss: 0.3716 - val_categorical_crossentropy: 0.3716\n",
      "Epoch 207/250\n",
      "Epoch 00207: categorical_crossentropy improved from 0.35473 to 0.35470, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3547 - categorical_crossentropy: 0.3547 - val_loss: 0.3716 - val_categorical_crossentropy: 0.3716\n",
      "Epoch 208/250\n",
      "Epoch 00208: categorical_crossentropy improved from 0.35470 to 0.35462, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3546 - categorical_crossentropy: 0.3546 - val_loss: 0.3717 - val_categorical_crossentropy: 0.3717\n",
      "Epoch 209/250\n",
      "Epoch 00209: categorical_crossentropy improved from 0.35462 to 0.35458, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3546 - categorical_crossentropy: 0.3546 - val_loss: 0.3719 - val_categorical_crossentropy: 0.3719\n",
      "Epoch 210/250\n",
      "Epoch 00210: categorical_crossentropy improved from 0.35458 to 0.35452, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3545 - categorical_crossentropy: 0.3545 - val_loss: 0.3715 - val_categorical_crossentropy: 0.3715\n",
      "Epoch 211/250\n",
      "Epoch 00211: categorical_crossentropy improved from 0.35452 to 0.35446, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3545 - categorical_crossentropy: 0.3545 - val_loss: 0.3718 - val_categorical_crossentropy: 0.3718\n",
      "Epoch 212/250\n",
      "Epoch 00212: categorical_crossentropy improved from 0.35446 to 0.35444, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3544 - categorical_crossentropy: 0.3544 - val_loss: 0.3716 - val_categorical_crossentropy: 0.3716\n",
      "Epoch 213/250\n",
      "Epoch 00213: categorical_crossentropy improved from 0.35444 to 0.35436, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3544 - categorical_crossentropy: 0.3544 - val_loss: 0.3715 - val_categorical_crossentropy: 0.3715\n",
      "Epoch 214/250\n",
      "Epoch 00214: categorical_crossentropy improved from 0.35436 to 0.35430, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3543 - categorical_crossentropy: 0.3543 - val_loss: 0.3714 - val_categorical_crossentropy: 0.3714\n",
      "Epoch 215/250\n",
      "Epoch 00215: categorical_crossentropy improved from 0.35430 to 0.35425, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3542 - categorical_crossentropy: 0.3542 - val_loss: 0.3714 - val_categorical_crossentropy: 0.3714\n",
      "Epoch 216/250\n",
      "Epoch 00216: categorical_crossentropy improved from 0.35425 to 0.35421, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3542 - categorical_crossentropy: 0.3542 - val_loss: 0.3713 - val_categorical_crossentropy: 0.3713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/250\n",
      "Epoch 00217: categorical_crossentropy improved from 0.35421 to 0.35415, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3542 - categorical_crossentropy: 0.3542 - val_loss: 0.3713 - val_categorical_crossentropy: 0.3713\n",
      "Epoch 218/250\n",
      "Epoch 00218: categorical_crossentropy improved from 0.35415 to 0.35414, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3541 - categorical_crossentropy: 0.3541 - val_loss: 0.3713 - val_categorical_crossentropy: 0.3713\n",
      "Epoch 219/250\n",
      "Epoch 00219: categorical_crossentropy improved from 0.35414 to 0.35408, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3541 - categorical_crossentropy: 0.3541 - val_loss: 0.3715 - val_categorical_crossentropy: 0.3715\n",
      "Epoch 220/250\n",
      "Epoch 00220: categorical_crossentropy improved from 0.35408 to 0.35402, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3540 - categorical_crossentropy: 0.3540 - val_loss: 0.3714 - val_categorical_crossentropy: 0.3714\n",
      "Epoch 221/250\n",
      "Epoch 00221: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.3540 - categorical_crossentropy: 0.3540 - val_loss: 0.3712 - val_categorical_crossentropy: 0.3712\n",
      "Epoch 222/250\n",
      "Epoch 00222: categorical_crossentropy improved from 0.35402 to 0.35393, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3539 - categorical_crossentropy: 0.3539 - val_loss: 0.3712 - val_categorical_crossentropy: 0.3712\n",
      "Epoch 223/250\n",
      "Epoch 00223: categorical_crossentropy improved from 0.35393 to 0.35390, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3539 - categorical_crossentropy: 0.3539 - val_loss: 0.3713 - val_categorical_crossentropy: 0.3713\n",
      "Epoch 224/250\n",
      "Epoch 00224: categorical_crossentropy improved from 0.35390 to 0.35384, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3538 - categorical_crossentropy: 0.3538 - val_loss: 0.3714 - val_categorical_crossentropy: 0.3714\n",
      "Epoch 225/250\n",
      "Epoch 00225: categorical_crossentropy improved from 0.35384 to 0.35381, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3538 - categorical_crossentropy: 0.3538 - val_loss: 0.3711 - val_categorical_crossentropy: 0.3711\n",
      "Epoch 226/250\n",
      "Epoch 00226: categorical_crossentropy improved from 0.35381 to 0.35375, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3537 - categorical_crossentropy: 0.3537 - val_loss: 0.3711 - val_categorical_crossentropy: 0.3711\n",
      "Epoch 227/250\n",
      "Epoch 00227: categorical_crossentropy improved from 0.35375 to 0.35372, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3537 - categorical_crossentropy: 0.3537 - val_loss: 0.3710 - val_categorical_crossentropy: 0.3710\n",
      "Epoch 228/250\n",
      "Epoch 00228: categorical_crossentropy improved from 0.35372 to 0.35370, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3537 - categorical_crossentropy: 0.3537 - val_loss: 0.3710 - val_categorical_crossentropy: 0.3710\n",
      "Epoch 229/250\n",
      "Epoch 00229: categorical_crossentropy improved from 0.35370 to 0.35365, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3536 - categorical_crossentropy: 0.3536 - val_loss: 0.3710 - val_categorical_crossentropy: 0.3710\n",
      "Epoch 230/250\n",
      "Epoch 00230: categorical_crossentropy improved from 0.35365 to 0.35361, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3536 - categorical_crossentropy: 0.3536 - val_loss: 0.3713 - val_categorical_crossentropy: 0.3713\n",
      "Epoch 231/250\n",
      "Epoch 00231: categorical_crossentropy improved from 0.35361 to 0.35359, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3536 - categorical_crossentropy: 0.3536 - val_loss: 0.3712 - val_categorical_crossentropy: 0.3712\n",
      "Epoch 232/250\n",
      "Epoch 00232: categorical_crossentropy improved from 0.35359 to 0.35354, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3535 - categorical_crossentropy: 0.3535 - val_loss: 0.3709 - val_categorical_crossentropy: 0.3709\n",
      "Epoch 233/250\n",
      "Epoch 00233: categorical_crossentropy improved from 0.35354 to 0.35349, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3535 - categorical_crossentropy: 0.3535 - val_loss: 0.3709 - val_categorical_crossentropy: 0.3709\n",
      "Epoch 234/250\n",
      "Epoch 00234: categorical_crossentropy did not improve\n",
      " - 1s - loss: 0.3535 - categorical_crossentropy: 0.3535 - val_loss: 0.3709 - val_categorical_crossentropy: 0.3709\n",
      "Epoch 235/250\n",
      "Epoch 00235: categorical_crossentropy improved from 0.35349 to 0.35342, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3534 - categorical_crossentropy: 0.3534 - val_loss: 0.3710 - val_categorical_crossentropy: 0.3710\n",
      "Epoch 236/250\n",
      "Epoch 00236: categorical_crossentropy improved from 0.35342 to 0.35342, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3534 - categorical_crossentropy: 0.3534 - val_loss: 0.3709 - val_categorical_crossentropy: 0.3709\n",
      "Epoch 237/250\n",
      "Epoch 00237: categorical_crossentropy improved from 0.35342 to 0.35337, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3534 - categorical_crossentropy: 0.3534 - val_loss: 0.3710 - val_categorical_crossentropy: 0.3710\n",
      "Epoch 238/250\n",
      "Epoch 00238: categorical_crossentropy improved from 0.35337 to 0.35336, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3534 - categorical_crossentropy: 0.3534 - val_loss: 0.3710 - val_categorical_crossentropy: 0.3710\n",
      "Epoch 239/250\n",
      "Epoch 00239: categorical_crossentropy improved from 0.35336 to 0.35331, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3533 - categorical_crossentropy: 0.3533 - val_loss: 0.3708 - val_categorical_crossentropy: 0.3708\n",
      "Epoch 240/250\n",
      "Epoch 00240: categorical_crossentropy improved from 0.35331 to 0.35328, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3533 - categorical_crossentropy: 0.3533 - val_loss: 0.3707 - val_categorical_crossentropy: 0.3707\n",
      "Epoch 241/250\n",
      "Epoch 00241: categorical_crossentropy improved from 0.35328 to 0.35325, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3532 - categorical_crossentropy: 0.3532 - val_loss: 0.3709 - val_categorical_crossentropy: 0.3709\n",
      "Epoch 242/250\n",
      "Epoch 00242: categorical_crossentropy improved from 0.35325 to 0.35322, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3532 - categorical_crossentropy: 0.3532 - val_loss: 0.3708 - val_categorical_crossentropy: 0.3708\n",
      "Epoch 243/250\n",
      "Epoch 00243: categorical_crossentropy improved from 0.35322 to 0.35320, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3532 - categorical_crossentropy: 0.3532 - val_loss: 0.3706 - val_categorical_crossentropy: 0.3706\n",
      "Epoch 244/250\n",
      "Epoch 00244: categorical_crossentropy improved from 0.35320 to 0.35319, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3532 - categorical_crossentropy: 0.3532 - val_loss: 0.3706 - val_categorical_crossentropy: 0.3706\n",
      "Epoch 245/250\n",
      "Epoch 00245: categorical_crossentropy improved from 0.35319 to 0.35314, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3531 - categorical_crossentropy: 0.3531 - val_loss: 0.3707 - val_categorical_crossentropy: 0.3707\n",
      "Epoch 246/250\n",
      "Epoch 00246: categorical_crossentropy improved from 0.35314 to 0.35310, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3531 - categorical_crossentropy: 0.3531 - val_loss: 0.3706 - val_categorical_crossentropy: 0.3706\n",
      "Epoch 247/250\n",
      "Epoch 00247: categorical_crossentropy improved from 0.35310 to 0.35309, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3531 - categorical_crossentropy: 0.3531 - val_loss: 0.3710 - val_categorical_crossentropy: 0.3710\n",
      "Epoch 248/250\n",
      "Epoch 00248: categorical_crossentropy improved from 0.35309 to 0.35307, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3531 - categorical_crossentropy: 0.3531 - val_loss: 0.3706 - val_categorical_crossentropy: 0.3706\n",
      "Epoch 249/250\n",
      "Epoch 00249: categorical_crossentropy improved from 0.35307 to 0.35303, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3530 - categorical_crossentropy: 0.3530 - val_loss: 0.3706 - val_categorical_crossentropy: 0.3706\n",
      "Epoch 250/250\n",
      "Epoch 00250: categorical_crossentropy improved from 0.35303 to 0.35300, saving model to gru_simple.h5\n",
      " - 1s - loss: 0.3530 - categorical_crossentropy: 0.3530 - val_loss: 0.3707 - val_categorical_crossentropy: 0.3707\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 20, 7)             315       \n",
      "=================================================================\n",
      "Total params: 315\n",
      "Trainable params: 315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None Training time : 330.1214189529419s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history3 = model3.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=nb_epoch, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    callbacks = [checkpoint, early])\n",
    "stop = time.time()\n",
    "t3 = stop-start\n",
    "print(model3.summary(), end=\" \")\n",
    "print(\"Training time : {}s\".format(t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GRU_steps = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We can first check the time used to train them on the same dataset with the same number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM :       164.06s\n",
      "Simple RNN : 181.82s\n",
      "GRU :        330.12s\n"
     ]
    }
   ],
   "source": [
    "print(\"LSTM :       {:.2f}s\".format(t1))\n",
    "print(\"Simple RNN : {:.2f}s\".format(t2))\n",
    "print(\"GRU :        {:.2f}s\".format(t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the simple RNN is the fastest to train because there is nearly no impact of provide the output as input. It's only and addtion to do on Matrices. However, LSTM and GRU are slower to train and as expected, GRU trained faster than LSTM. Ze can also check the error of prediction. For this I used a Mean Absolute Error as loss fonction and Mean Squared Error as metrics . I used this loss fonction to have the norm 1 between prediction and real output. With the Means Squared Error, the training would take longer as the loss would be smaller as all outputs are below 1. For the metric, I used it to ease the visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [90, 250, 250]\n",
      "time [164.06, 181.82, 330.12]\n"
     ]
    }
   ],
   "source": [
    "print(\"epoch\", [LSTM_steps, SRNN_steps, GRU_steps])\n",
    "print(\"time\", [164.06, 181.82, 330.12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu8AAAHfCAYAAADgETZhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKIR4BwCAQvx/oXBdVaqa9hAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x246e6c78080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=[LSTM_steps, SRNN_steps, GRU_steps], y=[\"LSTM\", \"SimpleRNN\", \"GRU\"], label=\"Training Epoch\", color=\"b\")\n",
    "\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=[t1, t2, t3] , y=[\"LSTM\", \"SimpleRNN\", \"GRU\"], label=\"Training time\", color=\"b\")\n",
    "\n",
    "# Add a legend and informative axis label\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(xlim=(0, 350), ylabel=\"\",\n",
    "       xlabel=\"Epochs/Time(s)\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig(\"barplot_softmax.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_categorical_crossentropy', 'loss', 'categorical_crossentropy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAK4CAYAAACLVRDOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJq0nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x246ebb59400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "key_ = list(history.history.keys())[3]\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(history.history[key_], label=\"LSTM\")\n",
    "plt.plot(history2.history[key_], label=\"SimpleRNN\")\n",
    "plt.plot(history3.history[key_], label=\"GRU\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.savefig(\"loss_softmax.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that GRU and LSTM perform better than a Simple RNN. LSTM is also performing slightly better that GRU but require more computation time. We can also check the output and compare it to the real output provided by the graph (see the y description in preparation of data section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :\n",
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 1 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0]\n",
      "  [0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 0 1 0 0 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 1 0 0]\n",
      "  [0 0 0 1 0 0 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0]]]\n",
      "\n",
      "\n",
      "LSTM predicts :\n",
      "[[[ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]\n",
      "  [ nan  nan  nan  nan  nan  nan  nan]]]\n",
      "\n",
      "\n",
      "GRU predicts :\n",
      "[[[ 0.     0.54   0.     0.     0.407  0.     0.   ]\n",
      "  [ 0.     0.005  0.66   0.314  0.     0.     0.001]\n",
      "  [ 0.     0.001  0.032  0.957  0.     0.004  0.   ]\n",
      "  [ 0.     0.628  0.     0.     0.     0.372  0.   ]\n",
      "  [ 0.     0.555  0.     0.     0.     0.372  0.   ]\n",
      "  [ 0.     0.     0.     0.     0.996  0.319  0.   ]\n",
      "  [ 0.     0.     0.167  0.55   0.     0.     0.   ]\n",
      "  [ 0.     0.486  0.     0.002  0.     0.51   0.   ]\n",
      "  [ 0.     0.001  0.     0.     0.992  0.499  0.   ]\n",
      "  [ 0.     0.     0.301  0.55   0.     0.     0.   ]\n",
      "  [ 0.     0.396  0.001  0.007  0.     0.592  0.   ]\n",
      "  [ 0.     0.689  0.     0.     0.     0.592  0.   ]\n",
      "  [ 0.     0.001  0.     0.     0.997  0.592  0.   ]\n",
      "  [ 0.     0.     0.37   0.55   0.     0.     0.   ]\n",
      "  [ 0.     0.327  0.003  0.025  0.     0.599  0.   ]\n",
      "  [ 0.     0.001  0.     0.     0.967  0.599  0.002]\n",
      "  [ 0.     0.     0.     0.     0.     0.002  0.874]\n",
      "  [ 0.004  0.076  0.128  0.337  0.02   0.069  0.378]\n",
      "  [ 0.006  0.379  0.047  0.113  0.029  0.284  0.193]\n",
      "  [ 0.006  0.469  0.001  0.037  0.13   0.295  0.193]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input :\")\n",
    "print(X_val)\n",
    "print(\"\\n\\nLSTM predicts :\")\n",
    "y_pred = model.predict(X_val)\n",
    "print(y_pred)\n",
    "print(\"\\n\\nGRU predicts :\")\n",
    "y_pred = model3.predict(X_val)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply the output by removing small output and compare it to the possible output (we will only keep prediction from GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.where(y_pred < 0.1, 0, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.     0.54   0.     0.     0.407  0.     0.   ] \t [0 1 0 0 1 0 0]\n",
      "[ 0.     0.     0.66   0.314  0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.     0.     0.957  0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.628  0.     0.     0.     0.372  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.555  0.     0.     0.     0.372  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.996  0.319  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.     0.     0.167  0.55   0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.486  0.     0.     0.     0.51   0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.992  0.499  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.     0.     0.301  0.55   0.     0.     0.   ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.396  0.     0.     0.     0.592  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.689  0.     0.     0.     0.592  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.997  0.592  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.    0.    0.37  0.55  0.    0.    0.  ] \t [0 0 1 1 0 0 0]\n",
      "[ 0.     0.327  0.     0.     0.     0.599  0.   ] \t [0 1 0 0 0 1 0]\n",
      "[ 0.     0.     0.     0.     0.967  0.599  0.   ] \t [0 0 0 0 1 1 0]\n",
      "[ 0.     0.     0.     0.     0.     0.     0.874] \t [0 0 0 0 0 0 1]\n",
      "[ 0.     0.     0.128  0.337  0.     0.     0.378] \t [0 0 0 0 0 0 0]\n",
      "[ 0.     0.379  0.     0.113  0.     0.284  0.193] \t [0 0 0 0 0 0 0]\n",
      "[ 0.     0.469  0.     0.     0.13   0.295  0.193] \t [0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for pred, real in zip(y_pred[0], y_possible[0]):\n",
    "    print(pred, \"\\t\", real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah !! Output is balanced between both offset but with different \"probabilities\". We can also check how well they are to generate sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it as generator\n",
    "\n",
    "As explained previously, we trained our model as a many-to-many RNN. Now we want a generator so we are going to use a one-to-many model but reusing knowledge from the training. \n",
    "\n",
    "Before that, we will need an evaluation function which take the output, pick the next input based on the probability to have this output, create the next input and run it until the graph is over. After that, we will check is the created word is really a Reber word. This will be done with following functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pick_From_Output(x):\n",
    "    y = np.zeros_like(x)\n",
    "    x = np.where(x < 0.1, 0, x)\n",
    "    x = x[0]/x[0].sum(axis=1)\n",
    "    i = np.random.choice(list(range(7)), size=1, p=x[0])\n",
    "    y[0,0,i] = 1\n",
    "    return y\n",
    "\n",
    "def evaluate(model, nb_word = 1, max_iter = 50):\n",
    "    good_pred = 0\n",
    "    for _ in range(nb_word):\n",
    "        model.reset_states()\n",
    "        first_input = np.array([[[1,0,0,0,0,0,0]]])\n",
    "        word = \"B\"\n",
    "        loop = 0\n",
    "        nextLetter = \"B\"\n",
    "        next_seq = first_input\n",
    "        while nextLetter != \"E\" and loop < max_iter:\n",
    "            y_pred = model.predict(next_seq)\n",
    "            next_seq = Pick_From_Output(y_pred)\n",
    "            nextLetter = reber.sequenceToWord(next_seq[0])\n",
    "            loop += 1\n",
    "            word += nextLetter\n",
    "        if reber.in_grammar(word):\n",
    "            good_pred += 1\n",
    "    acc = 100*good_pred/nb_word\n",
    "    print(\"Good prediction : {:.2f}%\".format(acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_samples = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create both model as one-to-many and evaluate them 20 times on 100 words generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model = load_model(\"lstm_simple.h5\")  # lstm_simple /  srnn_simple / gru_simple\n",
    "\n",
    "newModel = Sequential()\n",
    "newModel.add(LSTM(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True))\n",
    "newModel.set_weights(Model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good prediction : 90.00%\n",
      "Good prediction : 92.00%\n",
      "Good prediction : 94.00%\n",
      "Good prediction : 95.00%\n",
      "Good prediction : 96.00%\n",
      "Good prediction : 94.00%\n",
      "Good prediction : 95.00%\n",
      "Good prediction : 94.00%\n",
      "Good prediction : 93.00%\n",
      "Good prediction : 98.00%\n",
      "Good prediction : 93.00%\n",
      "Good prediction : 95.00%\n",
      "Good prediction : 92.00%\n",
      "Good prediction : 93.00%\n",
      "Good prediction : 99.00%\n",
      "Good prediction : 94.00%\n",
      "Good prediction : 97.00%\n",
      "Good prediction : 95.00%\n",
      "Good prediction : 96.00%\n",
      "Good prediction : 93.00%\n"
     ]
    }
   ],
   "source": [
    "result_LSTM = []\n",
    "for _ in range(nb_samples):\n",
    "    result_LSTM.append(evaluate(newModel, 100, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model = load_model(\"srnn_simple.h5\")\n",
    "\n",
    "newModel = Sequential()\n",
    "newModel.add(SimpleRNN(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True))\n",
    "newModel.set_weights(Model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good prediction : 11.00%\n",
      "Good prediction : 8.00%\n",
      "Good prediction : 8.00%\n",
      "Good prediction : 12.00%\n",
      "Good prediction : 10.00%\n",
      "Good prediction : 9.00%\n",
      "Good prediction : 10.00%\n",
      "Good prediction : 13.00%\n",
      "Good prediction : 6.00%\n",
      "Good prediction : 7.00%\n",
      "Good prediction : 12.00%\n",
      "Good prediction : 14.00%\n",
      "Good prediction : 8.00%\n",
      "Good prediction : 14.00%\n",
      "Good prediction : 6.00%\n",
      "Good prediction : 16.00%\n",
      "Good prediction : 8.00%\n",
      "Good prediction : 7.00%\n",
      "Good prediction : 12.00%\n",
      "Good prediction : 11.00%\n"
     ]
    }
   ],
   "source": [
    "result_SRNN = []\n",
    "for _ in range(nb_samples):\n",
    "    result_SRNN.append(evaluate(newModel, 100, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model = load_model(\"gru_simple.h5\")\n",
    "\n",
    "newModel = Sequential()\n",
    "newModel.add(GRU(units=7, stateful=True, batch_input_shape=(1,1,7), return_sequences=True))\n",
    "newModel.set_weights(Model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good prediction : 89.00%\n",
      "Good prediction : 87.00%\n",
      "Good prediction : 81.00%\n",
      "Good prediction : 84.00%\n",
      "Good prediction : 82.00%\n",
      "Good prediction : 84.00%\n",
      "Good prediction : 88.00%\n",
      "Good prediction : 86.00%\n",
      "Good prediction : 83.00%\n",
      "Good prediction : 87.00%\n",
      "Good prediction : 76.00%\n",
      "Good prediction : 87.00%\n",
      "Good prediction : 88.00%\n",
      "Good prediction : 77.00%\n",
      "Good prediction : 86.00%\n",
      "Good prediction : 86.00%\n",
      "Good prediction : 86.00%\n",
      "Good prediction : 82.00%\n",
      "Good prediction : 87.00%\n",
      "Good prediction : 87.00%\n"
     ]
    }
   ],
   "source": [
    "result_GRU = []\n",
    "for _ in range(nb_samples):\n",
    "    result_GRU.append(evaluate(newModel, 100, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'LSTM': result_LSTM, 'Simple RNN': result_SRNN, 'GRU' : result_GRU}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18f705c5940>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAD3CAYAAAC6jVe2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f705c26d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=[\"LSTM\", \"Simple RNN\", \"GRU\"], data=df, capsize=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that bost LSTM and GRU outperform the standard RNN. In average LSTM is slightly better than GRU but takes also more time to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu8AAAFyCAYAAABFkzRRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f6ff31160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax = sns.boxplot(x=[result_LSTM, result_SRNN, result_GRU], y=[\"LSTM\", \"SimpleRNN\", \"GRU\"])\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(xlim=(0, 100), ylabel=\"\",\n",
    "       xlabel=\"Accuracy (%)\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig(\"boxplot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0sAAAK4CAYAAAClNWZ1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XdA1fX+x/Hnl733likguHCggpqa\nE7Nc2TCz8mpZdut2W1radmdZ99YvbdnOtrlyb1ERURHBicoUUGTIhnO+vz8QkquZyvge8P34p4Rz\nzvd9vhw45/X9fD7vj6KqqooQQgghhBBCiDqMtC5ACCGEEEIIIQyRhCUhhBBCCCGEuAoJS0IIIYQQ\nQghxFRKWhBBCCCGEEOIqJCwJIYQQQgghxFWYaF3AzYiLi9O6BCGEEEIIcQsIDw/XugShoWYZlkCb\nF25cXJz8wtSDnL/6kfNXf3IO60fOX/3I+asfOX/1I+fv5sgFeiHT8IQQQgghhBDiKiQsCSGEEEII\nIcRVSFgSQgghhBBCiKtotmuWhBBCCCGEEE0jJiaGH374gffee6/2aykpKcyePRudTkdVVRUdOnTg\n+eefZ8mSJWzbto3CwkJycnIICgoC4Msvv6Rdu3aMHTuWN998s/ZxZs2axebNm9m8eXOTP6+/I2FJ\nCCGEEEIIccMWLlzI+PHj6du3L6qq8tRTT7Fp0yYeffRRHn300asGLAcHB2JjY6mqqsLExASdTsfh\nw4c1fBbXJmFJCCGEEEKIZmLJykSi4zMa9DF7d2rFxOHtb/h+Xl5eLFu2DGtra8LCwnj//fcxMbl2\nvDAxMaFHjx5ER0fTr18/du7cSc+ePVm+fPnNlt+oZM2SEEIIIYQQ4oY9++yzdOrUiYULF9KrVy9e\nfvllLl68+Lf3u+uuu/jjjz8AWLVqFcOHD2/sUm+ajCwJIYQQQgjRTEwc3v6mRoEaw549e5gwYQIT\nJkyguLiY+fPn89FHH/HSSy9d837h4eG8+eab5OXlkZ+fT6tWrZqo4hsnI0tCCCGEEEKIG7ZgwQKi\no6MBsLa2JiAgADMzs7+9n6Io9OvXjzfeeINBgwY1dpn1IiNLQgghhBBCiL8VHR3N3XffXfvvBQsW\nMH/+fN59913MzMzw9vbmjTfeuK7HGj58OGPGjOGtt95qpGobhoQlIYQQQgghxDVFRESwd+/eK77+\nxRdfXPM+ERERdb5WMxIVEhJSpwueIbYNB5mGJ4QQQgghhBBXJWFJCCGEEEIIIa5CwpIQQgghhBBC\nXIWEJSGEEEIIIYS4CglLQgghhBBCCHEVEpaEEEIIIYQQ4iokLAkhhBBCCCGu6ZNPPmHChAlMnDiR\nSZMmcfjwYWbPnk1mZuZNP+ZLL73E9u3b//L7Dz30EPfccw8PPfQQDz74IMOHD2fbtm21933qqafq\n3L53794A/PbbbwwYMICioqLa7z377LPExMTccI2yz5IQQgghhBDiL508eZLNmzezdOlSFEXhyJEj\nTJs2jRUrVjT6sefPn09gYCAAp06d4l//+hf9+vUDIC4ujt9//51Ro0Zdcb/S0lLmzJnDnDlz6nX8\nRg1L8fHxvPPOO3zzzTekpKTw0ksvoSgKwcHBvP766xgZGfHhhx+ydetWTExMmD59OmFhYY1ZkhBC\nCCGEEM3WNwd/ZU/a/gZ9zEifrjzUecxfft/JyYnMzEx++eUX+vbtS9u2bfnll1946KGHeOONN/jj\njz9ISUkhLy+PgoICxo0bx/r16zl9+jTz58/HxcWFZ555BldXV7Kzs+nbty/PPvts7eNXVlby+uuv\nk5KSgl6v59///vcVm9kCZGZmYmdnV/vv559/ng8++IDIyEg8PDzq3HbUqFEcOHCALVu20L9//5s+\nN402De/TTz/llVdeoby8HIC5c+fy73//m++//x5VVdm0aROJiYns3buXn3/+mYULF/Lmm282VjlC\nCCGEEEKIm+Dk5MSiRYvYv38/999/P0OHDmXLli11bmNhYcHnn3/OkCFD2LZtG4sXL2by5MmsXr0a\ngIyMDObNm8cvv/zCnj17SExMrL3vzz//jKOjI9999x0fffQRb731Vu33pk2bxtixY+nbty8//fQT\nc+fOrf2em5sbzzzzDDNmzLiiZmNjY+bNm8ecOXPIy8u76efeaCNLvr6+fPDBB0ydOhWAxMREevTo\nAUDfvn2Jjo4mICCA2267DUVR8PLyQqfTceHCBZycnBqrLCGEEEIIIZqthzqPueYoUGNISUnBxsam\nNqgkJCQwefJkXFxcam/Trl07AGxtbQkKCgLA3t6+duAkNDQUBwcHAMLCwjh9+nTtfY8fP05cXByH\nDh0CoKqqqjbg1EzD++GHH1i1ahWenp51ahsxYgQbN27k+++/v6Juf39/Hn74Yd58800URbmp595o\nYSkqKor09PTaf6uqWluktbU1Fy9epKioqPakXf716wlLcXFxDV/0ddDquC2FnL/6kfNXf3IO60fO\nX/3I+asfOX/1I+dP3Kxjx46xdOlSFi9ejLm5OQEBAdja2mJsbFx7m78LI8nJyZSWlmJmZsahQ4cY\nM2YMO3fuBKB169Z4eHjwxBNPUFZWxqJFi7C3t69z/7FjxxIXF8d7773HtGnT6nzvjTfe4L777qO4\nuPiK444fP55NmzZx7Ngxxo4de8PPvckaPBgZ/Tnjr7i4GDs7O2xsbOo8qeLiYmxtba/r8cLDwxu8\nxr8TFxenyXFbCjl/9SPnr/7kHNaPnL/6kfNXP3L+6kfO382RgFltyJAhJCcnc++992JlZYWqqkyd\nOpWvvvrquh/D1NSUZ555hvPnzzN06FBCQ0Nrvzd27FheeeUVxo8fT1FREePGjauTHWrMmDGDESNG\nMHLkyDpfd3Jy4qWXXuKf//znFfdRFIU5c+YwfPjwG3jGf2qysNSuXTtiYmKIiIhg+/btREZG4uvr\ny4IFC5g0aRJZWVno9XqZgieEEEIIIYSBmTJlClOmTKnztUGDBgHw9NNP137tgQceqPP9QYMGkZ6e\njouLC5988kmd+8+bN6/2/99+++0rjvnNN9/U+beDg0Ntq/HL71tzrGPHjgFw99131/mel5fXTQff\nJgtL06ZN49VXX2XhwoW0bt2aqKgojI2N6datG/fffz96vZ7XXnutqcoRQgghhBBCiGtq1LDk7e3N\nTz/9BEBAQADffvvtFbd5+umn66RRIYQQQgghRMtxeSZobhqtdbgQQgghmr/ySh0f/RrP1rg0rUsR\nQogm12TT8IQQQgjRvKiqyn9+OMCOgxms2XWG4rIq7uwdoHVZQgjRZGRkSQghhBBX9cOG4+w4mEGw\njwMOtuYs/u0Qq3ee0rosIYRoMjKyJIQQQogr7DiYwffrjuLmZMXrj0ZSWFzB9EXRLF6WgArcdVtr\nrUsUQohGJ2FJCCGEEHUcT83j/aX7sTQ34bWJEdjbmGNvY86cKb2ZsSiaj5cloKowvI8EJiFuFWlp\naSxYsICsrCwsLCywsLDgxRdfZO3ataxatQo3NzcA8vPzGTZsGFOmTOG3337j1KlTvPDCC7WP8+yz\nzzJ27FgiIiK0eio3RMKSEEIIIWqdzy9l9hcxVOn0vDyhB36edrXf83G3ZfalwPTJ7wmoqIzoE6hh\ntUKIplBaWsqUKVOYOXMmXbp0AeDQoUO89dZb9OjRgwkTJtTur1RRUcGwYcO47777tCy5wUhYEkII\nA6fTqxw+eZ4QP0cszOXPtmg8ZeVVzFwSw4XCciaN6EC3tu5X3MbH3ZY5T1YHpk9/P4yqwsi+EpiE\naCqnv/iK3F27G/QxnXv1JOAfj/zl97ds2UJkZGRtUAIICwvj66+/5sMPP6xz27y8PKqqqjA3N2/Q\nGrUi77pCCGHAdHqV//54gM370gjxdeTNyT2xtjTVuizRAun1KguX7udURgFRkX6M7PvXU+y83f4c\nYfpseXVgGtVPApMQLVV6ejq+vr61/54yZQpFRUXk5OTQrVs3Vq1axerVqzl79izu7u7MmjULGxub\nv3w8RVGaouwGIWFJCCEM1OVBydrSlGOpebz2yS7enNwLGwlMooF9u/YIuxPO0jHQhcdHh/3thxlv\nN1vmPHkb0z+K5vMVhwGVUf2CmqZYIW5hAf945JqjQI3Bw8ODw4cP1/570aJFANx3333odLraaXiH\nDx/mueeew9/fHwALCwsqKirqPFZJSQkWFhZNVnt9SetwIYQwQDq9yn9+2M/mfWm08XXg0+mDGNDN\nh+Op+bz28S6KSiu1LlG0IFvi0vh50wk8Xax56ZHumJpc38eDVq42zH2yN872Fny+IpFlW082cqVC\nCC0MHDiQ3bt3c/DgwdqvpaSkkJWVVefCSocOHXjsscd47rnn0Ov1hIaGsmvXLoqLi4Hq5g8nTpwg\nMLD5jETLyJIQQhgYnV7l/R/2szUuvc7Uu3/d3wVFgU2xabz68S5mTu6JjZWZ1uWKZu7omQv898eD\nWFuY8OrECOysb+w15eVqw5wnezP9o2iWrExEVVXu7h/cSNUKIbRgbW3NokWLePfdd3nnnXeoqqrC\nxMSEmTNncujQoTq3vffee1mzZg1Lly7lwQcfZNy4cYwbNw5ra2uqqqqYMWMG1tbWGj2TGydhSQgh\nDIhOr/L+0v1s3Z9OiJ8jbz725xolYyOFp+/rgoLCxtjU6sD0eC8JTOKm5VwoYfYXe9GrKtMe7o6P\nu+1NPY6XS3VgmvFRNF+sSkJVYcwACUxCtCTe3t689957V3y9X79+V3xtyZIltf9fE5aaK5mGJ4QQ\nBkKn0/Pe99VBKdTPkbeu0syhOjB1ZnAPX06mF/Dqx7soKqn4i0cU4q+VlFUyc0kM+UXlTB7VkS4h\nbvV6vOrAdBsuDpZ8uTqJXzafaKBKhRBCOxKWhBDCAOh0ehYu3c+2A+m09Xfizck9sbK4ehMHIyOF\np+79MzC98vEuLkpgEjdAp1d557s4zpwt5M7eAdzZO6BBHtfTxZq5T/bGxcGSr1Yn8fOm4w3yuFpR\nVZXdCZn8c8Fmnlm4ldXRpymW9YJC3FIkLAkhhMZ0Oj0Lv9/P9gMZtPV34o3HIv8yKNWoCUxDIvxI\nTi/glcUSmMT1+2p1ErFJ2XRu48pjIzs06GN7OFcHJldHS77+4wg/bWyegSnjXBGvf7KbOV/Gknmu\niJSzhSz+7RCPvLWO//xwgKMpF1BVVesyhRCNTNYsCSGEhnQ6Pe9+v58dB68/KNUwMlL45z2dUBRY\ntyeFVxbtYuYTvW54gb64tWyISWHZ1pO0crVh2sPdMTZu+OumHs7WzJnSm+mLovlmzRFUVO4fFNLg\nx2kMZeVV/LjxOL9vO0mVTqVLG1cmj+6ItYUpG2NTWR+TwsbYVDbGpuLvaUdUpB+3h/tIO38hWigJ\nS0IIoRGdTs8738WxMz6TdgFOvP7o9QelGkZGCk+O6YSiKKzdfYZXF0tgEn/tcPJ5Pvo1HhtLU157\nNKJRP+DXBKYZi6L5ds1RUOH+wYYbmFRVJfpQJp8vP8z5gjJcHS15dEQHenb0rG2NfO/ANozpH8yh\nk+dYuyeFPQln+XhZAl+sTOS2zq2IivSjrb9Ts9pwUwhxbRKWhBBCA1WXglJ0fCbtWzvz+qORWJrf\n3J9kIyOFKXeHoQBrdp/hlcXRzHy8F/Y25g1as2jezp4vZs6XsagqTJ/QAy8Xm0Y/poezdfXGtYui\n+XbtUfQqPDDE8AJTWvZFPl52iPgT5zExNuL+QW24Z2AwFmZX/k4aGSl0buNG5zZu5F0sY3NsGuti\nUti8L43N+9LwcbdlaKQf/bv5YCudKoVo9iQsCSFEE6vS6Xnn2ziiD9U/KNUwMlJ44u4wUGDNrjO8\nsngXs56QwCSqFZdWMnPJHi6WVPDUvZ3pGOTSZMd2d7Ji7pTevLwomu/XHQVV5YGo0CY7/rWUlFXy\nw4bjrNiejE6v0q2tO4+N6nDdQdLR1oIxA4IZfXsQCcnnWbcnhd0JmXy6/DBfrk6idycvhkb60y5A\nRpuEaK4kLAlxDcWllSRn5HMyrYDcwlIi23vSIdBZ3vTETavS6Vnw7T52HTpLh0BnXptU/6BU4/IR\npj8kMIlLdDo9b3+zj7TsIkb2DSQq0q/Ja3C7FJimL4rm+/XHUIFxGgYmVVXZfiCDJSsTuVBYhpuT\nFZNHdqBHe4+b+vtuZKTQKdiVTsGuFBSVs3lfGuv2nGFrXDpb49LxdrMhKtKfAd18ms0UWb1e5Wxu\nMSfT8jmdWYCHszWDe/g2yho3IQyZhCUhLikqqSA5vYCT6fkkZ1T/9+z54jq3WbH9FK1crRkS4c/A\n7j7yIVTckKpLH1p3J5ylY6ALr02KwKKBglINRakeYVIUhdXRpyUwCT5fmcj+Yzl0a+vOP4a316wO\nNycr5jzZm+kfRbN0/TFUFcZFhTT5xaeUs4UsXnaIw8m5mJoY8cCQEMYMCMbc1LhBHt/expzRtwcx\nql8gh0/lsm53SvVaqBWH+Wp1Er3CPBka6W9QF970epXM80WcTC8gOT2fk+n5nMoooKSsqs7tVkef\n5vHRHekQ2HQjk0JoTcKSuCVdLKm49IZwKRyl55OVW1LnNjaWpnQOdiXQ254gHwesLUzZEpfGzvhM\nvliVyDdrkujZ0YuoSD86BrpgZGQYb3rCMFVWVY8o7U44S1iQC69ObPigVENRFB4f3REFWBV9mhmL\nopn1RG8cbCUw3WrW7DrNyh2n8PWw5cXx4Rhr/HfKzdGKuU/exvRFO/lhwzFUVB6MCm2S0FBcWsnS\n9cdYufMUer1Kj3YePDaqAx7O1o1yPEVR6BjoQsdAFx4r6sCWuHTW7TnD9gMZbD+QodmFN51eJfNc\nUZ33wFMZBZSW/xmMFAVaudrQo50Dgd4OBHjase1AOhv2pvLyR9Hc3tWbCXe1w9nessnqFkIrEpZE\ni1dYXFF7paxm5Cj7Qt1gZGtlSuc2rgR5OxDk7UCgtz3uTlZXvIF3CXHjsVEd2RKXxro9Kew4mMGO\ngxl4ulgTFeHHwO6+8oFUXKGySs/b38Sy53BWdVCaFHHVheMNSVEUJo/uCAqs2nmaGYujmS2B6ZYS\nf/wci5clYGdtxqsTI26402JjcXW0ZM6U25ixKJofNxwHFR4c2niBSVVVtsSl88WqRPIvluPpbM1j\nozrQvZ1HoxzvauxtzBnVL5CRfVuTdPoCa/ecIboJLrzp9CoZORc5mV7Arv35/LR7B6czCygt19Xe\nxkiBVm62BHnbX3r/cyDAy+6K10unNq5ERfqx+LdDbN2fTkziWR4YEsrwPq0xkal5ogWTsCRalMLi\nitqRopOXrprlXBGMzOjSxpUgn+o3hSBvB9wcLa/7jdrWyowRfQIZfltrjp7JY+2eM+w8mMGXq5P4\ndu0RItp7EhXpR6dgVxltElRW6Zn/dSwxiU0XlGooisLkUR0xUhRW7DjF9EXRzJ7SC0dbiyY5vtBO\nxrki5n4di5GiMH1Cj0YbPblZro6WtVPyftx4HBUY3wiB6XRmAYt/O0TS6QuYmRozfmgoo28PwqyB\nptzdKEVRaN/amfatnZk8qiNb9qWxtoEuvOn0Kuk5F/8cMbq01qisom4w8na3rb0oGOTtQGsv++se\n5Q7xc+KdZ/qxPiaFb/5IYsnKRDbsTeWJuzsSFuR6Q/UK0VxIWBLNVkFR+aVA9OeI0bm80jq3sbM2\no2uIW+2bQpC3A643EIyuRVEU2gY40TbAicdGdWRbXPWbXvShTKIPZeLuZEVUpB+DuvviaCcfTm9F\nlwelzsGuzJjYo8mCUg1FUXh0ZAdQqtfczVhUPcIkr8mWq6ikgrc+20NxaSX/HtuF9q2dtS7pqlwc\nLgWmRdH8tPE4qqry0B1tG+Tvc1FpJd+tPcIf0afRq9CzoyePjuiAm5NVA1TeMGytzBjRN5DhfW78\nwptOpyctp6jOrIlTmQWU/08w8nG3rb0oWFWcxR39e9R7+q+xkcIdPf3pHebFN2uOsG7PGWYs2kWf\nzq2YOLw9Lg4yNU+0LBKWRLOQf7H8ihGj8/l1g5G9jRldQ90uhSJ7Ar0dcHVomGD0d2wsTbnzttYM\n6x3A8dQ81u1JYfvBDL7+4wjfrT1Kj/YeDI30p3Ob5jnaVFRSwdncYjxdbGSX+utUWaVj3lf72JtU\nHZRemRTRYAvIb5SiKDw6ogMKCsu3JzN9UTRzpjSfwKSqKlm5Jbg4WGBqos05bC6qdHrmfhVL5vli\nxvQPYmB3X61LuiYXB0vmXhph+nnTCVQVHh5284FJr1fZvC+Nr1YnkV9UjpeLNY+PDqNrqFsDV95w\n6lx4G9mBrfvTWXeVC2+Otua1a4xOZxZSUXlZMDJS8HW3rXNh0N/Lrs7Fmbi4vAZdJ2lnbcY/7+nE\nkAhfPv4tgR0HM4hNymLs4BBG9A3E1ESm5omWQcKSMDh5F8tqR4pOplUHpPMFZXVu42BrTre27nXe\nGJztLTTvLKQoCiF+ToT4OTFpRAe2HUhn7e4z7E44y+6Es7g5WjIkwo9BPXwNdmHs3zW/8HS2rnPe\nA73tsZGNF+uorNIx96tYYpOy6dzGlVcmaheUaiiKwqQR7VEU+H1b8qUpeb1xMuDAVFhccWl94BnS\nsovwcLbisZEd6dG+6daaNCeqqvLxsgQOnTxPZAcPHh7WTuuSrouz/Z9T8n7ZfAJVVXnkznY3/Pf8\nZHo+H/92iKMpeZibGfPwsLaM6hfYrAK2jZUZd93Wmjt7B3AsNY91u/+88FajJhjVXhj0cSDAy16z\nvzHBPo68/XQfNsam8tXqJL5cncSGvak8ProjXUIMN6QKcb0kLAlN5RWW1Y4U1Ywa5f5PMHK8FIxq\n3hiCfBxwstM+GP0da0tThvUK4I6e/pxIy68ebTqQzrdrj/L9+mN0b+vO0J7+dAlx06xD1fWt8apu\nftHK1YaMSx2UdsZnsjM+s/Y2Hs5WtVM9akb1btWd6yurdMz5MpZ9R7Lp0saVGQYQlGooisLES62j\nf9+WzPSPopnzpGEFJlVVa9st70rIpLJKj4mxEZ2DXUlIPs/MJTF0a+vO5FEd8XQxrHU4Wlu58xRr\nd58hwMuO58aFN6tR7JrANGNRNL9uOQlw3YHpYkkF36w5wtrdZ1BV6N3Ji0nDO+DqaJgXpK6HoiiE\n+jkR6ufEoyM7sDM+kyqdniBve/w1DEZ/xchIYUiEHz07evLd2qOs2XWa1z7ZTa8wTyaN6ICbo+FM\nfxTiRklYEk3mYqmOvUlZJKf9OWpxobBuMHKyM6d7O/c6oxaGOgJzvRRFoY2vI218HZk0oj3bDmSw\nbs8ZYhKziEnMwsWherRpcA/fRp3rXVBU/ueI3aWAlHMTa7xUVSUnr/TPkHXp5xkdn0n0ZQHK3cmq\nziLiQG+HZrMZ482qqKweUdp3JJuuIW7M+EcPzRaS/5WawGSkKPy29STTP9rJ7Cm9Nf89+3MjzxQy\nzhUB1a2Lh/b0o394dWvl1KxCPl6WwL4j2cSfOMfd/YO4Z0Bwk68DM0RxR7P5fPlhHGzNeWViRINt\ndNyUnO0tmT2lNzMW7eLXLSfRq/CPu/46MOn1Khv2pvL1H0kUFlfg7WbD46M70rlNyxrNsLY01WQj\n4Ztha2XGE3eHMbiHLx8vS2DXobPEHc3hvoFtGH178xrlE6KGoqqqqnURNyouLo7w8PBb5rjNjaqq\nXCgsq/0QXfOhOu9ieZ3bOdlZ1JlGEOTtYFBXuBvbybR81sWksG1/GqXlOowU6NbWg6iefoSHuF2x\nS/qNvP6up/mFvY3ZFaNBN7vGS1VVzl0KUJcfs7C4os7t3BwtLztmdZBqyv1FGvN3uKJSx5wv9xJ3\nNIeuoW7MmGB4Qelyqqry1eokft1yklau1tcVmBr6/KmqSkLy+UujSGep0ukxNTGid1h1G+X2ra/c\ntFNVVXYezOTzlYfJLSjDzdGSR0d2JLKDh8GPNjfW6y81q5AXP9hBZZWeuU/2JsTPqcGP0ZQuFJYx\nY1E06TlFjOoXyMTh7VEUpc75O5GWx+LfDnE8NR8LM2MeGBLC8D6yTuZamvozjF6vsiUujS9X/bl+\nbPLojoSHujdZDQ1BPvuJ5nfpSRgUVVXJLSi74kNy/v8EIxd7C0K8LejWwb/6Q3Ir+2azuLyxBPk4\nEOTjwMTh7dl+abRpb1IWe5OycLG3YFAPPwZH+P7t9IXraX7hYGNO+KXmFzVhxcWh4aYyKoqCm5MV\nbk5W9ArzAi4FqPzSK9Y/1azfquHqaFlnBCrI26FJA1RDqKjUMfvLvew/mkN4qBvTDTwoQfXP7JE7\nq9e0/LrlZO2UvKYYYcq/WM7mfams25NC5vliAHzcbRga6U//bj7XnMKpKAp9urSiWzt3ftxwjOXb\nk5nz5V66hroxeVRHWrnaNHr9hqSgqJyZS2IoKavihQfDm31QguoLaXOmVHfJ+31bMkDt9NGConK+\nWXOE9TEpqCr07VLdgU3rkVFxJSMjhYHdfYno4Mn3646yeucp3vh0D5EdPHh0ZEfcDagzoRDXIiNL\nzeC4hkJVVc7nl9X5YJ6cXkB+0f8EIwfLOpvbBXk74GBrfsufv+uRnF492rQ1Lp3S8ioUBcJD3YmK\n9MOoNIPg0A7X1fzif8OHITS/gPq/huqrMV6DFZU6Zn+xl/3HcujW1p2XH+lu8EHpcqqq8vUfR/hl\n8wm8XKyvGZjqc/70epVDJ8+xdk8KMYfPUqVTMTMx4rbOrYiK9KOtv9NNvUbTsi/yye8JHDx+DhNj\nI0bfHsh9A9s0aNevhtLQr7/KKj2vfryLxFO53D+4DeOHtm2wxzYEeYVlzFgcTVp2ESP7BlJVmsv2\nxGIullTi62HLE6PD6BjkonWZzYbW78GnMwv4eFkCiadyMTMx4p6BbRjTX7s9r66X1udNaE/CUjM4\nrtZOpuWzds8ZYg5nXfGh9kZGBW7V83czysqr2HEwg3V7UjiWmgeAibFCla7ur6ujrXmdqXTNpfnF\n5W5kdDLQu3o0ruY1d6Obqzb0a7C8UsfsJTEcOH6Obm3dmT6he7Ock6+qKt+sOcLPm07g6WLNnCm9\nr7p+7mbOX15hGRtjU1kfk1LbVdHPw5aoSH/6h3s3SCdFVVXZlXCWz5Yf5nx+KS4Oljw6ogO9wjwN\n6nehIV9/qqry3x8PsjE2ld4LbaJEAAAgAElEQVSdvJg6vluzauhwvfIuljFj0S7Ssi8CYGluwrio\nUO66LQATY5lydyMM4T1YVVW27U9nycpE8i6WV3e4HNWRHu0Mt8OlIZw3oS3Du/QmDEJJWSXb9qez\nLiaF5PQCoLr5Qq8wz9qr/YGtmna9ya3EwtyEwRF+DI7w43RmAev2pBCTkEZrb5cWt8ZLURRcHCxx\ncbAksoNn7ddzC0qvaEhR0xSjhrO9xWWjT9WBvammd5ZX6pi1JIaDx8/RvV31iFJzDEpQ/TOo2Qz0\np43Hmf5RdVvxm+0mpterHDxxrrqRyeEsdHoVM1NjBnb3YWikPyF+jg0aYhRFoXeYF+Ehbvy06TjL\ntiYz7+tYOge7Mnl0R3zcbRvsWIZi2dZkNsamEuRtz7/HdmmRQQnA0daC2VN68e53cSi6Ep59qE+L\n+Lt3q1IUhdvDfejR3oOl64+xYscpZn4eQ/d21R0uPZylw6UwPBKWRC1VVTmRls/a3WfYfjCD8god\nRkYKkR08iIrUtsX1rSzAy54n7g6ju1/lLXV1y9neEmd7yzp76ly41Gr+8o6K/xugnOzMr2gi0dDr\nGS4PSj3aefDSI92abVCqoSgK44eGogA/bjzO9EU7mTPlthsKTBcKy9i4N5V1MSm1Lej9Pe0YGulH\nv3CfRt/Q2MLchIeHtWNQd18+/j2B/Udz+Ne7WxjZN5D7B4c0yw5xV7M3MYsvVyfiZGfBKxMjWnw3\nQEdbC2Y90Zu4uDgJSi2ElYUpk0Z0YFCP6g1tY5OyOXj8HGP6B3PPwGCDa40ubm0t+y+suC7FpZWX\ndgw/w+nMQgDcnKwYEuHLoO6Gu3mquPU42VnQo51HnSkbV9urKzYpm9ik7Nrb1ExXtDYuocr8bL2m\nK5ZVVDF7yV4Onmg5QamGoig8ODQUFPhxQ3Vgmj2l9zWbjOj0KgeO5VxqUJKNXq9ibmbM4B6+DO3p\nT7CPQ5NPhfNyteGNRyOJSczi0+WH+XXLSbbuT2fS8A7c1tnLoKbm3ajTmQW8890+TE2MeXVihPx9\nFs2an4cds6f0YsfBDD5fkcgPG46xOS6Nx0Z2IKK94Xe4FLcGCUu3KFVV6+wOXlGpw9hIoVeYJ1GR\n/nQOdm2x0zpEy+JoZ0H3dh50vzxAXSy7ohHGviPV4Wnb4b3AzTXCKKuoYtaSGOJPnCeivQfTHu7e\n4loVK4rCg1GhKCj8sOFYdZe8Kb1x+5/OVbkFpWzYW70WqaYtfWsve4b29KNfV2+sLBp3FOnvKIpC\nZAdPuoS48cumE/y65QRvf7uPtXtcmDy6I34edprWdzPyLpYxc0kMpeU6Xnq4O0E+DlqXJES9KYpC\n3y7edG/nwY8bjvH7tmRmf7GX8EsdLr1usQ6XwvBIWLrFFJVWsjWueuPHM2erR5E8nK0YEuHHoO6+\nt3w7b9EyONpa0K2tBd3a/rmfR/7FctZujUWxcK0didp3JLs2REF1i/U/N9Gtu/dUWUUVMz+P4dDJ\n80R28GDqQy0vKNWoGWFSFFi6/hgvL4pm7pTe6PUqsUlZrNuTQmxSFnoVLMyMiYr0IyrSjyDvph9F\n+jvmpsY8ODSUAd18+HR59XSfZ97dyvA+rXlgSIjmoe56VVTqmPPFXs7llTJ+aCi9O3lpXZIQDcrS\n3IQJd7VnYHdfPlmWQNzRHP65YItBd7gUtwZ55d0CVFXlyJkLrNuTws6DGVRU6TE2UujdyYuhkX6E\nBckokmj5HGzNCfayJDw8pPZrV9u8N+5oDnFHc2pvY29jRmArBy6WVHAiLZ+eHT15cXy3FhuULjcu\nqnoN0/frjzHtwx1UVFZSWJIBVO8TNjTSjz6dWzWLwOHpYs1rkyLZm5TFp78n8Pu2ZLbtT2fi8Pb0\n6+ptcCGvRnFpJckZ+azaeZqjKXn06+LNfYPaaF2WEI3Gx92Wtx7vya5DZ/lsxWF+3nSCLXHpPHN/\nZzq3cdO6PHELkrDUgl0sqWDLvjTW7kmpbbvq6WJNVIQfA7r73HDbZSFaGnsbc8JD3evsKF9QVE5y\nRkGdTX73H6sOTz07ejL1oW63VMviB6JCQVH4ft1RzEwU7ujpz5BLo0jNUY92HnQOduW3rSf5eeNx\n3v1+P2v3pPDE3WH4e2o7Na+otJLk2j3IqsP72Uub9gKE+Dnyr/s7G2ywE6KhKEr1Bd3w0JoOlydZ\nuv6YhCWhCQlLLYyqqiSdvsDaPWeIjs+kskqPibFCn0sbP3YMdJFRJCGuwd7GnK4hbnQN+fNNubC4\ngtyCUvw87G7J358HhoTQs6MnmSnH6BXZSety6s3M1Jixg0PoH+7DZ8sT2HM4i2cWbuXO3gGMiwpt\n9K59AEUlFXUakySnF3A2t7jObWwsTekU7FLbHr97O3eD38BTiIZU0+HyrttaYyQXCYRGJCy1EIXF\nFWzel8a6PWdIzykCoJWrNVGR/gzo5iP7IQlRD3bWZthZ13/z1ObM39OO3MyWNaLm7mTFjH9EEHc0\nm4+XJbByxyl2HMhgwl3t6B/u02DB+GJJBSfT8tmRWMiGw7GcTM8n+1Jr9Rq2VqZ0buNap+W9u5OV\njCIJAdIyXmhKwlIzpqoqh0/lsm53CtGHMqnS6TExNqJfF2+ievrRobWzvNEKIcTfCA915/9edGHZ\n1mR+3Hic9384wLpLU/Nat7K/occqLK6o3US5ZuQop04wKsTWyowubVwJ8nGo3RPMzdFS/l4LIYQB\nkrDUDBUUlbMpNo31MWfIOFc9bcPbzYaoSH/6h3vLKJIQQtwgUxNj7hvUhtvDvfl8xWF2HTrLs+9t\n5Y5eAYwfGoqN1ZUjiwVF5X+2qL8UkHIutVGvYWdtRtcQNwK97VEqLhDVtyuuEoyEEKLZkLDUTOj1\nKgnJ51m3J4XdCZlU6VRMTYy4PdyboZH+tAtwkjdfIYSoJzdHK15+pAcHjuXw8bIEVkefZsfBDB4e\n1g5ne4s6I0bn8+sGIwcbc8JD3a7aeh4gLi7uiv2qhBBCGDYJSwYu/2I5m2JTWReTUtsVycfdlqE9\n/egf7oPtVa52CiGEqJ8uIW588EJ/VmxP5ocNx/jw54N1vu9ga063tu43tKmxEEKI5kfCkgHS61Xi\nT5xj3Z4UYhLPUqVTMTMxYkA3H4ZG+hPq7yhvyEII0chMTYwYMyCYfl29WbHjFOamxgR52xPk44CT\nnQQjIYS4FUhYMiB5hWVsjE1l3Z6U2k5J/p52REX6cXtX76vOmRdCCNG4XBwsmTi8vdZlCCGE0ICE\nJY3p9SoHj59j7Z4z7E3MQqdXMTM1ZlB3X6J6+hHiK6NIQgghhBBCaEHCkkZyC0rZGJvK+pjU2ray\nAV52DO3pT78u3lg3waaIQgghhBBCiL8mYakJ6fQqB47lsG7PGfYmZaPXq1iYGTMkwo+oSD+CfRxk\nFEkIIYQQQggDIWGpCZzPL2XD3lQ27E3h3KU9OFq3sr80itQKKwsZRRJCCCGEEMLQSFhqJDq9StzR\nbNbtTmHfkSz0KliaGxMV6cfQSH+CfBy0LlEIIYQQQghxDRKWGlhOXgkb96ayISaF8wVlAAT5ODA0\n0o8+nWUUSQghhBBCiOZCwlID0On0xB7JZt2eFPYfzb40imTCHb38iYrwI9BbRpGEEEIIIYRobiQs\n1UP2hRI2xKSwYW8qFwqrR5FCfB2JujSKZGEup1cIIYQQQojmSj7N36AqnZ7YpCzW7knhwLEcVBWs\nLEy4s3cAUZF+BHjZa12iEEIIIYQQogFIWLpORSUVbIov4D8r15N3sRyAtv5OREX60buTFxZmciqF\nEEIIIYRoSeQT/nX6betJdiRexNrSlOF9WhMV4Yefp53WZQkhhBBCCCEaiYSl6zSybyAmVRcYc0dP\nzE2NtS5HCCGEEEII0ciMtC6gubC3MSeklaUEJSGEEEIIIW4REpaEEEIIIYQQ4iokLAkhhBBCCCHE\nVUhYEkIIIYQQQoirkLB0nbLWb6Ts/Q85/fkXlKSla12OEEIIIYQQopFJN7zrZO7iDFVVZK5YReaK\nVdi1a4v7kEE49+qJsbm51uUJIYQQQgghGpiEpevk2LUL5s8+jX9lFVnrNlAQf4jCpCOc+nQJbv37\n4RE1GCtfX63LFEIIIYQQQjQQCUs3QDE2xqVHD1x696L0bBbZGzaSs2kLZ1f9wdlVf2AbGoJH1GCc\ne/eS0SYhhBBCCCGaOQlLN8nS0wP/h8fjO24sebH7yFq3gfyD8Vw8eoxTny3B7fZ+uA8ZjLW/n9al\nCiGEEEIIIW6ChKV6MjIxwblnJM49IynLziZ7wyayN27m7Oo1nF29BtuQNrgPGYzLbb0wtrDQulwh\nhBBCCCHEdZKw1IAs3N3xGz8On7H3kbcvjuz1G8nbf4CLx45z+vMvcO3XF/chg7BpHaB1qULckLKs\nLLLWrsehcyfswzqiGEkjTdHy6auqKE1Lpyj5FCVpabjd3g/rAH+tyxJCCNGEJCw1AiMTE5wjI3CO\njKAsJ4ecjZvJ3riJrDVryVqzFpvgINyHDMa1T2+MLS21LleIa8o7cJDj77xHVVERGcuWY+7uhseQ\nwbgN7I+Zo6PW5QnRIPRVVZSkplGcnExR8imKTp6iJCUFfUVF7W0KE48QtmAuiqJoWKkQQoimJGGp\nkVm4ueE7biw+999LXtx+stZvIC/uAEX/t6h2tMkjajA2ga21LlWIOlRVJePXZaR8+z2KsTF+D4+n\nNDOT8zuiSfnmO1K//wGnHt1wHzIYh86dZLRJNBv6ykpK0tIoOnmqNhwVn0lBraysvY1iYoKVrw82\ngYFYB7Ymd/eeS11Qk7Bv317D6oUQQjQlCUtNRDE2xqlHd5x6dKf83HmyN20me/1GstetJ3vdeqwD\nA/GIGoRLnz6YWMlok9CWrrSUE//9P3J37cbM2YnQl6Zi2yYYgICJEzi3fQfZ6zaQuzuG3N0xmLu5\n4T54IG4DB2Du7KRx9UL8SV9ZSUlqGkXJybXhqPhMCmpVVe1tFBMTrPx8sQlsXRuOrP39MDI1rb2N\ntb8fCfGHyFi2XMKSEELcQiQsacDc1QXfsffhc+8Y8g4cJHv9Bi7ExpH80cecXvIVrn1uwz1qMDZB\ngTLdQzS50sxMjs59m5LUNOzatyNk6vOYOTjUft/E2hrPO4biMTSKopPJZK/bwLkdO0n9bimpS3/E\nqXs3PKIujTYZG2v4TMStRl9ZSUlKanUwumwq3ZXByA+boNa14cjKz7dOMLoau7ah2IaEkBcbR0lq\nGla+Po39dIQQQhgACUsaUoyNceoWjlO3cMpzc8nZtIXs9RvI3rCR7A0bsQ4IwD1qEK59+2Biba11\nueIWcGFfHMcXvo+uuATPu4bh/49HMDK5+p8JRVGwDQ7CNjgI/4mPcH77TrLWb+BCzF4uxOzF3NUF\nt0EDcR80EHMX5yZ+JqKl01dWUnwmheLkU7XhqCQl9YpgZO3vh3Vg4KVwFIiVr8/fBqO/0mr0SI7O\ne5uM5SsIfvqfDfVUhBBCGDAJSwbC3NkZn/vuwXvMaPLjD5G1bgMX9sZyavGnnPnia1z69MbzjqHY\nBAVqXapogVS9nvSffyV16Y8YmZoS/MzTuA24/brvb2JlhcfQIXgMHULRyWSy1m/k3LbtpC39kbQf\nf8YxvCseUYNx7NpFRptuUvm5c5i5uNyyo80l6ekUJCTWhqOS1LS6wcjUFOsAf2wCW9eGIyufmw9G\nV+PUoxsWXp6c27odvwfHYeYkDU7EraGy8CKlGRma1mDl44OJjVw4Fk1PwpKBUYyNcezaBceuXai4\nkFe9tmnDRnI2biZn0xZCpj6PS6+eWpcpWpCqkhJOvP9fLsTEYu7qQuhLU+sVym2CAgkKCiTgHw9z\nbkc02es3kBe7j7zYfZg5O+M++NJok6tLAz6LlktfWcnpz5aQtXY9fg89iPc9d2tdUpO7eOIkCS/N\nqA1HRmZmWLcOwCYwEJvAAKxrRoz+YhS0oSjGxrQaOYLkRR+TuWo1/g+Pb9TjCWEILh4/QeIbb6Er\nLtG0DrsO7ek4+y1NaxC3JglLBszMyRGfe8fgPWY0efsPcGzBQk68/wEW7u7SPU80iJL0dI7OfZvS\n9AzswzoS8sKzmNrbN8hjG1ta4jFkEB5DBlF06hTZ6zdybut20n74ibSffsGxaxfchwzGqVtXGW36\nC+W5Fzj29jtcPHoMgIzfV+A5/E6Mzc01rqxpZfy6DLWqCr+Hx+MY3gVLb+9GD0Z/xbV/P1K/X0rW\n2vV43zNGGvKIFu3iseMkvjETXVkZnnfeoel2J/adwjQ7tri1SVhqBhQjI5y6hdPmuX9zdO58jsye\nS9iC+dJ1TNRLbsxeTrz3X3SlpXiNGoH/w+MbLbTYtG6NzROT8Z/wMOd3RpO1bgN5++LI2xeHmZMT\nboMG4D54IBZubo1y/Oao8MhRjs5fQGVePi59+2Dm6EDm8pXkbNqC57ChWpfXZErPniV3TwzWga1p\ndfcozachGpub43nnMFK//4GcjZvwGnGXpvUI0VguD0ptnv0Xrn37aF2SEJqQjVGaEeeI7vg9PJ6K\n3AscnTMPXXm51iWJZkjV60n5bilH58xH1elo8/y/CfjHI00yumNsYYH7oIF0WjCPzv95F88770BX\nXkb6T78QN/lJkt6aRe7uGPSXrUW51aiqytk16zj8yutUFhTiP3ECbZ57pjoomJqSuXwlqk6ndZlN\nJnP5SlBVWo0aqXlQquFxx1CMzM3JXLHyln6tipbr4rHjJL7+VnVQeu7fEpTELU3CUjPTavRI3AYO\noOhkMif+8wGqXq91SaIZqSoq5sjseaT/9Avm7m6EvT1XszdBa39/Wk9+lO5ffEbwM09hG9KGvLgD\nHJ33NvsefZyUb76jLDtbk9q0oq+o4OSHH3Fq8ScYW1nR/s3XaDVyOIqiYObggFv/fpRlZZG7Z6/W\npTaJyoICcjZtwdzNDZfehrNW09TOFvdBAyg/d57c6N1alyNEgyo8eqw6KJWXE/L8v3Ht01vrkoTQ\nlISlZkZRFAKnTMauXVtyo3eT9uPPWpckmomS1FTiX5hK3r44HDp3otO7b2Md4K91WRibm+M2oD9h\n8+fQ+b/v4XnXMPQVlaT/8htxj/+TxNff4vyu3S3+Cn75+VwSpr9KzsbNWAcG0nnh2ziEdaxzG6+R\nI0BRyFi2HFVVNaq06Zz9Yy36igq8RtxlcOvavEYOByOjW+ZnIW4NhUeO/hmUXngWl9skKAkha5aa\nISNTU0Jfnkr8C9NI++EnLFu1wrXvbVqXJQzY+ejdnPjvh+jLymg1ZjR+Dz5gcB8+Aaz9fGn92CT8\nHh5P7q7dZK/fSP7BePIPxmPq4IDPfffgMXSIQdZeHwWJiRyb/y6VBQW49r+dwCmTr9rEwcq7FU49\nunEhJpbCpCTs27fXoNqmoSsv5+zqNZjY2OA+aIDW5VzBwt0d556R5EbvoiD+EA6dO2ldUqPRlZdz\ndO7blGXnaFpHeXkZceYWmh3fMbwr/o+Mb9B29Iak8MhREt+Yib6iojoo9e6ldUlCGAQJS82UqZ0d\n7V6ZzqFp0znx3w+xcHfDNqSN1mUJA6PqdKR8t5SMX5dhZGFByNQXDGo6018xNjfHrf/tuPW/nZLU\ntOqNmjdu5tQnn5G9YROtH38Uu7ahWpdZb6qqcnb1Gs4s+RKA1pMn4THsjmuuzWk1ehQXYmLJWLa8\nRYelnE1bqLp4Ee97x2jagetaWo0eSW70LjKWLW/RYensytXkHziIsbU1RmbaBQW1shKdRlPP9eUV\nnF25iqLjxwmZ9mKLa7BUmHSExDdnoVZWEvLic7JFiRCXkbDUjFn5+hDywrMkzZrLkTnz6fTOfNm7\nRtSqvHiR4+++T/6Bg1h4ehD68jSs/Xy1LuuGWfn6EDDpH7QaM5qUr74hZ/NWEl6agduA2/F75CHM\nHBy0LvGm6MrLSV70Cee2bMXU3p6QaS9g377d397PNjSken1XbBwlqWlY+fo0QbVNS9XpyFy+EsXU\nFM+7hmldzl+yDQ7CrkN78g/GU3z6jEFMa21oFfkFpP/yGya2toQv/j9NNwWNi4sjPDxck2Pryss5\n+eEizm/fQfzzLxI67cUWccEGrgxKzj0jtS5JCIMia5aaOcfwrgRMfITK/HyOzJ6LrrRU65KEASg+\nc4b456eSf+AgjuFd6fTO280yKF3OzMGB4GeepuO82VgHBJCzeSv7n3yazJWrm113uLKcHBJefoVz\nW7ZiExxMp4ULrisoQfW6xVajRwKQsXxlY5apmdyYvZRlZeHWv5/Bh+Han8XvyzWupHGkLf0BXWkp\nvg/cp2lQ0pqxuTltnnsG/4kTqCwo5PCM1zi7Zm2zX69WkJh0WVB6XoKSEFchYakF8LzrTtyjhlB8\n+gzH3/uvdMi7xZ3bvpNDU6dTnp2D93330PaVl1vUhxy7tqF0enc+rSc/Ciic/mwJB599gYLERK1L\nuy75hxKIf24qxcmncBs0kI5zZ2Lu4nxDj+HUozsWnh6c27qNigt5jVSpNlRVJWNZdfDwGjlC42r+\nnmN4V6x8fTi/I5ryc+e1LqdBlaSmkbV+I5atvHCPGqJ1OZpTFIVWI4fT/s3XMLa25tTiTzn54Ufo\nKyq0Lu2mFCQmkvTW7MuCUoTWJQlhkCQstQCKotB68iTswzpyIWYvKd9+r3VJQgOqTsfpL77i+Lvv\noRgZEfry1OpGDkYt79dcMTbG8847CF/0AW6DBlKSksrh6a9xfOF/DDY8qKpKxvIV1Z2mSksJnPI4\nQU9NuanF4oqxMV4jR6BWVXF29R+NUK12CpOOUHT8BE49umPl3Urrcv6Woih4jRpRPXVw5Sqty2lQ\nZ778GvR6/B55GCMTmbVfwyGsI50Xvo11YGtyNm4mYfqrzS4oFxxOJOnN2ahVVYRMe0GCkhDX0PI+\nRd2ijExMCJn6PBZenmT8uoyczVu1Lkk0ocrCQhLfmEnm7yuwbOVF2IJ5OEe2/Dc/U3t7gp9+krC3\n52IdGMi5bdvZ/+TTZCxfYVCtxnXl5Rxf+D5nlnyFqb0dHWa9Wd3Vrx6brLoNuB1TezvOrllHVUnL\nmX5bM6pUM72tOXDt2wdTR0ey1m2gqqhY63IaRP7BePLi9mPXoT1OPbppXY7BMXd1pePcWbj2v52i\nEyeJf/5FCg43j9HtgoTD1SNKOh0hU1/AOaKH1iUJYdAkLLUgpra2tJ3xMsbW1pz8v0UUJh3RuiTR\nBIqSTxH//FQKDiXgFNGdsHfmY+XjrXVZTco2pA2dFswlcMrjKCbGnFnyFfHPvkBBwmGtS6MsK4tD\nU1/m/Pad2IaG0HnhOw2yMNzY3ByPYXegKy4mZ+OmBqhUeyVp6eTF7sM2pA22zWjxvJGpKV7D70Rf\nVkbWuvVal1NvNaPUKAoBEyfUK9S3ZMbm5gQ/8xStJ0+iqqiYw6++Ub2G0oDXMRUkHCZp5hxUnY7Q\naS/gHNFd65KEMHgSlloYK+9WhE59HlWv54gB7IshGlfOlurOcOXnzuM7biyhL03FxMpK67I0oRgb\n4zF0CF0/+hD3qMGUpKVz+JXXOfbOQspzczWpKe/AQeKfn0bJmRQ87oiiw6w3MXNybLDH9xw2FCMz\nMzJXrDSokbSblfH7CqB6VKm5fUD3iBqCkYUFmStXo6+s1LqcesnZso2SMym43t4Pm8DWWpdj0BRF\nwfPOYbSf+Qamtrac/mwJJ97/AF15udalXUF3+kztiFLoSy/i1EOCkhDXQ8JSC+TQuROtJz9KVWEh\nR2bPpaqkROuSRAPTV1Vx6tPPOfH+ByimJrR95WV87r+3Ra5PulGmdrYEPfkEYQvmYRMczPkd0ex/\n8l+k//Z7k3XNU1WV9F+XkfTWbHRlZQQ9NYXAJyY3+GaWpnZ2uA0aQPm58+RG727Qx25qFRfyOLd1\nGxaeHs3yQ5yJjTUeUYOpzMvj3PYdWpdz03RlZaR8+z1GZmb4jR+ndTnNhn37dnRauACb4GDObd1G\nwkszDOpiZX78ISqX/oSq1xP68lScusvUSiGul3yyaqE874jC885hlKSkcvzd95tda2Xx1yryC0h8\n7U3OrvoDSx9vOr0zH6du2uw9Yshsg4MIe3tOdRMFMzNSvvqGio8/I/9gfKMeV1dayrG33yXl628x\nc3Sg49xZuA8e1GjHazVyOBgZkbFsuUFP//k7Z1f/gVpVhdfIESjGxlqXc1O8ht+FYmxM5u8rmu3P\nIuP3FVTm5eE1asQNd2m81Zm7ONNx7kzcBg2k+NTp6u0b4g9pXRb58Yc4MmsuqGp1UJL3CyFuiISl\nFixg0gQcunQmb18cZ776RutyRAO4eOIk8c+9SGFiEs49Iwl7ex6WXl5al2WwFCMj3AcPoutH/8Xj\njqGouRdIfP0tjs5/p1G6V5VmZnJo6svk7tqN3aUrzbZtghv8OJez8PDAuWcExadPU2AAH8xuRlVJ\nKWfXrMPU3g63AbdrXc5NM3d1waVPb0pS08iL2691OTesPPcCGb/9jqmDA61Gj9K6nGbJyNS0eiR5\nyuPoSktJfGMmGRqG5/yD8RyZNRdVr8f0vjESlIS4CRKWWjDF2JiQF5/D0tubzOUryVq/UeuS6uVW\nHx2rOhhPwsuvUHHhAn4PPUjItBcwsbLUuqxmwdTWlsAnHsPs0X9gGxJC7q7d7P/nv0j/5bcGW19y\nYV8c8S9MoyQ1Dc+7htH+rdebbEPVmg+2NZ3kmpucjZvQFRfjMewOjM3NtS6nXlqNurRJbTP8WaR+\nvxR9eTm+D46Vvy31oCgKHkOH0GH2W5ja23Pm0pYOurKyJq0j/2A8R2bPQ1VV2s54CePgoCY9vhAt\nhYSlFs7E2rp6U1JbW04t/sQguoPdqJL0DBLfmMmuMfeT+MZMcnfvaRGL2a+HrrSU7A0biX/hJapW\nrMbY3Jx2r83A+567m90CeENg5OlBx3mzCH7mKYwtLEj55jsO/OtZ8vYfuOnHVPV60n76pfrqbWUV\nwc88TevHJjXpvjS2wVe5xz4AACAASURBVEHYdWhP/sF4ik+fabLjNgR9VRWZK1ZiZGaG57ChWpdT\nb9YB/jh07kTh4UQunjipdTnXrfj0GXI2bcHKzxf3gQO0LqdFsAsNofPCBdiGhnB+RzSHpk2nLCur\nSY6dd+AgSbPmVgel6dNw7NqlSY4rREskYekWYOnpQejLL4KicHT+AkrPntW6pOuiKy3lzFffcPCZ\n58g/cBBzV1fyDxzk6LwF7Jv0OCnffNdkbzxNrSj5FMmLPib2H49x8sNFFCUnYxQcRNg78+VNr54U\nIyPcBvSn60cf4HnXMMqyskl6cxZH5sy/4QXZVSUlHJ23gNTvll5arzBLs2lkNfsSZfzevEY0cqN3\nU37uPG6DBmBqZ6d1OQ2i9mfRTEaXVFWtbhWuqvhPeLjZrhkzRGZOjtX7qt0RRcmZFOKfn1avizPX\nI2//AY7MngcgQUmIBiBbct8i7Nu3J/CJ6g/eR2bNJWz+XExsrLUu66pUVSU3ehenl3xFRW4u5q4u\nBEyaiFNkD0rT0shav5GczVtJ/+U30n/5DYfOnXAfMhinHt0avNtYU6oqKeX8jh1krdtIcXIyAGbO\nzniNGoH7wAEcTk3B0tND4ypbDhMba1o/Ngn3wQM59fFnXIjZS/6Bg3jfczetRo/EyMzsmvcvSU/n\n6Ny3KU3PwD6sIyEvPIupvX0TVX8lx65dsPTx5vyOaPzGP4i5q4tmtVwvVVWrA4WRUXWjihbCvlMY\n1gEB5O7eQ1lWFhYehv17mxe3n4L4Qzh06SwfrBuBkakpgU9MxiYokORFn5D01mz8xo/j/9m77/Co\n6vxv4+8zmfQQIIFUaugdIRTpSAmgILgogrIiKj+7sBZYV8GtFnRZV9dF1sdGERtCAKlBCc0AkS5F\nQEo6hEAaIZPMPH8gcV0OBEhmJjD367q8Lkgy53w8CZA731OifzOi0s8QyPl+m/b+7VUZhqHmz09W\nzZvaV+r2AU/k9dJLL73k7iGuVnp6uqLccFG7u/ZbWYIaxai0qEg5m7eq4PBh1e7Vw6W3mr6S41d4\nPEUHXp+h1K8WyW6zqc7IO9Ts2d8psEF9GYYh7+rVVbPDTYq8bYj860SrJDdXZ3btVvaGjcpcsUq2\n3Fz5hofJu1o1F/1fVYzD4VD+wUM6Pv9T/fjPt3VqU5JsZ84opFOsGowfp0YTHlSNtm1kDQy47r/+\nqgKzY+hTo4bC+vWVX2SEcn/4QTlbturkug3yi4y45M0zspM2a++f/qriU6cUNXyYmj71hLz83XuN\nh2EYsvj46tR3SZJhOOWbpMr+GjyzY6dSv1qk0G5dFRE3sNK2626GYcjL31/ZGzdJDodqduwgqWr+\nG+IoLdW+l19TSX6+mk951mXX2V2Lqnj8rkZQTMz5my4lf69T321W4bHjqtnxpkr7Id9/h1KLP0y5\n6O+A6/34uQvHDawseZgGv71XZ1NTlbMlWYffe1+N/u8hd48k6fyqyvFPP1P64qVylJaqZscOavjQ\nePlHRpp+vJevr8L69FZYn94qPJ6izJWrlPXNt0pdsFCpCxaqets2Ch84QKFdO1fJ1aaSwkKdWLtO\nmStXqeDwT5LO30kr/I7hCut3C7fsdTHDMBTWp7dCOnfS8fmfKW3xUu39899Us1NHxTw4vmxlwGG3\n69gnnyrlsy9k8fFR06cnqnavnm6e/he1e/fU0TnzlLFileredWeVXT2+4MJpajfinddCu98s39lz\nlLl6jerePUrewVXzBzgZK1frbEqKwgf0V2CD+u4e54ZXrWkTtfv7dO1/7Q1lb9yksykpav775yp8\nV9NTW5O17+XXZFgsavGHKarRvl0lTQyAlaXrYL+VybBYVDM2Vjlbtypna7K8g4OdfmvjC8yOn8Ph\n0Ml167Xvr6+cvy4prLaaTnxCdUePuuLVIe/qwarZ4SZF3XarAurWlS0vT7m7dit74yZlLF8p25kz\n8gsLc/s3Kw6HQ/kHftSxT+br4D//pVNJm2U7k6uQLp3V8IH7FfPgeFVv01rWgADT198IX3/uVt4x\ntHh7q+ZN7VWrW1cVHk/Rme07lLFilRwlJfKPjtaBN/6hrFUJ8g0PU+s/Taty35AYXl5ylJTo9Pfb\nZK0WpOAWzSt1+5X5NVhw5IiOfPixglu3Ut07f1Mp26xKzq/aG8rZslVe/n6q3rpVlfszXFJYqP2v\nvCYZhlo8/5zbV0fLU9WO37Xy8vNT7d69VFpYqJwtycr6dq0C6te/5mD6VSi98PtL/r10oxw/V+O4\ngZUlD2QN8FeLF36vnc9M0eH33pd/dJRbvukrOHpMh2e9p9zde2Tx8VHd0aMUPeL2a751sMXHR7V7\n91Tt3j1VmJKqzFXnr21KWxivtIXxCm7dShFxAxTatUu516NUppL8Ap1Ym6iMlatUeOSoJMk3LEzh\nA/srvN8t8gmp6bJZcGUC6tVT67/8USfXbdCRDz7S8U8/1/HPv5TsdtVo305Nn57k9vi+lIhBcTr+\n+ZdKX7xUUUNvrZIrq5KU+lW8JCl6+DA3T+I84QP66dj8z5S+9GtFVcH/z9Qvv5LtTK7qjblbPjX5\ne8iVLFarYh564Px1TO+8q71/eVn1Ro9SnTt/c1Wnx5/aslX7Xpl+PpRefF412rZx4tSAZyKWPJRf\nWJia//457X5hmva99rravvayAurUccm+SwoKdOyT899AyG5XSOdOavjAuEq9CDqgTrQa3n+f6t87\nRtnfbVbmylU6s3OXcnfvkbVaNYXd0kfhA/s77f/Z4XAob/8BZa5YpZPrN8heXCzDy0uhN3dVeNwA\n1WjX1qXXi+HqGYah2r16qGZsR6V89rnSl61Q5JBBqn/vmCp9tzBrUKAiBvZXWvwSnUhcVyVvA33u\nxEmdXLde/nXqlF3PcyPy8vdX5OA4pXyxQCe+WSvVrjqn1547cUJp8UvkExpSJUPOU4T17aOAevW0\n7+VXdWzefOUfOqQmE5+85BkG/41QAlyDWPJgwS2aq/ETj+rHGf/U3j+/rLbTX3HqT8sdDoeyvvlW\nRz6cLdvp0/KLiFDDh8Y79YniFm9v1e7ZXbV7dtfZtDRlrkpQVsIapS1arLRFixXcsoXC4wYo9Oau\nlfIwzJL8fGV9m6jMlatUePSYJMkvIlzhAwcorF/fKn3xNMxZA/zVYNxvVf++sdfNs62iht2mtCVf\nK21hvMJu6Vvl5k5bcv7axOgRw274HxpE3jpEqQvjlbooXo7x97l7nDJH58yTvbhY9e8dc90/CPh6\nF9Qo5vx1TNP/rlNJW7Tzmclq/vzky/4w79TmLdr36usyvLzU8sXnVb1NaxdODHgWYsnDhfXprbPH\nU5TyxQLte3W6Wr30olNO2yn46YiKP5ytH4+nyOLjo3r3jFb08GEuPR3OPypKDe4bq3pj7tapzVuU\nsWKVzuzYqdwf9uqn/7yv2n17K2JgfwXUq3dV23U4HMrbu08ZK1Ype+Om86tIVqtCu3dTRNwAVW/T\n+ob/htATVLXguBzf2rVVu2cPnVibqJzk7536A4mrVVJQoMwVq+Rds6Zq9+7l7nGcziekpmr36a2s\n1QnyPvCj1KmTu0dS3o8HdeLbRAXGNFTtPr3dPQ4keQcHq9VLL+rIx3OUtjBeO5+ZoiaTnlRol84X\nfWx20hbtf+3nUJr6B1Vv3coNEwOeg1iC6t0zWmdTU5W9KUmHZ72nRo8+XGnfGJbkF+jYvPlKX7b8\n/Cl3XbucP+UuLKxStn8tLN7eqtW9m2p176az6Rnnr21K+Ebpi5cqffFSVWvRXBEDByi0+82X/Ymr\nLTdPJ75dq4wVq3Q2JUWS5BcZcX4V6Za+8qnhvmfuANEjbteJtYlK/WpRlYqljBWrVHr2rOqMvKPK\nXk9V2aKHD1PW6gSVbPxOumeMW2dxOBw68sFHkqQG99/HD3KqEMPLSw3vv09BjRrp4Fv/0r6/vao6\nd41UvdGjyj5P2Umbtf+1N2RYrWo59XlVb0UoAc5GLEGGxaImE59UUeYLyly5WgF16ypq2G0V2qbD\nblfWmm919OPZsp3JlV9UlEr79FKLUXdW0tSVwz8yQg1+e6/qjblbOVu2KmPFKp3evkN5e/fp8Hvv\nK6xPb4UP/OWWug6HQ7k//KDMFat1cuMmOWw2GVaravXsrvCBP68iXUcrELhxBTZsoBrt253/ev7x\noKo1aezukWS32ZS+eKksfn6KGBTn7nFcJqBuHdXs1FE5W5KVu3dfpd+l8GqcStqs3D0/qGanWK5x\nqaJq9+qhgLp1tPflV5Xy2RcqOPyTmk56Smd27z4fSt7e51eUWrV096iARyCWIOn8rUxb/OH32vHM\nc/rpg4/kFxV5zT+Nzj90WIff/Y/y9h+QxddX9cfeo6jbh2rbzp2VPHXlsVitCr25q0Jv7qqizExl\nrkpQ5uoEpS/9WulLv1a1Zk1VvW2b88/FSE2TJPlHRyk8boDC+vaRd3Cwm/8PgItFj7hdp7fvUOpX\ni9T8uafdPY5OJK47/yDfYbdV+WdAVbboEbcrZ0uyUr9a5LZYsttsOvLRbMliUYNxY90yA65MYMMG\navfGazrw+gzlbE3W9klPqzj7FKEEuAGxhDK+tULV4g+/1+7nX9SB12eozat/U2D9K79+x5aXp2Nz\nP1HG8pWSw6HQ7jer4f3j5Fu7lhOnrnx+4eGqf+8Y1b37LuVsTVbmylXK+X678vYfkOHtrdq9eyk8\nrr+CW7ZkFQlVWvV2bRXYsKGyN32nooyMSr3j5NVyOBxKWxgvWSwVXrm+HgW3bCkjKkqnNm/R2dQ0\n+Ue7/rktGctXqigtXRFDBrns7qe4dt7Vqqnl1D/o2Lz5SvligSx+fmo17QUFt2zh7tEAj0Is4Veq\nNWmsJk89rv3T/669f3lZ7V5/Rd7VL3/tjcNuV+bqBB39eK5K8vLkXydaMQ89UOUe2Hm1LFarQrt2\nUWjXLirKylL+jwdVvU2bKvt8HeB/GYahqOHD9OOMN5UWv0QxEx502yw5yd+r8Nhx1e7dS761a7tt\nDncxDEPWbl1k++IrpS6KV+NHH3bp/kvy83X808/kFRCgenff5dJ949oZXl6qP/Ye1YztKGu1ICIX\ncAOu7MRFavXorrqjR+lcVpb2vvya7DbbJT8278eD2vnc73XoXzNlt9nUYNxv1f4fb1z3ofS//MLC\nVKt7N0IJ151aPbrJp1YtZa5eI1tuntvmSP1qkaTzp6N5KkvzZvKLiFDWmm9VfPq0S/d9/PMvVZKX\nrzp3/qbcH4Ch6glu0ZxQAtyEWIKpuqPuVK0e3ZW3d58O/mumHA7Hr95vy83VwX/9WzufnaL8Hw+q\nVq8e6vDOPxU94naPucMVcD2wWK2KGnab7OfOKWPZcrfMkPfjQeXu3qMa7dspsGEDt8xQFRgWi6Ju\nHyqHzab0pctctt+ijAylL/lavmG1FXXbEJftFwBuBMQSTBmGocZPPqagJo114ptvlbpgoSTJUVqq\n9GUr9P2jT/x857w6av2XP6rZ05PkG1p1nk4P4BfhA/rLKzBA6Uu/Vum5cy7fP6tKvwjr11fW4GBl\nLFuu0qIil+zzyMdz5CgpUf2x97j02XYAcCMglnBJXr6+avH8FPmEhuro7LlK+fIr7Xh2ig7PnCVH\nSakajB+ndjNe58nhQBVnDfBXxKA42c7k6sQ3a12676KMDGVv+k6BDRuqeru2Lt13VeTl66vIIYNU\nkpevzNVrnL6/3L37lL1hk4KaNFGtnj2cvj8AuNEQS7gsn5CaavHCFFl8fHT04zkqOHRYtfv0Uod3\n3lL07UNlsXKPEOB6EHnrEBlWq1IXxctRWuqy/abFL5HsdkUNH8bdI38WOWSQLD4+Slu02Kmfi/9+\nAG3DB8Zx/AHgGhBLKFdQTIyaT3lWIZ07qfXf/qymk56ST0hNd48F4Cr4hoaodu9eKkpL16ktW12y\nT1tunjJXr5FPrVqq1aObS/Z5PfCuXl1h/frqXFaWTm78zmn7yd6wUXn7Dyj05q5ufRAuAFzPiCVc\nkZodblKLP0zhQXjAdSx6+DBJv1xD5GwZy1fIfu6coobdyir0/4i6fahkGEr9atFFN9CpDHabTUc+\nniPDalX9+3gALQBcK2IJADxEQL26qhnbUXn79it37z6n7steXKz0JV/LKzBA4QMGOHVf1yP/yEiF\ndu2igkOHdGbX7krffvqSr3UuM0uRQwbJP9J9DyMGgOsdsQQAHuTCHemcvbqU9c23sp05o4i4gbIG\n+Dt1X9erC5+LtIWV+7mw5ebq+OdfyBoUpDp3jazUbQOAp3HpeRE2m01TpkxRamqqLBaL/vznP8tq\ntWrKlCkyDENNmjTRtGnTZLHQcADgDMGtWiqoSWOd2rxFZ1PT5B8dVen7cNjtSl24WIbVqsjbbq30\n7d8oqjVrquCWLZSTvE0FR48psH69Stnu8fmfq7SgUA0fuF/e1XiQNgBUhEurZO3atSopKdH8+fP1\n2GOP6R//+IdefvllTZw4UfPmzZPD4VBCQoIrRwIAj2IYxvkVDYdDqYvinbKPU5u3qCgtTbV795Jv\naIhT9nGj+GV1qXI+F2dT05SxfIX8IiMUMTiuUrYJAJ7MpStLDRs2VGlpqex2u/Lz82W1WrV9+3Z1\n7txZktSrVy9t2LBBA67g/Pbk5GRnj1ul9nuj4PhVDMev4jiGksPHW0bNGspcvUanW7WQERR0xa+9\nkuN3bvY8SdLppo043v/jf4+Hw2LIqBWqrG/X6kzb1jKCK7YSVPzpF3KUlqq0Rzdt27mzQtuqivh6\nqhiOH3D1XBpLAQEBSk1N1eDBg5WTk6OZM2dqy5YtZc9+CAwMVF5e3hVtq2PHjs4c1VRycrJb9nuj\n4PhVDMev4jiGv0i/86QOz3pPtVPSVP+e0Vf0mis5frl792lXSopqxnZUy0GDKmPUG8aljl/m3ad1\n8O1/q9ax42pQgTvXndm9R7v3H1BwyxZqfc+YG+65Svz5rRiO37UhMOHS0/A+/PBD9ejRQytWrNCi\nRYs0ZcoU2Wy2svcXFBQoODjYlSMBgEcK63+LrNWqKWPZcpUWFVXadi/cOOLC6WUoX+0+veVdo4Yy\nlq9USWHhNW3DYbfrp/c/lCQ1GM8DaAGgsrg0loKDg1Xt54tNq1evrpKSErVs2VJJSUmSpMTERMXG\nxrpyJADwSF6+voocMkglefnKXL2mUrZ5NjVNpzZvUVCTxgrmmWxXzOLtrcjbhqi0sFCZK1df0zZO\nrE1UwaHDqtWrp6o1aVzJEwKA53JpLI0bN0579uzRmDFjdN9992nSpEmaOnWq3nrrLY0aNUo2m01x\ncVyQCgCuEHnrYFl8fJS2aLEcpaUV3l7qonjJ4VD0iNtZ2bhKkYPjZPHzU1r8EtlLSq7qtaXnzuno\n7HkyvL1Vf+wYJ00IAJ7JpdcsBQYG6s0337zo7XPmzHHlGAAASd7Vqyvslj7KWL5SJzd+p9o9u1/z\ntopPn1bWmm/lFxGu0K5dKm9ID2ENClL4gH5KX7xUJ9etV1jfPlf82rRFi1Wcna3oO4bLLyzMeUMC\ngAfigUYA4MGibh8qGYZSv1okh8NxzdtJX7pMDptNUcOGyvDyqsQJPUfUsNski+WqPhfFOTlK+fIr\nWYODVWfkHU6eEAA8D7EEAB7MPypKoV07q+DQIZ3ZtfuatlFaVKSMZctlrVZNYf1vqeQJPYdfWJhq\n9eimwqPHdHrb9it6zbFPPpW9qEj1Ro+SNTDQyRMCgOchlgDAw0UNv/Bg1EXX9PrM1WtUkpevyCGD\n5OXrW5mjeZwLdxG8cFfByyk8dkyZqxLkXydaEXHlP58QAHD1iCUA8HDBzZupWovmyknepoKjx67q\ntY7SUqXFL5bFx0cRQwY7aULPERQTo+pt2+jMzl3KP3T4sh975MOPJbtdDcb9llMfAcBJiCUAQNmK\nRtrC+Kt6Xfam73QuM0u1+/aRT43qzhjN45StLl1mpe/09h3KSd6m6m3bqGYsDxoFAGchlgAACukU\nK//oKJ1IXKdz2dlX9BqHw3H+dDHDUPTwoU6e0HPUuKm9AhrU18n1G1WUlXXR+x2lpecfQGsYanD/\nfdymHQCciFgCAMiwWBQ1fJgcJSVKX/L1Fb0md/ce5R88pJAuneUfFeXkCT2HYRiKHj5MstuVFr/k\novdnrflGhUePKaxvHwXFNHTDhADgOYglAIAkKaxPb3nXqKGM5StVUlhY7sdfuAnBhdPGUHlq9ewh\nn9BQZa5KUEl+ftnbS8+e1dG5n8ji66t6945244QA4BmIJQCAJMni46PIWwertLBQmStXX/ZjC48d\nU07y96rWormCmzdz0YSew2K1KmrYbbIXFSlj+cqyt6d+tUi2nNOKHj5MvqGhbpwQADwDsQQAKBMx\nOE4WPz+lxS+RvaTkkh+X+tX5G0GwquQ84QP7yysgQGlLlspus+lcdrZSv1ok75o1OO4A4CLEEgCg\njHe1agrvf4uKs7N1ct160485l52tE4nr5B8dpZBOsS6e0HNYAwIUMWigbDmndeLbtTo25xPZi4tV\n/57R8vL3d/d4AOARiCUAwK9EDRsqWSxK/WqRHA7HRe9PX/K1HCUliho+TIaFf0acKfK2W2VYrTo2\n71NlffOtAhrUV9gtfd09FgB4DP6VAwD8il94mGp1v1mFR4/p9Lbtv3pfSWGhMpavlHeNGgrr09tN\nE3oO39AQ1e7VU8WnTkkOhxrefx8PoAUAFyKWAAAXiR4xXNIvd7y7IHPlapUWFiry1sGy+Pi4YzSP\nEz1imGSxqGbHDqrRvp27xwEAj2J19wAAgKonqFGMqrdtozM7dyn/0GEFNYqRo7RUafFLZPHzU8Tg\nOHeP6DEC6tXTTf+cId9a3P0OAFyNlSUAgKkLd1xLXXh+dcm+5wcVZ2crvP8t8q5WzZ2jeZyAunW4\nqQMAuAGxBAAwVeOm9gqoX08n129UUWaWSjZ+J1ks528AAQCAByCWAACmDMNQ9PBhkt2u/dPfkCPr\nhGp1u1l+4WHuHg0AAJcglgAAl1SrZw/5hIYo/8eDkngILQDAsxBLAIBLsnh7K/K2W8//ukF9BTVu\n5OaJAABwHe6GBwC4rMghg1R8KkfZ0ZHuHgUAAJdiZQkAcFlefn6KefB+WcJqu3sUAABcilgCAAAA\nABPEEgAAAACYIJYAAAAAwASxBAAAAAAmiCUAAAAAMEEsAQAAAIAJYgkAAAAATBBLAAAAAGCCWAIA\nAAAAE8QSAAAAAJgglgAAAADABLEEAAAAACaIJQAAAAAwQSwBAAAAgAliCQAAAABMEEsAAAAAYIJY\nAgAAAAATxBIAAAAAmCCWAAAAAMAEsQQAAAAAJoglAAAAADBBLAEAAACACWIJAAAAAEwQSwAAAABg\nglgCAAAAABPEEgAAAACYIJYAAAAAwASxBAAAAAAmiCUAAAAAMEEsAQAAAIAJYgkAAAAATBBLAAAA\nAGCCWAIAAAAAE8QSAAAAAJgglgAAAADABLEEAAAAACaIJQAAAAAwQSwBAAAAgAliCQAAAABMEEsA\nAAAAYIJYAgAAAAATxBIAAAAAmCCWAAAAAMAEsQQAAAAAJoglAAAAADBBLAEAAACACWIJAAAAAEwQ\nSwAAAABgglgCAAAAABPEEgAAAACYIJYAAAAAwASxBAAAAAAmiCUAAAAAMEEsAQAAAIAJYgkAAAAA\nTBBLAAAAAGCCWAIAAAAAE8QSAAAAAJgglgAAAADABLEEAAAAACaIJQAAAAAwQSwBAAAAgAliCQAA\nAABMEEsAAAAAYIJYAgAAAAATxBIAAAAAmCCWAAAAAMAEsQQAAAAAJoglAAAAADBBLAEAAACACWIJ\nAAAAAEwQSwAAAABgglgCAAAAABPEEgAAAACYIJYAAAAAwASxBAAAAAAmiCUAAAAAMEEsAQAAAIAJ\nYgkAAAAATBBLAAAAAGCCWAIAAAAAE8QSAAAAAJgglgAAAADABLEEAAAAACaIJQAAAAAwQSwBAAAA\ngAliCQAAAABMEEsAAAAAYIJYAgAAAAATxBIAAAAAmCCWAAAAAMAEsQQAAAAAJoglAAAAADBBLAEA\nAACACWIJAAAAAEwQSwAAAABgglgCAAAAABNWV+/w3Xff1Zo1a2Sz2TR69Gh17txZU6ZMkWEYatKk\niaZNmyaLhYYDAAAA4F4urZKkpCRt27ZNn3zyiWbPnq2MjAy9/PLLmjhxoubNmyeHw6GEhARXjgQA\nAAAAplwaS+vXr1fTpk312GOP6eGHH1afPn20Z88ede7cWZLUq1cvbdy40ZUjAQAAAIApl56Gl5OT\no7S0NM2cOVMpKSl65JFH5HA4ZBiGJCkwMFB5eXlXtK3k5GRnjlrl9nuj4PhVDMev4jiGFcPxqxiO\nX8Vw/CqG4wdcPZfGUo0aNRQTEyMfHx/FxMTI19dXGRkZZe8vKChQcHDwFW2rY8eOzhrzkpKTk92y\n3xsFx69iOH4VxzGsGI5fxXD8KobjVzEcv2tDYMKlp+F17NhR69atk8PhUGZmps6ePaubb75ZSUlJ\nkqTExETFxsa6ciQAAAAAMOXSlaW+fftqy5YtGjlypBwOh6ZOnao6deroxRdf1N///nfFxMQoLi7O\nlSMBAAAAgCmX3zr8ueeeu+htc+bMcfUYAAAAAHBZPNAIAAAAAEwQSwAAAABgglgCAAAAABPEEgAA\nAACYIJYAAAAAwASxBAAAAAAmiCUAAAAAMEEsAQAAAIAJYgkAAAAATBBLAAAAAGCCWAIAAAAAE8QS\nAAAAAJiwXu6dp06d0ty5c7VmzRodPXpUFotF9erVU79+/TR69GiFhIS4ak4AAAAAcKlLxtLcuXO1\ncuVKDRw4UK+88oqio6NltVqVkpKipKQkPf744xo0aJB++9vfunJeAAAAAHCJS8ZSWFiYPvroo4ve\n3rhxYzVu3Fj33HOPVqxY4dThAAAAAMBdLnnN0oABAy56W1FRkfLz88t+HxcX55ypAAAAAMDNLnvN\n0n/7/PPPNXv2yiGJ/wAAIABJREFUbDkcDvXv319PPfWUM+cCAAAAALe65MrSwYMHf/X7FStWKD4+\nXosXL9bixYudPhgAAAAAuNMlV5Y++eQTlZSU6NFHH1V4eLjatGmjBx54QFarVa1bt3bljAAAAADg\ncpeMpRdffFE//fSTXnvtNUVHR2vChAnKysqSzWZTs2bNXDkjAAAAALjcZR9K27BhQ73xxhvq27ev\nnnnmGSUmJiomJsZVswEAAACA21wylubNm6f+/fsrLi5OWVlZmjlzpqKiovTwww8rPj7elTMCAAAA\ngMtdMpY+/PBDrVixQl988YXefvttSdLAgQM1a9asX90+HAAAAABuRJe8ZikqKkp//etfdfbsWTVt\n2rTs7V5eXhozZoxLhgMAAAAAd7lkLM2aNUvr1q2Tt7e3unfv7sqZAAAAAMDtLnka3oYNG9SvXz/1\n6tVLXl5eph+TkJDgtMEAAAAAwJ0uubKUkpKi8ePHKy4uTrGxsYqIiJC3t7dSUlL03XffadmyZerf\nv78rZwUAAAAAl7lkLI0dO1ZDhgzR3Llz9fTTT+vo0aOyWCyqV6+e+vbtqxkzZqhWrVqunBUAAAAA\nXOaSsSRJoaGhevLJJ/Xkk0+6ah4AAAAAqBIu+1BaAAAAAPBUxBIAAAAAmCg3lk6cOOGKOQAAAACg\nSik3lu69915NmDBBy5YtU3FxsStmAgAAAAC3KzeWVqxYoQkTJmj9+vUaPHiw/vSnP2nXrl2umA0A\nAAAA3Oayd8O7IDY2Vq1bt9by5cs1Y8YMrVmzRiEhIZo6darat2/v7BkBAAAAwOXKjaVNmzZp4cKF\n2rhxo3r37q0ZM2aoQ4cO2r9/vx566CElJia6Yk4AAAAAcKlyY+ntt9/WyJEj9dJLL8nf37/s7c2a\nNdP48eOdOhwAAAAAuEu51yy9++67KiwslL+/vzIzM/Xmm2/q7NmzkqRx48Y5ez4AAAAAcItyY+mZ\nZ55RVlaWJCkwMFB2u13PPfec0wcDAAAAAHcqN5bS0tI0adIkSVJQUJAmTZqkY8eOOX0wAAAAAHCn\ncmPJMAzt37+/7PeHDh2S1XpFN9EDAAAAgOtWudUzefJkjR8/XuHh4ZKknJwcvfbaa04fDAAAAADc\nqdxY6tatm7755hsdOHBAVqtVMTEx8vHxccVsAAAAAOA25cbSkSNHNGfOHBUWFsrhcMhutyslJUVz\n5851xXwAAAAA4BblXrP0u9/9TsHBwdq7d69atGihtLQ0NWnSxBWzAQAAAIDblLuyZLPZ9OSTT6qk\npEQtW7bUXXfdpd/85jeumA0AAAAA3KbclSV/f38VFxerQYMG2rNnj/z8/FwxFwAAAAC4VbmxNGzY\nMD388MPq06eP5syZowcffLDszngAAAAAcKMq9zS82NhYDR8+XEFBQZo9e7Z27dql7t27u2I2AAAA\nAHCbcleWJk2apKCgIElSRESEBgwYoICAAKcPBgAAAADuVO7KUuPGjfX222+rXbt2v7peqVOnTk4d\nDAAAAADcqdxYOn36tJKSkpSUlFT2NsMw9PHHHzt1MAAAAABwp3Jjafbs2a6YAwAAAACqlHJjaezY\nsTIM46K3s7IEAAAA4EZWbiw98cQTZb8uKSlRQkKCgoODnToUAAAAALhbubHUuXPnX/2+W7duuvPO\nO/XUU085bSgAAAAAcLdyYyktLa3s1w6HQwcPHtTp06edOhQAAAAAuFu5sXTvvfeW/dowDIWEhOiF\nF15w6lAAAAAA4G7lxtKaNWtks9nk7e0tm80mm83GQ2kBAAAA3PAs5X3AsmXLdMcdd0iS0tPTNXjw\nYK1evdrpgwEAAACAO5UbS++8844++OADSVK9evW0YMECvfXWW04fDAAAAADcqdxYstlsqlWrVtnv\nQ0ND5XA4nDoUAAAAALhbudcsdezYUb/73e80dOhQGYahpUuXqn379q6YDQAAAADcptxYmjZtmmbP\nnq1PP/1UVqtVnTp10ujRo10xGwAAAAC4TbmxZLPZ5Ofnp5kzZyozM1Pz589XaWmpK2YDAAAAALcp\n95qlp59+WllZWZKkwMBA2e12Pffcc04fDAAAAADcqdxYSktL06RJkyRJQUFBmjRpko4dO+b0wQAA\nAADAncqNJcMwtH///rLfHzp0SFZruWfvAQAAAMB1rdzqmTx5ssaPH6/w8HAZhqFTp05p+vTprpgN\nAAAAANym3Fjq1q2bvvnmG+3bt0+JiYlat26dHnroIW3bts0V8wEAAACAW5QbS8ePH9dnn32mL7/8\nUrm5uXr44Yf173//2xWzAQAAAIDbXPKapVWrVumBBx7QnXfeqdOnT2v69OkKCwvT448/rpCQEFfO\nCAAAAAAud8mVpSeeeEKDBw/Wp59+qvr160s6f7MHAAAAAPAEl4yl+Ph4LViwQGPGjFF0dLRuvfVW\nHkYLAAAAwGNc8jS8pk2basqUKVq7dq0mTJigpKQknTx5UhMmTNDatWtdOSMAAAAAuFy5z1myWq3q\n37+/3nnnHSUmJqpr16564403XDEbAAAAALhNubH030JCQjR+/HjFx8c7ax4AAAAAqBKuKpYAAAAA\nwFMQSwAAAABgglgCAAAAABPEEgAAAACYIJYAAAAAwASxBAAAAAAmiCUAAAAAMEEsAQAAAIAJYgkA\nAAAATBBLAAAAAGCCWAIAAAAAE8QSAAAAAJgglgAAAADABLEEAAAAACaIJQAAAAAwQSwBAAAAgAli\nCQAAAABMEEsAAAAAYIJYAgAAAAATxBIAAAAAmCCWAAAAAMAEsQQAAAAAJoglAAAAADBBLAEAAACA\nCWIJAAAAAEwQSwAAAABgglgCAAAAABPEEgAAAACYIJYAAAAAwASxBAAAAAAmiCUAAAAAMEEsAQAA\nAIAJYgkAAAAATBBLAAAAAGCCWAIAAAAAE8QSAAAAAJgglgAAAADABLEEAAAAACaIJQAAAAAwQSwB\nAAAAgAliCQAAAABMEEsAAAAAYIJYAgAAAAATboml7Oxs9e7dW4cOHdLRo0c1evRojRkzRtOmTZPd\nbnfHSAAAAADwKy6PJZvNpqlTp8rPz0+S9PLLL2vixImaN2+eHA6HEhISXD0SAAAAAFzEcDgcDlfu\n8C9/+Yt69+6tWbNm6aWXXtK4ceOUmJgowzC0evVqbdiwQdOmTbvsNpKTk100LQAAADxZx44d3T0C\n3Mjqyp0tWLBAISEh6tmzp2bNmiVJcjgcMgxDkhQYGKi8vLwr2pY7vnCTk5P5A1MBHL+K4fhVHMew\nYjh+FcPxqxiOX8Vw/K4NP6CHS2Ppyy+/lGEY2rRpk/bu3avJkyfr1KlTZe8vKChQcHCwK0cCAAAA\nAFMujaW5c+eW/Xrs2LF66aWXNH36dCUlJalLly5KTExU165dXTkSAAAAAJhy+63DJ0+erLfeekuj\nRo2SzWZTXFycu0cCAAAAANeuLP232bNnl/16zpw57hoDAAAAAEy5fWUJAAAAAKoiYgkAAAAATBBL\nAAAAAGCCWAIAAAAAE8QSAAAAAJgglgAAAADABLEEAAAAACaIJQAAAAAwQSwBAAAAgAliCQAAAABM\nEEsAAAAAYIJYAgAAAAATxBIAAAAAmCCWAAAAAMAEsQQAAAAAJoglAAAAADBBLAEAAACACWIJAAAA\nAEwQSwAAAABgglgCAAAAABPEEgAAAACYIJYAAAAAwASxBAAAAAAmiCUAAAAAMEEsAQAAAIAJYgkA\nAAAATBBLAAAAAGCCWAIAAAAAE8QSAAAAAJgglgAAAADABLEEAAAAACaIJQAAAAAwQSwBAAAAgAli\nCQAAAABMEEsAAAAAYIJYAgAAAAATxBIAAAAAmCCWAAAAAMAEsQQAAAAAJoglAAAAADBBLAEAAACA\nCWIJAAAAAEwQSwAAAABgglgCAAAAABPEEgAAAACYIJYAAAAAwASxBAAAAAAmiCUAAAAAMEEsAQAA\nAIAJYgkAAAAATBBLAAAAAGCCWAIAAAAAE8QSAAAAAJgglgAAAADABLEEAAAAACaIJQAAAAAwQSwB\nAAAAgAliCQAAAABMEEsAAAAAYIJYAgAAAAATxBIAAAAAmCCWAAAAAMAEsQQAAAAAJoglAAAAADBB\nLAEAAACACWIJAAAAAEwQSwAAAABgglgCAAAAABPEEgAAAACYIJYAAAAAwASxBAAAAAAmiCUAAAAA\nMEEsAQAAAIAJYgkAAAAATBBLAAAAAGCCWAIAAAAAE8QSAAAAAJgglgAAAADABLEEAAAAACaIJQAA\nAAAwQSwBAAAAgAliCQAAAABMEEsAAAAAYIJYAgAAAAATxBIAAAAAmCCWAAAAAMAEsQQAAAAAJogl\nAAAAADBBLAEAAACACWIJAAAAAEwQSwAAAABgglgCAAAAABPEEgAAAACYIJYAAAAAwASxBAAAAAAm\niCUAAAAAMEEsAQAAAIAJYgkAAAAATBBLAAAAAGCCWAIAAAAAE8QSAAAAAJgglgAAAADABLEEAAAA\nACaIJQAAAAAwQSwBAAAAgAliCQAAAABMEEsAAAAAYIJYAgAAAAATxBIAAAAAmCCWAAAAAMAEsQQA\nAAAAJoglAAAAADBBLAEAAACACWIJAAAAAEwQSwAAAABgglgCAAAAABPEEgAAAACYIJYAAAAAwASx\nBAAAAAAmrK7cmc1m0/PPP6/U1FQVFxfrkUceUePGjTVlyhQZhqEmTZpo2rRpslhoOAAAAADu5dJY\nio+PV40aNTR9+nTl5ORoxIgRat68uSZOnKguXbpo6tSpSkhI0IABA1w5FgAAAABcxKVLOIMGDdJT\nTz1V9nsvLy/t2bNHnTt3liT16tVLGzdudOVIAAAAAGDKcDgcDlfvND8/X4888ojuuusuvfrqq1q/\nfr0kadOmTfryyy/1+uuvX/b1ycnJrhgTAAAAHq5jx47uHgFu5NLT8CQpPT1djz32mMaMGaOhQ4dq\n+vTpZe8rKChQcHDwFW3HHV+4ycnJ/IGpAI5fxXD8Ko5jWDEcv4rh+FUMx69iOH7Xhh/Qw6Wn4Z08\neVLjx4/Xs88+q5EjR0qSWrZsqaSkJElSYmKiYmNjXTkSAAAAAJhyaSzNnDlTubm5eueddzR27FiN\nHTtWEydO1FtvvaVRo0bJZrMpLi7OlSMBAAAAgCmXnob3wgsv6IUXXrjo7XPmzHHlGAAAAABQLh5o\nBAAAAAAmiCUAAAAAMEEsAQAAAIAJYgkAAAAATBBLAAAAAGCCWAIAAAAAE8QSAAAAAJgglgAAAADA\nBLEEAAAAACaIJQAAAAAwQSwBAAAAgAliCQAAAABMEEsAAAAAYIJYAgAAAAATxBIAAAAAmCCWAAAA\nAMAEsQQAAAAAJoglAAAAADBBLAEAAACACau7BwAAALiczSnbdercKXePAcADEUsAAKDKOph9RK9v\neFdBXgHqZeuhAG9/d48EwINwGh4AAKiyPt+zVJKUX1qo+bvi3TwNAE9DLAEAgCrpYPYRbUvfrWa1\nGinEu7pW/LhWB7OPuHssAB6EWAIAAFXS53uWSJLubjNMcWE95JBD726dqxJ7qZsnA+ApiCUAAFDl\nHDh5WNvS96hVWFO1Cmuqev6R6tuwm46eTtHXBxLcPR4AD0EsAQCAKueLn69VurPVrWVvu7fdCFXz\nDdJnu5coqyDbXaMB8CDEEgAAqFIOnDys7Rk/qFVYU7UMa1r29mq+Qbqv/UgVl9r0/5I/kcPhcOOU\nADwBsQQAAKqUC9cq3dnqtove17N+Z7UNb6Ft6Xu06Xiyq0cD4GGIJQAAUGXsP3lIOzL2qnVYM7UM\na3LR+w3D0IOxo+Xt5a0Ptn2u/OICN0wJwFMQSwAAoMr4fPfP1yq1vvWSHxMRVFu/aTlYZ4pyNW/n\nIleNBsADEUsAAKBK2HfikHZm7lWb8GZqUfviVaX/NqzZANUNjtTqQ+u078QhF00IwNMQSwAAoEr4\n5VqloeV+rNXLqgmd7pEkzdo6VyWlJU6dDYBnIpYAAFVWSWmJNh5L1t83/kc7M/a6exy3KLIV6b3k\nT7Qj4wd3j+JU+04c1K7MfWob3kLNaze6otc0q9VIAxr1VEpuuuL3r3LyhAA8kdXdAwAA8L/S8jK1\n5vAGffvTJuWey5ckbU/foz/3e0b1a9Rx83SuY3fY9VbSh9qSukMbjm7RjCEvqYZfsLvHcoqyVaXL\nXKtkZkzb4dqSukNf7vla3ep2VES1MGeMB8BDsbIEAKgSbKU2rT+6RX/8ZoYmfv2S4vetksPh0G3N\n+mt8h1EqKjmnV9f9W6eLct09qsvM3xWvLak7VNOvugpsZ/XRts/dPZJT7D3xo3Zl7le7iBZqVuvK\nVpUuCPQJ0Lib7pLNXqL/JM/j2UsAKhUrSwAAt0rNzVDCofVae+Q75f18G+jWYc3Ur1F3dY5uL28v\nb0lSoe2s5u+K1+vr39XUvhPl8/Pbb1Rrf/pOC/euUGRQmP7c/1m9kvgvbTi2Vb0bdFX7yFbuHq9S\nfbb70s9VuhI31+2gtUdaa1v6bq07ulm9GnSpzPEAeDBWlgAALldcatO6I5s1bc3fNWnZH7XkQIIM\nw9Cw5gP15pA/amrfieper1NZKEnSiBaD1KNeJx3IPqx3t8y5oVcQ9p04pHe3zlWgt78m93xEwb5B\nmhB7jyyGRe8lf6JzJcXuHrHS/JB1QHuyDqhdREs1rRVzTdswDEMPdLxbvl4++mj7F2WnbgJARbGy\nBABwmZQz6Vp9eL0SjySVPUy0TXhz9W/UQ52i2snqdel/lgzD0MOdxyqz4KTWHd2s6OAI3dFysKtG\nd5msgmy9vmGm7A67JnV7SFHBEZKkBjXr6LZm/RS/b5W+2LNU97Qb4eZJK8fne84/V+mu1te2qnRB\nWGCo7mo9VLN3fKk5Oxbo0c6/rYzxAHg4YglAlVdcatPeEz+qVVgzWS1e7h4HV6m4pFibjn+v1YfX\na//J88/Dqe5bTcNbxOmWmO6KCKp9xdvy8fLWsz0e1u9XvaL5u+IVHRyhLnVuctboLldoO6tX172j\n3HP5erDjaLWNaPGr949sdas2Hf9ei/evVo/6na77m13s+XlV6abIVmoS2rDC2xvStK/WHU3Stz9t\nUu8GXdUqrGklTAnAk3EaHoAqLTltl55e9if9de1bej95vrvHwVU4djpV73//qf4vfor+tfkj7T95\nSO0iWuh33R7Sv4f+TWPaDr+qULqghl+wJvd4VL5WX7393Yc6fOqYE6Z3Pbvdrn9uel/Hz6RpUJM+\nGti410Uf42f11YMd75bdYdesLXNlt9vdMGnl+byC1yr9Ly+LlybE3iPDMDRr61wVl9oqZbsAPBcr\nSwCqpIz8E/pw2+f6Pm2XLIZFNf2ra/Xh9Wof2Uqd67R393i4hHMlxdp0PFmrD63XgezDks7HzYjG\nvdUvprvCgmpVyn4a1Kyjp7rer+nr39Vr6/+tvw2YrBD/GpWybXeZs2OBvk/frXYRLXVf+5GX/Lib\nIlurW92O2ng8WasOrVNck94unLLy7M7crx9O/KibIlurcWiDSttu49AGGtS4j5b9+I0W7l2uu1qX\n/4BbALgUYglAlXKupFgL965Q/L6VstlL1CqsqcZ3GCVDhqaselkzt8xR45AGCgm4vr8xvtEcyUlR\nwuH1Wnd0swptZ2XI0E2RrdQvpoc6RLVxyumTsdHtdE+74Zqz4ytNXzdTL93yO/lafSp9P66QcGi9\nlhxIUHRwhCbd/KC8yjle4266UzsyftC8XQvVqU676y4UHQ7HL89VanV1z1W6Ene3GaaklG36au8K\ndasXqzrBkZW+DwCegdPwAFQJDodDm1O263fL/qgvf/ha1XyDNPHmBzS1z0TVrR6lOtUjdV/7O5Vf\nXKC3kj647k8/uhEUlZzTmsMb9YdVr+q5lX/VioNr5Wv10W9aDtHbt/1Zv+/1uDrXae/U68yGNhug\nPg1v1qGco3pn88eyO66/r4s9WQf0XvInquYTqMk9H1WAj3+5r6nhX133tBuhs7YiffD9Zy6YsnLt\nydqvvScOqkMlrypd4O/tp/EdRqnUXqr/bJ13XX5dAKgaWFkC4HZpeZn68PvPtD3jB3lZvDSs+UCN\nbDlYft5+v/q4/o16aFvGHm1N3aH4/as0vEWcmyb2bD/lHNfqQ+u0/ugWnS0pkmEY6hDVRv1juuum\nyNblropUJsMw9FDH0crMP6FNx5MVHRxR4buquVJGXpbe2DBLMgw93f3/ruoarltiumvtkSQlpWzT\n1tSdio1u68RJK4/D4fjluUpO/Fx1rtNenaLbaUvqDn370ybdEtPdafsCcOMilgC4TVHJOS34YZmW\n7E9Qib1EbcKba3yHUYr++VbJ/8swDD3c6V49e+qIPt0Vr9ZhzZzyU2lc7KytSNvP7NMXK1fpUM5R\nSVKof03d1qyf+sZ0U62AELfN5u3lrae7TdDzq1/VF3uWKjo4XN3rdXLbPFeqoLhQr677t/KLC/Rw\np7FqGdbkql5vMSyaEDtGz638m/7f9/PVOqzpRT9gqIp2Ze7TvpOH1CGqjRqF1HfqvsZ3GKXdmfs1\ne8cCdYxqo+p+wU7dH4AbD7GEKs9ut2v+7nglHN6gTtHt1D+mhxqF1JdhGO4eDdfI4XAoKWWbPtr+\nhbILcxQaUFP3tR+pLnVuKvfzGuwbpMe7jNNfvv2n/vnd+3pt4PPXxTeI17M9WQc0ff3M89ciGYZi\no9qqf6Meah/RShZL1TibO9ivmib3fFQvJEzXO5tnKzywdpUO6VJ7qWZsfE+peRka2qy/bonpdk3b\nqVs9Src3H6AFPyzXp7uX6L6bLn1jiKrg/LVKPz9XyQnXKv2v0ICaurvNMH2w7TN9tO0LPXnzeKfv\n80aTW5SnGZveU1pephrWrKeYC/+F1LvurpUDrgWxhCot71y+3tz0vnZm7pWXYdGawxu05vAGNahR\nR/0b9VCPep2v6Px+VB2puRl6//tPtStzn6wWq0a0GKQRLQfJz+p7xdtoE95cQ5sPUPy+lXp/22c8\nfNKJdmfu0yvr3pHd4VD3kA66t/tIhQbUdPdYpupWj9LEmx/QK+veKbtDnjtXvC7no21faGfmXnWI\naqN72lbs4bJ3tBisjceS9fWPa9SzfifFOHm1piJ2Ze7T/pOHFBvV1mVzxjXurcSjSVp/bIt6N+yq\ndhEtXbLfG8GZolz96ds3dfxMmoJ8AvV92i59n7ar7P01/ILLwul8RNVXTf/q/DATNxRiCVXWkZzj\nmr7hXZ0oyFaHqDZ6vMt9Oph9VKsPr9PW1J16L3m+Zm9foG71YtW/UQ81DmnAX9BV2Flbkb784Wst\n3Z+gUodd7SNa6v4OoxRZLeyatnd366HanblP/7+9+w6rqv7jAP4+98IFZC+RPRRUQJkKKkKKprlT\n3CPTcjSsfrnammZZrrJMLTNXmWE2zcpCERkKyFRzsWSJbFCGcH5/ADfQazmAe4H363l6HuGce8+H\n07nn3vf9rmMpEXDv4oz+Nt7NXDEl5p7H2vqgtHjAPIjZVSoblBp4mLviCfcgfHnmW7x/4lO8Hbj4\nvoJ4a/jt4nEcuXQMNvqWeMF3zkO3zsnUZHjaexpWHfsQ26L3Yc2QZa06buxeiaIoX1cpqBValRpI\nJBLM956O5X+8h8+jv8a64W+02VkTW1NxRQneDtmEjJJsDHd8BE96TEJxRQmuFGbgSmE6rhSmI6Ug\nHbHZSYjNTpI/Tr8hQDUKUUZaBnx/pjaLYYlUUljaKWw9vRdVNdUIchmJIJcRkAgSuJs7w93cGYU3\ni3EsJQJ/XglDSEo4QlLCYaNviSFd/TDQti+0ZZ2U/SdQPVEUEZ4Rjd1xB1F4sximnYzwhMdE9LF0\ne6g3TzWpGhb1m4Nlv7+L7dFfwdHYHqbaxs1YeceWWN+iJIoiFg+YD08LV8Rkxyi7rHvymOMgXC3J\nwdHLJ7A5cideHjAPEkE1ugsm5JzDzjMHoK+hi2UDF0KrmbqQ9jLrAX87H4SmRuHXi8cwqntgszxv\nc0rIPYe/86/A29INDkY2rXpsO0NrjHQajJ/+PoqDZw9jWu9xrXr8tqaoPihdLcnGY46DMNtjIgRB\ngIGWPjy19OFp4Srfty5ApeNKQbo8RJ3JTsKZxgFKQxcORjb/dOMzsoGxliEDFLUJDEukUmpqa7Av\n/hB+vvAntNQ1sbTfXHhbut2xn6GWPh53Ho6xPR9FUu7fOHo5DKcz4/BF7DfYG/8d+ll7YUhXPzgZ\nO/BmrEQZxVn4IvYbJF+7AHWJGoJcRmBsj2HN9q2uha4Z5nhMwqen92Bz5E6sGPQ/lRlD05Yl5JzD\n2rBPAVHEEr/58DB3/e8HqRBBEDDHczJySq/hdGY89if+qBIfjvOrivBV+D5IBAkW+81v9nA/y20C\nzmQl4Zukn+Br5QETbdXpgthkBrxWbFVqbKLrKERmxOKn83/Az6YPbAwslVKHqmsclEY4DsIT9UHp\nbvQ19eBh7trkPlFSUSoPTg0h6kx2Ms5kJ8v30dPQadT6ZAsHQxsYd2KAItXDsEQqo2EQafK1C7DU\n7YIlfvNhcZdZ0RpIBAl6d+mJ3l16oqiipL616SSOp0bieGokrPXMEdjVD/52PtCRabfSX0I3qm8i\nOOkX/HoxBDViLTwtemG2x8T7mhb5Xj1i3w9ncpIRmRGL784dQZDLiGY/RkfSNCgtgLu5i7JLeiBq\nEin+1/9pvHb0fXx/7jdY6nZBgL2v0uoprSxDcPbvuFF9E8/5zEZ3k67Nfgw9TV3MdJ+ALad24/PY\n/Vjmt1BlPnjG55zDxfwU9LF0g72htVJq0FTTwFPeU/Fu6CfYFr0PqwIXq0yLo6ooulmMlcc2IbMk\nByOdAjHLfcIDXUN6mrpwN3dpcv8oqSyrD05p8i58cTlnEZdzVr6PbkOAatSFz6STkcpcx9QxMSzd\no9TCqwgriIVjhRP0NHWVXU67c6UgDR+c3Ib8G4XoY+mGZ32eQCf1+5u4wUBTD+N6DsOYHkNx9toF\nHL0chqjxzBUNAAAgAElEQVTMOHx55lvsS/ge/aw8Edh1AHqYdOONt4WIoogTaaewN/47FFWUwEzb\nBLM9J8HLoleLHVMQBMzznoaL+SkITv4Fvcy6t8gH0Y4gPucs3j/xKQBgid9CuJu37YHwOhraWDZw\nIV47+j62Re+DmY4pepi2/rVxq+YWNoR/hqLqEjzeczj87Xxa7FgBdr44nhqJ2KxERF09A19rzxY7\n1r2qG6v0EwDltSo18DB3RT9rL0RkxODo5RN4tFuAUutRJYU3i/F2yCZkluZglFMgZj5gULobPQ0d\neVf6BqWVZUhpGANVH6Tic84ivnGAkmnD3tAGQ7r6qcT1TB0Pw9I9OpOdhJMFsYg7fA6Te43Bo139\n2d2nmRxLicBn0V/hVm0NpvQag3E9hz3Ut30SQQJXsx5wNeuBkopSHEuNxJ+XwxCaFoXQtChY6nZB\nYFc/BNj5QFdDpxn/ko4tregqvoj9BufyLkFdqo5JrqMwpsejkEnVW/zYOjJtLPJ9EitCNuKjyJ34\n4NHXOEvifYrLPosPwtpPUGpgodcFL/V/GmtCP8a6k1uxZuhydG7FsW2iKGJHfVdUJ207TO41ukWP\nJwgCnvaehiVHVmNn7AH0Nuup9NdCXE4yLhakoq+lO+yU1KrU2JMeExGfcxb7Er6Ht6Ubp79GXVBa\nGbIRWaW5GNV9CGa6jW+VLxV1NXTkvUMalFWW/9OFr74FKiH3HAQBDEukFNIVK1asUHYR9ys7OxsW\nFhatekwnY3sUXStAemUOTmfGIzorAdb6lirVJ1zV3f7/7VZtDb6M/RZfJ/4ATTUNvDxgHgY7DGjW\nG7SGmga6m3TFcMdH4NLZCbdqb+Hv/Cs4k52EwxdCkFmSA10N7TbRzK+M6/5elFfdwL74Q9h6ei/y\nyvPRx9INy/wWoo+Ve6vOyGWqbYya2hrEZCXg+o0C+Fh73LGPqp5DZYvLTsYHYVsBQcDSgXcPSm31\n/JnpmEJPQwcRGbFIzD2PgbZ9od4KIR4ADl/4C4fOHYG9gTXGmA6CjWXLhwVdDR2IAGKyEnDj1k14\ntmDL7n8RRRGbI79Ewc0ivNh/LgweYlHY5rr+NNU1oa3eCVFXz+B6eSH62Xg99HO2BXc7f42D0uhW\nDEp3I1OT1bcCd0M/ay+McBqMEU6DEWDfTyndJtvqfY+aD1uW7pFUIoW3gSsmD3gc++IP4XhqJN78\nax387Xwww238Q70BdERFFSXYGP4ZzuVdgrW+BZYMmI8uDziF9L0QBAEunZ3g0tkJJZVlCE2NxNHL\nYQhLP42w9NMw1+2MIQ4DEWDvCz22Nt2TWrEWoalR2Bd/CMWVpeiiY4o5npOVOsYlyGUkEnPPIyz9\nNNzNXVq0u1N7cSY7CR+EbYMgCFjmt7DJN7ztyaPdAnC1JAdHLh7DRxFfYKnfwhbvHRCblYTd8Qdh\noKmHpQMXIvXclRY9XmNjewzFybTT+OPSCfjb+sDJxKHVjt3YmexkXCpIhY+VB2wNrJRSgyKBXQcg\nNDUSkVdjEZOV2KJdhVVZwc0irAzZiOzSaxjT41FM7z1OJb845Ay3pEzsR3afDDT18KzPE1gVuBh2\nBlYITY3CC4ffwuELf6GmtkbZ5bUJF/NTsPz3d3Eu7xJ8rT3xTuCSFg1Kt9PT0MGo7kOw8bG3sGLQ\n/+Bn2xfXywuwJ/4gFvz4CjZF7EBS7t8QRbHVamprUgoz8Naf67Hl1G7cvFWBKb3GYP3wN5Q+GYCa\nRIpFvk9CS00TO2L2I6csT6n1qLrYrI4RlBo84R4Ety7OiM1Owt6EQy16rPSiTHwYsQNqEjUs9VvY\n6utTqUvVMa/PNIgQsb2+m3Nra7qukmpNvCIRJHjaexqkggQ7YvajorpC2SW1uoIbRVj5V11QGqvC\nQYlI2dgN7wGPa9LJCIEOftDT1MXZaxdwOjMepzPjYaVnzrVe7iI7OxvnK1KwIfwz3Lh1E9N7P47Z\nHhNbrTvM7QRBgKm2MXysPDCsWwAMtfSRW34dZ69dwPHUSISlnUJVTTXMdU1VYlFLVegKUFZVjt1x\nB7E9eh+u3yiEj5UHlg98Bl6WvVVmEUwdWV23ypMZ0biUn9Kk64YqnENVEZuViHUnt0MiCFg+8Jl7\nCkpt/fxJBAm8LXrjdFY8YrISYNzJEPaGzb/eT3FFCd4+9iGKK0uxyHcO3Oq7Nbb2+TPVNkb+zSLE\n5SRDQ02GHqbdWu3YQF2r5U9/H4WvlScecxr00M/X3OdPX1MP1TW3EJudiOqaW/L/T+1V4/NXcKO+\nRansGsb1HIZpDEp31dbve/TwGJYe4riCIKCbsR0G2/dHWVU54nLO4lhqBLLL8uBobN9siw22B9U1\n1didcBA/p/yFTupaWOq3AAH2vipzc5apyeBobI9h3QLQ26wnasQaXMhPQVxOMg5fDEF6cSa01LRg\noKkLNalyeq8q84ZdXnUDJ1Kj8MHJbTiXdxEWumZ4od9cPO48XOmDxxWxNbBEdlke4nKSIaIWrmY9\nAPBNr0FMViLWNwpKverPz39pD+dPXaoOd3MXnEg7hairZ9DT1LFZJ3yorqnGuye2IL04ExNdRmK4\n4yPybco4fz1MuuJYSgQScs9hgI13qy2hUDdWaScKK4rxYr+50G+Gruotcf66GzsgPCMGZ3KS4WXe\nC4Za+s36/Kqk4fzl3yjEypCNyCnLw7iewzC111iVeS9WRe3hvkcPh2GpGY6roaYBb0s3uJu7ILUw\nA/E5Z3H0chjUJGroamTb4ddxKLhZhPdCtyC56CJsDazw1iMvwsHIVtllKSQIAky0jdDXyh3DuvnD\nSMsAeTcKcPbaBZxIO4Xvz/2O8IxoXMxPwfXyAtSINdCRaUO9FQJUa133ZVXl+Pv6FURmxOLXiyH4\nKuF77Es4hJisRAiCgCmuY/CczxMw1zNr8VoeRq/OPRCeEY2YrCS4dHaEqbYx3/QARGcmYH34dkgF\nCZYPfFYeJO9Fezl/OjJtOBrbITTtFE5nxsPHyh06Gg8fIkRRxKen9yA2KxH9rb0wx3Nykw+hyjh/\nMjUZjLT0EZ4Rg6zSHAy07dsqH4xjshLx84Wj8LX2bBIYH0ZLnD+pRAorfXMcT43ElcJ0DLZv3kmG\nVEl2djY0DLSwImQjcsvyMN55OKYwKP2n9nLfowfHCR6akaOxPdYMWYY/r5zE14k/YE/8QYSkhGOO\n52S4mnVXdnlKcT7vMjaEb0dRRQmcdbrilcBF0FCTKbuse6Ij08ZjToMw3PERXMxPQWRGbN00poUZ\nyCzJwYm0UwAAAQLMdTs3WUTPztD6vteJUgZFU7Tmll9vso+2rBN6mfVAVyNbDOsW0OpjLx5UJ5kW\nFvnOwZt/rcfmyC/xwfDXlF2S0kVnxmN9+GdQE6RY7v8sXDo7KbskpXHu7ISnvaZi6+m9WHviU6we\nsuShB5H/cP53hKZGoauRLZ7pO0tlPoQOsOmD46mRiM85h5Pp0fCz7dOixxNFEd8m/wwBAoKcVWus\nkiK9zHrA39YHoWlROHLpGEY4DVZ2SS2ipLqsUVB6DJNdR6vMNUqkyhiWmplEIsHQbgPha+2BrxN/\nxJ+Xw/D2sU3ob+2Fme4T2swHzYcliiL+uByKnWe+hSiKmOUehC6l+m0mKDUmCAKcTBzks0nVirXI\nKcurX0AvHSn1QaNhZj2gLkB10TWtX4ncFg5GNrBXcoBqEozqF/+7Vp7fZB8dmTZ6m/WUhz4HQxuY\nahu32TdUJxMHTHQZiW+SfsL201/BX+PO6cQ7itOZ8dhQH5Re8X8Wzh04KDUY7DAAV0ty8PPfR7Ep\n4nMsH/jsA4+9O3U1Dl8n/ABjLUMs9VsImQrd6wRBwFNeU/HykVXYdeZbuHdxbpaWtLuJyUpASmEG\n+ll7wcbAssWO05xmuU9AbHYS9if+iL5W7jDp1L6WBbleXoCvM39B0a1STHAegUmuo9rsfZ2otTEs\ntRBdDR3M856GQIcB2BGzH+EZMYjJTkKQ8wiMdBqstHEvraGqpho7YvYjJCUcuho6eKnfU3A1646Y\nmBhll9YsJIIEFrpmsNA1k39DWyvWIrfsOq4UpjUKURk4mR6Nk+nR8sea63SGfaMg4mBo0yJjfkor\nyxqForr/8m4LRroybbh16Qn7hlqMbGHaBtabul+P9xyOhNxziLwaC4PO2vCGt7JLanWnrsZhY8Tn\nDEoKzOj9OLJKcxGblYhdZ4Ixx2vyfT9HamEGNkfuhEyqjqUDF6rkuBczHVMEuYzEVwnfY2/CISzo\nM6NFjlM3A94vECBgosvIFjlGS9DT1MVMt/H49PQefBHzDZb4LWg398Lr5QVYEbIBRbdKEeQyAhNd\nGJSI7kf7/cSuIroa2WL1kCU4lhKBffVjPxq65rXHaXqv3yjA+pPbcbkgDfaG1lgyYEGHWLhXIkhg\nrtsZ5rqdMcDmnwB1rex6k9aclMJ0hKdHI7xRgOqiY9qkC5+9oc19dQcqqSyTtxQ1dKXLu1HQZB9d\nDR24dXFucpy2sBBvc5BIJHje50ks/m01/syLwPCSwbDQ66LsslrNqatx2Bj+GdSk6nhl4LNw7uyo\n7JJUikQiwQu+c/D6nx/gyKVjsNTrgmGOAff8+KKbxVh74lNU1lRh8YD5sDds+UVnH9So7kMQlnYa\nf105iQA7H/Q0bf5rITorASlFGehv4w0rffNmf/6W9Ih9P4SmRSE6KwGnMuPgY9X2W6LzyvOxMmQj\nrpXnY4ChBya5jlZ2SURtDsNSK5AIEgx2GIC+lu74Jukn/H45FKuPfwQfKw884R7UbsLE2WsXsCH8\nM5RUlsHfzgfzvKapVFeU1iYRJOii2xlddDujv01da4Yoisgtv96o9SkNVwozEJ4Rg/CMf1rezBoC\nVH24afgAVlJReltXunRcvy0Y6WnowL2Lc30osoWDoQ2MOxl2iGB0NybaRpjnPR2bIj7Hh5Ff4J3A\npe26dbdB1NUz2BT+OdSk6njV/9kW+XDcHmipa2LZwGfw6h/vYeeZAzDX7XxPX2ZV3arCB2FbkX+z\nEFN7jUVfK/dWqPbBqUmkmOc9DW/8uQ7bT3+F94e92qxLNzSsq9RWxirdThAEPO01FYt/ewdfxH6D\nXmY92sTY07u5Vh+U8srzMdFlJBwq21Z4JVIV7f/TggrR0dDGXK8pGFzfNS/q6hnEZSfjcefhGN19\niNLWG3pYoiji14sh2B13EAKAOZ6TMaxbQIf+cH43giCgi44puuiYor+NF4C685dXnn9HCIrIiEFE\nowClKdFAxaXKJs+nr6kHD3PXJi1GRloGPPcK9Lfxwp9JoUgsvID9ST9ihtt4ZZfUoiIzYvFhxA6o\nS9Xxqv9zrb7GTlvTWdsYS/wWYGXIJmwI/wzvDFkKy39pgWyY+e5iQSr8bX0wruewVqz2wTmZOGBo\nt4H4/VIofjj/R7MuFns6Mx6pRVcxoA22KjWw0OuCx3sOw7fJv2B/wo8P1C1TFVwrz8fKvzYg70YB\nJrmOQpDLyHbTFZ6otTEsKYG9oTXeDnwZoalR2Bd/CPsTf8TxlEg86TkJ7uYuyi7vvlTdqsL26K8Q\nmhYFfQ1dvNT/aXbzuU+CIKCzjgk665jA19oTQH2AulGAKwVp8kkk0vIz4Wzm2GjyBVsYaukzGN2H\nIab9cF0swo/n/0Bvs57tsissUBeUNkXsgEyqjlf9n0cP067KLqlN6G7SFQv6zMDHUV9i7YktWDNk\n2V0nQjh49lecTI9Gd2MHzO8zvU29Dqf1GofTV+Nx6Oyv6G/jBQvdh18GoFasxbfJdWOVgtrQWCVF\nxvUchvD0GPx26TgG2vWFo7G9sku6L42D0mTX0ZjQjIGYqCPq2AsAKZFEkOAR+37YNGIFHnMchJzy\nPKwJ/Rjvh229Y4YyVXWtPB9v/LkOoWlR6GZkh/cefYVBqZkIgoDO2sbwtfbEtN7j8FrAIsy3nYTl\n/s9ikutoeFu6wagTW5Dul0yijkX95kAqSPBJ1C6UVJYpu6RmF5ERg00RO6AhleG1AAal++VvV9dK\nlFOWh/Xh23GrtuaOfcLTY3Ag6SeYdjLCYr/5ba5XQCeZFp70nITq2lv4LPoriKL40M95OjMeafWt\nSv/WItcWqEvV8bT3NIgQsf30PoXXgKq6VnYdK+qD0pReYxiUiJoBw5KSacs64UnPSXj/0VfR07Qb\nojPj8dKvKxGc/AuqaqqVXd5dJeaexyu/v4uUogwMtu+PFYP/12GmRae2rauRLab0GovCimJsPbWn\nWT4oqorw9Bh8GPGFPCh1N2FQehBTeo1BX0t3JF+7gB0x+5tcI5fyU/HJqV3QVNPAsoHPQF9TT4mV\nPjgfKw94WfRC8rULOJ4a+VDPVSvWIjjpFwiC0Kzd+pTJubMjBtv3R1pxJg5f+FPZ5dyT3LI8rAjZ\niOv1QWm882PKLomoXWBYUhG2BlZYMeh/eN7nSWira+FA0s94+de3EZOVqOzSmhBFET+dP4rVxz/C\njVsVeNprGub3mQFZG/tmlTq20T2GwLVzd0RnJeCPy6HKLqdZhKdH46PIf4JSw7pgdP8kggTP+c6G\nvYE1/rwShl8vhgAACm4U4YOwrbhVcwsv9JvbZtYQUkQQBMz1nAINNQ3siTv4UK2sp67GIa04E342\nfdrVTJMz3MZDT0MHB5J+xrWy6//9ACXKaRSUpvYay6BE1IwYllSIIAgYaNcXm0aswCinQOTdKMDa\nE1vw3oktyCnLU3Z5qLhViQ8jv8Ce+IPQ19DFikEvYWi3gewKRm2ORJDgOZ/Z0JFpY1fcQWQUZym7\npIdyMv00PorcCQ01BqXmoqmmgaUDF8JAUw+74oIRmRGLtWFbUFhRjJnu4+Fl0UvZJT40E20jTHYd\njdKqcuyOC36g55CPVRKEdtflS0dDG0+4T0RVTTU+j/laZVuhc8rysPKvjci/UYhpvcfhcefhyi6J\nqF3hBA8qqJO6FmZ5BGGQQ398EfsNYrMSkZhzDoFd/WCgxC4fEekxSCvORHdjB/xvwDyVXHiR6F4Z\ndTLAgj4zsO7kNnwY8QXWDF3WJltIw9JOY3PUTmiqaeD1gEVtbjC6KjPuZIilfgvxVsgGbAj/DAAw\n2L4/RjoFKrmy5vOY4yM4kRaF0NQoBNj5opdZj/t6/KmrccgozoK/rU+zTBShavxs+yA0LRJxOWdx\n8Oxh9LV0h6VeF0glUmWXBgDIKb2GlSGbkH+zENN7P46xPR9VdklE7Q7Dkgqz1rfAm4+8iPCMaOyO\nO4gjF48puyQ82tUfsz0mdog1aqj962vljqFdB+KPyyfwVfwhzPacpOyS7ktY2ilsjvoSWmqaeD1g\nEboZ2ym7pHanm7Ednu07C5sidsDZ1BFPeU1tV63pUokU872n45Wja/FZ9FdYN+z1e14fr3Gr0niX\n9tntSxAEzPWaiiVHVuNA0s84kPQzZFJ12BpYNVkLz0rPvNUDVE7pNawI2YiCm0WY4fY4xvRgUCJq\nCfzEq+IEQcAAmz7wMu+FSwWpqFViNwBdDR2VXp2e6EHMcg/C2byLOHwxBL27OMPTwlXZJd2TE6mn\n8PEpBqXW0N/GGw5GtjDRMmyXXxQ5GNniMcdBOHzhL3x37gim9BpzT4+LunqmrlXJrn22KjXoomOK\ndcNfR1z22Ubr4aXhYn6KfB91qTrs9C1h32gxcCt9c6i1UIDKLr2GFSEbUHizGDPcxmNMj6Etchwi\nYlhqMzTVNeF6n90jiOi/aajJ8ILvHLx69H18emo3Phj+ulK7u96L0NQofHJqF4NSK+qiY6rsElrU\nFNfRiLp6Bj+c/x1+Nn3+c1HZhhnwJIIEQc7ta6ySImY6phjmGCD/uaqmGulFmfLwlFK/mPjFglT5\nPuoStX9aoOrXx7PSt3joAJVVmouVIRtReLMYs9wnYFT3IQ/1fET07xiWiKjDszO0xvTe47ArLhhb\nonZhuf+zkAiqOf9NaGoUPonahU7qmnj9kRfQ1chW2SVRO6Cprom5nlPwftin2Ba9DysH/+9fXwOR\nGbHIKMlGgJ0vuuh2bsVKVYNMqo5uxnZNvqiorqlGenEWrtQHpyuFaUgpysClglTgct0+6hI12BhY\nwr6hC5+hDWz0Le65xTKrNBcr/9qIwopizHIPwqju7Wf8HJGqYlgiIgLwmNMgxOWcRVzOWRy5eAwj\nnAYru6Q7HE+JxJZTu9FJpoU3AhbBgUGJmpG3ZW/4WHkg6uoZ/HXlJIZ0Hahwv9raWgQnH4ZEkLS7\nGfAehrpUHV2NbJt8gVFdU42M4qz6rnt1ISqtKBOXC9Lk+6hJ1GCjb9GkBcpa3+KOxY6zSnKwMmQT\ngxJRK2NYIiJC3XTiz/adhcW/rcbe+ENwNnWCnaGVsssCULe+2fHUSHx6ak99UHoBDkY2yi6L2qEn\nPSchIecc9sYfgrdFbxgomPU04moMrpZk4xH7fu2+e+LDUpeqw8HItu6Ljfo1om/V3EJGSTauFKTJ\nu/E1dOnDlbp9pBJpfYCqG/9kom2Iraf2orCiGLM9JqrklzlE7RXDEhFRPQMtfTzT9wm8d+ITfBi5\nA+8NfQUa9zgzWHMRRREFN4uafBN9pTAdxRUl0JZ1YlCiFmWkZYCpvcfii9hv8GVcMF7sN7fJ9tra\nWgQn1bUqceHTB6MmVYO9oTXsDa3R0DZ0q7YGV+9ogbqKlMIM/NnosQxKRK2PYYmIqBFPC1c85jgI\nv14Mwe64YDztPa3FjiWKIvJvFso/HKXUf1Aqrixtsp9xJ0P0tXLHRJeRsDVQjdYuar8e7eqPE6lR\nCE+PxiN2vnA3d5FvC8+IQWZpDgbZ92erUjNSk0hhZ2gNO0NrDHYYAKAhQGXLg1NP027wtfZUcqVE\nHQ/DEhHRbaa7PY7kaxfwx+UTcDd3QR9Lt4d+TlEUkX+jUD7wuyEglVSWNdnPpJMR+lq6y8cuOBja\nQE9T96GPT3SvJBIJ5vWZjuW/v4vPYr7G+uFvQFNNA7W1tTiYfBhSQYLxzsOVXWa7VxegrFSmOzBR\nR8WwRER0G5lUHYt8n8QrR9fi01N70HWYLYw6Gdzz40VRRN6NAvmYhJTCdFwpzEDpbcHItJMR+lq5\n14ciWzgYWjMYkUqwNbDCqO5D8MP53xGc/AtmuI3HyfRoZJbmYLB9f5ixVYmIOgiGJSIiBWwMLDHL\nbQJ2xO7Hx1Ff4vVHFimcSlkUReSV5zdarLIuHJVWlTfZz1TbGM6mjvIZr+wNbaCnodNafw7RfQty\nGYmIjBj8/Pef6G/tjeCzv9S3KnGsEhF1HAxLRER38Wg3f8TlJCMmKxE/nT+KMT2G4lr59SaDsFMK\nM1B2WzAy0zaBi1l3eTc6B0Mb6GhoK+mvIHowGmoyPOU1DWtCN2P18Y9QVlWOwQ4D0FnHRNmlERG1\nGoYlIqK7EAQBC/vMxOLfVmN/4g/4/vxvKK+60WQfMx1T9DLr0ajFyBo6MgYjah/czZ0xwMYbJ9Oj\n2apERB0SwxIR0b/Q09TF875P4v0Tn0JXpg03s57yyRfsDW2gLeuk7BKJWtQTHhNxMT8FvtZe6Kxt\nrOxyiIhaFcMSEdF/6GXWA7snbIIgCMouhajVGWjq4eNRq5VdBhGRUtw5WpmIiO7AoERERNTxMCwR\nEREREREpwLBERERERESkAMMSERERERGRAgxLRERERERECjAsERERERERKcCwREREREREpADDEhER\nERERkQIMS0RERERERAowLBERERERESnAsERERERERKQAwxIREREREZECDEtEREREREQKMCwRERER\nEREpwLBERERERESkAMMSERERERGRAgxLRERERERECjAsERERERERKcCwREREREREpADDEhERERER\nkQIMS0RERERERAowLBERERERESnAsERERERERKQAwxIREREREZECDEtEREREREQKMCwREREREREp\nwLBERERERESkAMMSERERERGRAoIoiqKyi7hfMTExyi6BiIiIiDoALy8vZZdAStQmwxIREREREVFL\nYzc8IiIiIiIiBRiWiIiIiIiIFGBYIiIiIiIiUoBhiYiIiIiISAGGJSIiIiIiIgUYloiIiIiIiBRQ\nU3YBqqi2thYrVqzA33//DZlMhtWrV8PW1la+/cCBA9i/fz/U1NSwcOFCDBo0SInVqp7q6mq8+uqr\nyMzMRFVVFRYuXIjAwED59p07dyI4OBhGRkYAgJUrV8LBwUFZ5aqkcePGQVdXFwBgZWWFd999V76N\n19+/++6773Do0CEAQGVlJc6dO4eTJ09CT08PALB69WrExsZCW1sbALBlyxb5ue7o4uPjsW7dOuzZ\nswdpaWlYvnw5BEGAo6Mj3nrrLUgk/3y/VlFRgSVLliA/Px/a2tpYu3at/DXdUTU+f+fOncOqVasg\nlUohk8mwdu1amJiYNNn/317nHVHj85ecnIwFCxbAzs4OADB16lSMGDFCvi+vvzs1Pn8vvfQSrl+/\nDgDIzMyEm5sbNm7cKN9XFEX4+/vLz6+7uztefvllZZRNpPpEusNvv/0mLlu2TBRFUTxz5oy4YMEC\n+bZr166Jo0aNEisrK8WSkhL5v+kfwcHB4urVq0VRFMWCggIxICCgyfaXX35ZTExMVEJlbUNFRYU4\nduxYhdt4/d2fFStWiPv372/yuylTpoj5+flKqkh1bd++XRw1apQ4ceJEURRFcf78+WJkZKQoiqL4\nxhtviL///nuT/b/44gvxo48+EkVRFH/++Wdx1apVrVuwirn9/E2fPl08e/asKIqi+PXXX4tr1qxp\nsv+/vc47otvP34EDB8QdO3bcdX9ef03dfv4aFBUViWPGjBFzc3Ob/D41NVWcP39+a5ZI1GaxG54C\nMTExGDhwIIC6b1uSkpLk2xISEuDh4QGZTAZdXV3Y2Njg/PnzyipVJQ0fPhwvvPCC/GepVNpke3Jy\nMrZv346pU6di27ZtrV2eyjt//jxu3ryJOXPmYNasWYiLi5Nv4/V37xITE3Hp0iVMnjxZ/rva2lqk\npYwGgYwAAAiNSURBVKXhzTffxJQpUxAcHKzEClWLjY0NNm/eLP85OTkZffv2BQD4+/sjPDy8yf6N\n75P+/v6IiIhovWJV0O3nb8OGDejZsycAoKamBhoaGk32/7fXeUd0+/lLSkrCsWPHMH36dLz66qso\nKytrsj+vv6ZuP38NNm/ejBkzZqBz585Nfp+cnIzc3FzMnDkTTz/9NK5cudJapRK1OQxLCpSVlUFH\nR0f+s1Qqxa1bt+TbGnfZ0dbWvuMm3tFpa2tDR0cHZWVlWLRoEV588cUm20eOHIkVK1Zg165diImJ\nQUhIiJIqVU2ampqYO3cuduzYgZUrV2Lx4sW8/h7Atm3b8Oyzzzb53Y0bNzBjxgx88MEH+Pzzz/HV\nV18xbNYbNmwY1NT+6ZktiiIEQQBQd52VlpY22b/xtahoe0dz+/lr+HAaGxuLvXv3Yvbs2U32/7fX\neUd0+/nr3bs3li5din379sHa2hqffPJJk/15/TV1+/kDgPz8fERERGD8+PF37G9qaop58+Zhz549\nmD9/PpYsWdJapRK1OQxLCujo6KC8vFz+c21trfwmdPu28vJyjndQIDs7G7NmzcLYsWMxevRo+e9F\nUcQTTzwBIyMjyGQyBAQE4OzZs0qsVPXY29tjzJgxEAQB9vb2MDAwQF5eHgBef/eqpKQEV65cga+v\nb5Pfa2lpYdasWdDS0oKOjg58fX0Zlu6i8fik8vJy+ZivBo2vRUXbCTh8+DDeeustbN++/Y7xNP/2\nOidg6NChcHV1lf/79vcJXn//7ciRIxg1atQdvTsAwNXVVT6W2NvbG7m5uRBFsbVLJGoTGJYU8PT0\nRGhoKAAgLi4OTk5O8m29e/dGTEwMKisrUVpaisuXLzfZTsD169cxZ84cLFmyBEFBQU22lZWVYdSo\nUSgvL4coioiKipK/IVKd4OBgvPfeewCA3NxclJWVwdTUFACvv3t1+vRp9O/f/47fp6amYtq0aaip\nqUF1dTViY2Ph4uKihApVn7OzM6KiogAAoaGh8Pb2brLd09MTx48fl2/38vJq9RpV2Q8//IC9e/di\nz549sLa2vmP7v73OCZg7dy4SEhIAABEREXe8Tnn9/beIiAj4+/sr3Pbxxx9j165dAOq6hFpYWMhb\nkomoKc6Gp8DQoUNx8uRJTJkyBaIoYs2aNdi5cydsbGwQGBiImTNnYtq0aRBFES+99NIdfdE7uq1b\nt6KkpARbtmzBli1bAAATJ07EzZs3MXnyZLz00kuYNWsWZDIZ+vXrh4CAACVXrFqCgoLwyiuvYOrU\nqRAEAWvWrMGePXt4/d2HlJQUWFlZyX9u/PodPXo0Jk2aBHV1dYwdOxaOjo5KrFR1LVu2DG+88QY2\nbNgABwcHDBs2DAAwZ84cbN26FVOnTsWyZcswdepUqKurY/369UquWHXU1NTgnXfegbm5OZ5//nkA\nQJ8+fbBo0SIsXboUL774osLX+e3dqDqyFStWYNWqVVBXV4eJiQlWrVoFgNff/UhJSbkjqDecv3nz\n5mHJkiU4fvw4pFJph5+JkejfCCLbXYmIiIiIiO7AbnhEREREREQKMCwREREREREpwLBERERERESk\nAMMSERERERGRAgxLRERERERECjAsERGpqCNHjmD8+PEYM2YMRo8ejc8//7zFjvXdd99h+fLlLfb8\nREREbREXdSAiUkG5ublYu3YtvvvuOxgaGqK8vBwzZ86Evb09AgMDlV0eERFRh8CwRESkggoLC1Fd\nXY2KigoAgLa2Nt577z1oaGjg119/xc6dO1FRUYGqqiqsWbMGnp6emDlzJpydnRETE4PKykosXrwY\nu3fvxuXLlzF79mzMnj0bmzdvRlZWFi5fvozCwkJMnjwZTz31VJNjJyQk4N1330VFRQUMDQ2xcuVK\nWFtbY+fOnTh06BAkEgl69+6Nt99+WxmnhoiIqNUwLBERqaAePXogMDAQQ4YMQc+ePeHj44PRo0fD\n2toab775JrZu3QojIyMEBwdj+/bt2Lp1KwBAFEUEBwfj448/xurVq/Hjjz+ioKAA48aNw+zZswEA\nSUlJ2L9/P2prazF+/Hj069dPftyqqiq8/vrr2Lp1KywsLHDixAm88cYb2LFjB7Zt24YTJ05AKpXi\ntddeQ25uLszMzJRxeoiIiFoFwxIRkYpauXIlnnnmGYSFhSEsLAyTJk3CunXr8Mknn+Cvv/5CSkoK\nTp06BYnkn+Gn/v7+AAALCwu4ublBS0sLlpaWKCkpke8zatQoaGtrAwAGDx6MyMhIGBoaAgBSU1OR\nkZGBhQsXyvcvKyuDVCqFh4cHgoKCEBgYiCeffJJBiYiI2j2GJSIiFXTs2DHcuHEDI0aMwIQJEzBh\nwgQcOHAA+/btw4YNGzBmzBj06dMH3bt3x759++SPU1dXl/9bTU3xLV4qlcr/XVtbe8fPVlZW+OGH\nHwAANTU1uH79OgBgy5YtiIuLQ2hoKJ566imsW7cOffv2bda/m4iISJVwNjwiIhWkqamJ9evX4+rV\nqwDqutedO3cOMpkMgiBgwYIF8PHxwR9//IGampr7eu6jR4+iqqoKxcXFCAkJgZ+fn3ybg4MDiouL\nER0dDQA4ePAgFi9ejIKCAowYMQJOTk544YUXMGDAAPz999/N9wcTERGpILYsERGpIF9fXzz33HNY\nsGABqqurAQADBw7EJ598guXLl+Oxxx6DIAjw8/NDTEzMfT23hoYGpk2bhrKyMsyfPx/dunVDQkIC\nAEAmk+HDDz/EO++8g8rKSujo6GDt2rUwMjLC5MmTERQUBC0tLdjb22PChAnN/ncTERGpEkEURVHZ\nRRARUevYvHkzAOD5559XciVERESqj93wiIiIiIiIFGDLEhERERERkQJsWSIiIiIiIlKAYYmIiIiI\niEgBhiUiIiIiIiIFGJaIiIiIiIgUYFgiIiIiIiJS4P+4TtII3dDQSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f6fbcf668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(nb_samples))\n",
    "y = [result_LSTM, result_SRNN, result_GRU]\n",
    "labels = [\"LSTM\", \"SimpleRNN\", \"GRU\"]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for y_arr, label in zip(y, labels):\n",
    "    plt.plot(x, y_arr, label=label)\n",
    "\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.savefig(\"test_result.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this workbook, we started to go through RNN. We check a simple model of both LSTM, GRU and SimpleRNN to check how fast and well they learn. On this example GRU and LSTM outperform the standard RNN due to the memory function. There is also a difference between LSTM and GRU but with slightly more epochs, they both perform similar. We can probably have better result by using a more advanced model but for such a simple model, we can see that it works really well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further\n",
    "\n",
    "On a future notebook, we will explore Embedded Reber but using deeper RNNs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
